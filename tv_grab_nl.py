#!/usr/bin/env python2
# -*- coding: utf-8 -*-

# Python 3 compatibility
from __future__ import unicode_literals
# from __future__ import print_function

description_text = """
    SYNOPSIS

    tv_grab_nl_py is a python script that trawls tvgids.nl for TV
    programming information and outputs it in XMLTV-formatted output (see
    http://membled.com/work/apps/xmltv). Users of MythTV
    (http://www.mythtv.org) will appreciate the output generated by this
    grabber, because it fills the category fields, i.e. colors in the EPG,
    and has logos for most channels automagically available. Check the
    website below for screenshots.  The newest version of this script can be
    found here:

         https://github.com/tvgrabbers/tvgrabnlpy/

    USAGE

    Check the web site above and/or run script with --help and start from there

    REQUIREMENTS

    * Python 2.6 or 2.7
    * Connection with the Internet

    QUESTIONS

    Questions (and patches) are welcome at:
    http://www.pwdebruin.net/mailman/listinfo/tv_grab_nl_py_pwdebruin.net
    https://github.com/tvgrabbers/tvgrabnlpy/issues
    https://groups.google.com/forum/#!forum/tvgrabnlpy

    UPGRADE NOTES

    If you were using tv_grab_nl from the XMLTV bundle then enable the
    compat flag or use the --compat command-line option.  Otherwise, the
    xmltvid's are wrong and you will not see any new data in MythTV.

    HISTORY

    tv_grab_nl_py used to be called tv_grab_nl_pdb, created by Paul de Bruin
    and first released on 2003/07/09. At the same time the code base switched
    from using CVS to SVN at Google Code, and as a result the version numbering
    scheme has changed. The lastest official release of tv_grab_nl_pdb is 0.48.
    The first official release of tv_grab_nl_py is 6. In 2012, The codebase
    moved to Git, and the version number was changed once more. The latest
    subversion release of tv_grab_nl_py is r109. The first Git release of
    tv_grab_nl_py is 2012-03-11 12:03.

    As of december 2014/ januari 2015 Version 2.0.0:
      Upgrading argument processing from getopt to argparse.
      Also adding some options and adding to help text.
      Fixing a small bug preventing multiple word details like 'jaar van
        premiere' from being proccessed.
      Adding genre/subgenre translation table and file (tv_grab_nl_py.set).
        Automatically adding new genre/subgenre combinations on every scan.
        Still looking into the way MythTV handles this.
        This contains also other translation tables which mostly get updated on
        every scan and gets created with defaults if not existing.
      Adding titlesplit exception list to tv_grab_nl_py.set. Especially for
        spin-off series like 'NCIS: Los Angeles'.
      Adding optional default options file and creation.  (tv_grab_nl_py.opt)
      Adding optional proccessing of HD attribute.
      Adding session log function (to the configname with .log added)
        the last log is saved to .old (like with .conf, .opt and .set files)
      Adding rtl.nl lookup for the 7 RTL channels. This adds season/episode info
        and lookup further than 4 days in the future, defaulting to 14 days.
        Genre info is missing. Timing and description from rtl.nl is used over
        tvgids.nl
      Adding  teveblad.be lookup, mainly for belgium channels. This adds
        season/episode info and lookup up to 7 days. Dutch channels only
        have prime-time info and the commercial channels are missing.
        Genre info is basic. Timing for the Belgium channels is used over
        tvgids.nl
      Adding tvgids.tv lookup. This adds lookup up to 14 days with decent genre
        info.
      Merged tv_grab_nl_py.opt into tv_grab_nl_py.conf and added several
        translation tables to tv_grab_nl_py.set.
      Moving html proccessing from pure regex filtering to ElementTree
      Reorganised code to be more generic to make adding new sources easer
        and as preparation for a configuration module. Also put the different
        sources in parallel threads.
      Working on more intelligent description proccessing.
      Working in ever more intelligent source merging.
      Working on a configuration module.
      Possibly adding ttvdb.com and tmdb3.com lookup for missing descriptions
        and season/episode info
      Possibly adding more optional (foreign) sources (atlas?)

    CONTRIBUTORS

    Main author: Paul de Bruin (paul at pwdebruin dot net)
    Current maintainer: Freek Dijkstra (software at macfreek dot nl)
    Currently 'december 2014' the latest version of '2012-03-27' adapted by:
    Hika van den Hoven hikavdh at gmail dot com, but also active on the
    mythtv list: mythtv-users at mythtv dot org

    Michel van der Laan made available his extensive collection of
    high-quality logos that is used by this script.

    Several other people have provided feedback and patches:
    Huub Bouma, Michael Heus, Udo van den Heuvel, Han Holl, Hugo van der Kooij,
    Roy van der Kuil, Ian Mcdonald, Dennis van Onselen, Remco Rotteveel, Paul
    Sijben, Willem Vermin, Michel Veerman, Sietse Visser, Mark Wormgoor.

    LICENSE

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 2 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
"""

# Modules we need
import re, sys, codecs, locale, argparse
import time, random, io, json, shutil
import os, os.path, curses, pickle
try:
    import urllib.request as urllib
except ImportError:
    import urllib2 as urllib
try:
    from html.entities import name2codepoint
except ImportError:
    from htmlentitydefs import name2codepoint
from threading import Thread
from threading import Lock
from xml.sax import saxutils
from xml.etree import cElementTree as ET
from collections import deque
try:
    unichr(42)
except NameError:
    unichr = chr    # Python 3

# Extra check for the datetime module
try:
    import datetime
except ImportError:
    sys.stderr.write('This script needs the datetime module that was introduced in Python version 2.3.\n')
    sys.stderr.write('You are running:\n')
    sys.stderr.write('%s\n' % sys.version)
    raise

# check Python version
if sys.version_info[:2] < (2,7):
    sys.stderr.write("tv_grab_nl_py requires Pyton 2.7 or higher\n")
    sys.exit(2)

elif sys.version_info[:2] >= (3,0):
    sys.stderr.write("tv_grab_nl_py does not yet support Pyton 3 or higher.\nExpect errors while we proceed\n")

# XXX: fix to prevent crashes in Snow Leopard [Robert Klep]
if sys.platform == 'darwin' and sys.version_info[:3] == (2, 6, 1):
    try:
        urllib.urlopen('http://localhost.localdomain')
    except Exception:
        pass

class AmsterdamTimeZone(datetime.tzinfo):
    """Timezone information for Amsterdam"""
    def __init__(self):
        # calculate for the current year:
        year = datetime.date.today().year
        d = datetime.datetime(year, 4, 1, 2, 0)  # Starts last Sunday in March 02:00:00
        self.dston = d - datetime.timedelta(days=d.weekday() + 1)
        d = datetime.datetime(year, 11, 1, 2, 0) # Ends last Sunday in October 02:00:00
        self.dstoff = d - datetime.timedelta(days=d.weekday() + 1)

    def tzname(self, dt):
        return unicode('CET_CEST')

    def utcoffset(self, dt):
        return datetime.timedelta(hours=1) + self.dst(dt)

    def dst(self, dt):

        if self.dston <=  dt.replace(tzinfo=None) < self.dstoff:
            return datetime.timedelta(hours=1)

        else:
            return datetime.timedelta(0)
# end AmsterdamTimeZone

class UTCTimeZone(datetime.tzinfo):
    """UTC Timezone"""
    def tzname(self, dt):
        return unicode('UTC')

    def utcoffset(self, dt):
        return datetime.timedelta(0)

    def dst(self, dt):
        return datetime.timedelta(0)

# end UTCTimeZone

CET_CEST = AmsterdamTimeZone()
UTC  = UTCTimeZone()

config = None
def log(message, log_level = 1, log_target = 3, Locked = False):
    # Prints a warning to stderr.
    # Note: The function encodes all ouput to utf-8. This may be wrong.
    # TODO: use sys.stdout.encoding, locale.getpreferredencoding(), sys.getfilesystemencoding(), and/or
    #       os.environ["PYTHONIOENCODING"] to determine the correct encoding.
    # TODO: use logging module
    def now():
         return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S %Z') + ': '

    try:
        # If config is not yet available
        if (config == None) and (log_target & 1):
            sys.stderr.write('Error writing to log. Not (yet) available?\n')
            sys.stderr.write(message.encode("utf-8"))
            return

        if not Locked:
            # If it's not locked beforehand
            config.log_lock.acquire()

        # Log to the Frontend. To set-up later.
        if config.opt_dict['graphic_frontend']:
            pass

        # Log to the screen
        elif log_level == 0 or ((not config.opt_dict['quiet']) and (log_level & config.opt_dict['log_level']) and (log_target & 1)):
            sys.stdout.write(message.encode("utf-8"))

        # Log to the log-file
        if (log_level == 0 or ((log_level & config.opt_dict['log_level']) and (log_target & 2))) and config.log_output != None:
           sys.stderr.write(now() + message.replace('\n','') + '\n')

        if not Locked:
            config.log_lock.release()

    except:
        print 'An error ocured while logging!'
        sys.stderr.write(now() + 'An error ocured while logging!\n')
        if not Locked:
            config.log_lock.release()

# end log()

class Configure:
    """This class holds all configuration details and manages file IO"""

    def __init__(self):
        """
        DEFAULT OPTIONS - Edit if you know what you are doing
        """
        # Version info as returned by the version function
        self.name ='tv_grab_nl_py'
        self.major = 2
        self.minor = 1
        self.patch = 9
        self.patchdate = u'20150625'
        self.alfa = False
        self.beta = True

        self.channels = {}
        self.chan_count = 0
        self.opt_dict = {}
        self.opt_dict['graphic_frontend'] = False

        # Used for creating extra output to beter the code
        self.write_info_files = False

        # This handles what goes to the log and screen
        # 0 Nothing (use quiet mode to turns of screen output, but keep a log)
        # 1 include Errors and Warnings
        # 2 include page fetches
        # 4 include summaries
        # 8 include detail fetches to the screen
        # 16 include detail fetches to the log
        # 32 include matchlogging (see below)
        # 64 Title renames
        self.opt_dict['log_level'] = 47
        # The log filehandler, gets set later
        self.log_output = None
        self.log_lock = Lock()

        # What match results go to the log/screen (needs code 32 above)
        # 0 = Log Nothing (just the overview)
        # 1 = log not matched programs
        # 2 = log left over programs
        # 4 = Log matches
        self.opt_dict['match_log_level'] = 1

        # A selection of user agents we will impersonate, in an attempt to be less
        # conspicuous to the tvgids.nl police.
        self.user_agents = [ 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1)',
               'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.9) Gecko/20071025 Firefox/2.0.0.9',
               'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322)',
               'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.7) Gecko/20060909 Firefox/1.5.0.7',
               'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)',
               'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.1.9) Gecko/20071105 Firefox/2.0.0.9',
               'Mozilla/5.0 (Macintosh; U; Intel Mac OS X; en-US; rv:1.8.1.9) Gecko/20071025 Firefox/2.0.0.9',
               'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.1.8) Gecko/20071022 Ubuntu/7.10 (gutsy) Firefox/2.0.0.8']

        # default encoding iso-8859-1 is general and iso-8859-15 is with euro support
        self.configencoding = 'iso-8859-15'
        self.file_encoding = 'utf-8'

        # seed the random generator
        random.seed(time.time())

        # default configuration file locations
        self.hpath = ''
        if 'HOME' in os.environ:
            self.hpath = os.environ['HOME']
        # extra test for windows users
        elif 'HOMEPATH' in os.environ:
            self.hpath = os.environ['HOMEPATH']

        self.xmltv_dir = u'%s/.xmltv' % self.hpath
        self.config_file = u'%s/tv_grab_nl_py.conf' % self.xmltv_dir
        self.log_file = u'%s/tv_grab_nl_py.log' % self.xmltv_dir
        self.settings_file = u'%s/tv_grab_nl_py.set' % self.xmltv_dir

        # cache the detail information.
        self.program_cache_file = u'%s/program_cache' % self.xmltv_dir

        # save the cache every # fetches
        self.opt_dict['cache_save_interval'] = 1000

        self.clean_cache = True
        self.clear_cache = False

        # where the output goes. None means to the screen (stdout)
        self.opt_dict['output_file'] = None

        # how many seconds to wait before we timeout on a
        # url fetch, 10 seconds seems reasonable
        self.global_timeout = 10

        # Wait a random number of seconds between each page fetch.
        # We want to be nice and not hammer tvgids.nl (these are the
        # friendly people that provide our data...).
        # Also, it appears tvgids.nl throttles its output.
        # So there, there is not point in lowering these numbers, if you
        # are in a hurry, use the (default) fast mode.
        self.nice_time = [1, 2]

        # Experimental strategy for clumping overlapping programming, all programs that overlap more
        # than max_overlap minutes, but less than the length of the shortest program are clumped
        # together. Highly experimental and disabled for now.
        self.do_clump = False

        # First fill the dict with some defaults
        # no output
        self.opt_dict['quiet'] = False

        # Fetch data in fast mode, i.e. do NOT grab all the detail information,
        # fast means fast, because as it then does not have to fetch a web page for each program
        self.opt_dict['fast'] = False

        # The day to start grabbing 0 means now
        self.opt_dict['offset'] = 0

        # the total number of days to fetch
        # the first four come from tvgids.nl the rest from tvgids.tv
        self.opt_dict['days'] = 14

        # None means all in slow-mode and none in fast-mode
        # Setting it to a value sets 'fast' always to False (i.e. to slow-mode)
        self.opt_dict['slowdays'] = None

        # the total number of days to fetch basic info for the RTL channels
        self.opt_dict['rtldays'] = 14

        # the total number of days to fetch basic info through belgium teveblad.be
        self.opt_dict['tevedays'] = 8

        self.opt_dict['use_npo'] = True
        # enable this option if you were using tv_grab_nl, it adjusts the generated
        # xmltvid's so that everything works.
        self.opt_dict['compat'] = False

        # Maximum length in minutes of gaps/overlaps between programs to correct
        self.opt_dict['max_overlap'] = 10

        # Strategy to use for correcting overlapping prgramming:
        # 'average' = use average of stop and start of next program
        # 'stop'    = keep stop time of current program and adjust start time of next program accordingly
        # 'start'   = keep start time of next program and adjust stop of current program accordingly
        # 'none'    = do not use any strategy and see what happens
        self.opt_dict['overlap_strategy'] = 'average'

        # insert url of channel logo into the xml data, this will be picked up by mythfilldatabase
        self.opt_dict['logos'] = True

        # Maximum number of characters to use for program description.
        # Different values may work better in different versions of MythTV.
        self.opt_dict['desc_length'] = 475

        # enable this option if you do not want the tvgids categories being translated into
        # MythTV-categories (genres)
        self.opt_dict['cattrans'] = True

        # mark programs with the HD 1080i tag in the output
        # leave off if you only record analog SD
        self.opt_dict['mark_hd'] = False

        # don't convert all the program date/times to UTC (GMT) timezone.
        # by default the current timezone is Europe/Amsterdam. This works fine
        # if you are located in the Amsterdam timezone, but not if you live abroad
        # in another timezone. If you want to use the UTC timestamp in combination
        # with mythtv, be sure to set the timezone in mythtv to 'auto'
        # (TimeOffset in Settings table)
        self.opt_dict['use_utc'] = False

        # The values for the Kijkwijzer
        self.kijkwijzer = {'1': {'code': 'AL','text': 'Voor alle leeftijden',
                        'icon':'http://tvgidsassets.nl/img/kijkwijzer/al_transp.png'},
                        '2': {'code': '6+','text': 'Afgeraden voor kinderen jonger dan 6 jaar',
                        'icon':'http://tvgidsassets.nl/img/kijkwijzer/6_transp.png'},
                        '9': {'code': '9+','text': 'Afgeraden voor kinderen jonger dan 9 jaar',
                        'icon':'http://tvgidsassets.nl/img/kijkwijzer/9_transp.png'},
                        '3': {'code': '12+','text': 'Afgeraden voor kinderen jonger dan 12 jaar',
                        'icon':'http://tvgidsassets.nl/img/kijkwijzer/12_transp.png'},
                        '4': {'code': '16+','text': 'Niet voor personen tot 16 jaar',
                        'icon':'http://tvgidsassets.nl/img/kijkwijzer/16_transp.png'},
                        'g': {'code': 'Geweld','text': 'Geweld',
                        'icon':'http://tvgidsassets.nl/img/kijkwijzer/geweld_transp.png'},
                        'a': {'code': 'Angst','text': 'Angst',
                        'icon':'http://tvgidsassets.nl/img/kijkwijzer/angst_transp.png'},
                        's': {'code': 'Seks','text': 'Seks',
                        'icon':'http://tvgidsassets.nl/img/kijkwijzer/seks_transp.png'},
                        't': {'code': 'Grof','text': 'Grof taalgebruik',
                        'icon':'http://tvgidsassets.nl/img/kijkwijzer/grof_transp.png'},
                        'h': {'code': 'Drugs','text': 'drugs- en/of alcoholmisbruik',
                        'icon':'http://tvgidsassets.nl/img/kijkwijzer/drugs_transp.png'},
                        'd': {'code': 'Discriminatie','text': 'Discriminatie',
                        'icon':'http://tvgidsassets.nl/img/kijkwijzer/discriminatie_transp.png'}}
        # Mystery values: o.A. 5 7 8 G A
        # RTL: AL,6,9,12,16 gasthd, tv: AL, 9, 12, 16, geweld
        # DEU, ARG, AUS, FRA, USA, AUT, GBR, BEL, CAN, CHE, SWE, DNK, ESP, HKG, IRL, HUN, ITA, KOR, NLD, NOR, ZAF
        # Create a role translation dictionary for the xmltv credits part
        # The keys are the roles used by tvgids.nl (lowercase please)
        self.roletrans = {'regisseur'                         : 'director',
                             'regie'                                        : 'director',
                             'acteurs'                                    : 'actor',
                             'acteursnamen_rolverdeling': 'actor',
                             'scenario'                                  : 'writer',
                             'scenario schrijver'              : 'writer',
                             'componist'                                : 'composer',
                             'presentatie'                            : 'presenter',
                             'commentaar'                              : 'commentator'}

        # List of titles not to split with title_split().
        # these are mainly spin-off series like NCIS: Los Angeles
        self.notitlesplit = [ u'ncis: los angeles',
                                u'ncis: new orleans',
                                u'csi: miami',
                                u'csi: new york',
                                u'law & order: special victims unit']

        # Parts to remove from a title
        self.groupnameremove = ['kro detectives',]
        # Titles to rename
        self.titlerename = {'navy ncis': 'NCIS',
                                        'inspector banks': 'DCI Banks'}

        # Create a category translation dictionary
        # Look in mythtv/themes/blue/ui.xml for all category names
        # The keys are the categories used by tvgids.nl (lowercase please)
        # See the file ~/.xmltv/genre_translation created after the first run and edit there!
        self.cattrans = { (u'', u'')                                                 : u'Unknown',
                             (u'talks', u'')                                              : u'Talk',
                             (u'amusement', u'')                                      : u'Talk',
                             (u'amusement', u'quiz')                              : u'Game',
                             (u'amusement', u'spelshow')                      : u'Game',
                             (u'amusement', u'muziekshow')                  : u'Art/Music',
                             (u'amusement', u'muziekprogramma')        : u'Art/Music',
                             (u'amusement', u'dansprogramma')            : u'Art/Music',
                             (u'amusement', u'cabaret')                        : u'Art/Music',
                             (u'amusement', u'sketches')                      : u'Art/Music',
                             (u'amusement', u'stand-up comedy')        : u'Art/Music',
                             (u'amusement', u'stand-up comedy, sketches'): u'Art/Music',
                             (u'amusement', u'erotisch programma')  : u'Adult',
                             (u'amusement', u'komedie')                        : u'Comedy',
                             (u'amusement', u'klusprogramma')            : u'Home/How-to',
                             (u'amusement', u'hobbyprogramma')          : u'Home/How-to',
                             (u'amusement', u'lifestyleprogramma')  : u'Home/How-to',
                             (u'amusement', u'modeprogramma')            : u'Home/How-to',
                             (u'amusement', u'kookprogramma')            : u'Cooking',
                             (u'amusement', u'realityserie')              : u'Reality',
                             (u'documentaire', u'')                                : u'Documentary',
                             (u'educatief', u'')                                      : u'Educational',
                             (u'film', u'')                                                : u'Film',
                             (u'korte film', u'')                                    : u'Film',
                             (u'info', u'')                                                : u'News',
                             (u'info', u'business')                                : u'Bus./financial',
                             (u'info', u'documentary')                          : u'Documentary',
                             (u'info', u'science')                                  : u'Science/Nature',
                             (u'informatief, amusement', u'')            : u'Educational',
                             (u'informatief, amusement', u'kookprogramma'): u'Cooking',
                             (u'informatief, kunst en cultuur', u''): u'Arts/Culture',
                             (u'informatief, wetenschap', u'')          : u'Science/Nature',
                             (u'informatief', u'')                                  : u'Educational',
                             (u'informatief', u'wetenschappelijk programma'): u'Science/Nature',
                             (u'informatief', u'techniek')                  : u'Science/Nature',
                             (u'informatief', u'documentaire')          : u'Documentary',
                             (u'informatief', u'gezondheid')              : u'Health',
                             (u'informatief', u'fitnessprogramma')  : u'Health',
                             (u'informatief', u'gymnastiekprogramma'): u'Health',
                             (u'informatief', u'medisch programma'): u'Health',
                             (u'informatief', u'medisch praatprogramma'): u'Health',
                             (u'informatief', u'docusoap')                  : u'Reality',
                             (u'informatief', u'realityprogramma')  : u'Reality',
                             (u'informatief', u'realityserie')          : u'Reality',
                             (u'informatief', u'praatprogramma')      : u'Talk',
                             (u'informatief', u'jeugdprogramma')      : u'Children',
                             (u'jeugd', u'')                                              : u'Children',
                             (u'kunst/cultuur', u'')                              : u'Arts/Culture',
                             (u'kunst en cultuur', u'')                        : u'Arts/Culture',
                             (u'magazine', u'')                                        : u'Talk',
                             (u'muziek', u'')                                            : u'Art/Music',
                             (u'natuur', u'')                                            : u'Science/Nature',
                             (u'nieuws/actualiteiten', u'')                : u'News',
                             (u'news', u'')                                                : u'News',
                             (u'religieus', u'')                                      : u'Religion',
                             (u'serie/soap', u'')                                    : u'Drama',
                             (u'serie/soap', u'jeugdserie')                : u'Children',
                             (u'serie/soap', u'animatieserie')          : u'Children',
                             (u'serie/soap', u'tekenfilmserie')        : u'Children',
                             (u'serie/soap', u'soap')                            : u'Soap',
                             (u'serie/soap', u'comedyserie')              : u'Comedy',
                             (u'serie/soap', u'komedieserie')            : u'Comedy',
                             (u'serie/soap', u'detectiveserie')        : u'Crime/Mystery',
                             (u'serie/soap', u'misdaadserie')            : u'Crime/Mystery',
                             (u'serie/soap', u'fantasyserie')            : u'Sci-fi/Fantasy',
                             (u'serie/soap', u'sciencefictionserie'): u'Sci-fi/Fantasy',
                             (u'serie/soap', u'actieserie')                : u'Action',
                             (u'sport', u'')                                              : u'Sports',
                             (u'talks', u'')                                              : u'Talk',
                             (u'talkshow', u'')                                        : u'Talk',
                             (u'wetenschap', u'')                                    : u'Science/Nature',
                             (u'overige', u'')                                          : u'Unknown'}

        self.genre_list = []

        self.source_channels ={}
        self.source_channels[0] = {}
        # channels for which to look on tvgids.tv
        self.source_channels[1] = {1: u'nederland-1',
                                           2: u'nederland-2',
                                           3: u'nederland-3',
                                           4: u'rtl-4',
                                           31: u'rtl-5',
                                           46: u'rtl-7',
                                           92: u'rtl-8',
                                           36: u'sbs-6',
                                           37: u'net-5',
                                           34: u'veronica',
                                           460: u'sbs-9',
                                           440: u'fox',
                                           29: u'discovery-channel',
                                           305: u'discovery-world',
                                           306: u'discovery-science',
                                           414: u'investigation-discovery',
                                           94: u'syfy',
                                           439: u'animal-planet',
                                           438: u'tlc',
                                           18: u'national-geographic',
                                           416: u'nat-geo-wild',
                                           413: u'history',
                                           25: u'mtv',
                                           404: u'foxlife',
                                           408: u'rtl-lounge',
                                           99: u'sport1',
                                           419: u'sport-1-3',
                                           420: u'sport-1-extra',
                                           19: u'eurosport',
                                           436: u'eurosport-2',
                                           148: u'eredivisie-live',
                                           417: u'extreme-sports',
                                           418: u'espn-classic',
                                           24: u'film1.1',
                                           411: u'film1-action',
                                           39: u'film1-familiy',
                                           107: u'film1-festival',
                                           430: u'film1-series',
                                           93: u'13th-street',
                                           409: u'rtl-crime',
                                           311: u'disney-xd',
                                           424: u'disney-channel',
                                           21: u'cartoon-network',
                                           317: u'comedy-family',
                                           91: u'comedy-central',
                                           89: u'nickelodeon',
                                           312: u'nick-jr',
                                           410: u'101-tv',
                                           66: u'humortv-24',
                                           316: u'best-24',
                                           70: u'cultura-24',
                                           81: u'hollanddoc-24',
                                           90: u'bvn',
                                           403: u'goed-tv',
                                           431: u'hbo',
                                           432: u'hbo-2',
                                           433: u'hbo-3',
                                           435: u'24kitchen',
                                           428: u'bravatv',
                                           407: u'out-tv',
                                           461: u'pebble-tv',
                                           304: u'mgm',
                                           5: u'een',
                                           6: u'ketnet-canvas',
                                           49: u'vtm',
                                           59: u'2be',
                                           60: u'vt4',
                                           40: u'at-5',
                                           115: u'l1-tv',
                                           114: u'omroep-brabant',
                                           113: u'omroep-flevoland',
                                           109: u'omrop-fryslan',
                                           112: u'omroep-gelderland',
                                           116: u'omroep-zeeland',
                                           110: u'rtv-drenthe',
                                           108: u'rtv-noord',
                                           103: u'rtv-noord-holland',
                                           111: u'rtv-oost',
                                           102: u'rtv-rijnmond',
                                           100: u'rtv-utrecht',
                                           101: u'rtv-west',
                                           7: u'bbc-1',
                                           8: u'bbc-2',
                                           300: u'bbc-3',
                                           301: u'bbc-4',
                                           104: u'bbc-prime',
                                           86: u'bbc-world',
                                           26: u'cnn',
                                           9: u'ard',
                                           10: u'zdf',
                                           11: u'rtl',
                                           12: u'wdr-fernsehen',
                                           13: u'ndr-fernsehen',
                                           50: u'3sat',
                                           38: u'arte',
                                           58: u'pro-7',
                                           28: u'sat-1',
                                           17: u'tv-5',
                                           15: u'rtbf-la-1',
                                           16: u'rtbf-la-2',
                                           32: u'trt-international',
                                           20: u'tcm'}

        # tvgids.tv subgenre to genre translation table
        self.tvtvcattrans = {'euromillions': 'Amusement',
                                 'erotisch magazine': 'Amusement',
                                 'reality-reeks': 'Amusement',
                                 'keno': 'Amusement',
                                 'loterij': 'Amusement',
                                 'spektakel': 'Amusement',
                                 'informatief programma': 'Informatief',
                                 'reportage': 'Informatief',
                                 'biografie': 'Informatief',
                                 'schooltelevisie ': 'Informatief',
                                 'peuterprogramma': 'Jeugd',
                                 'kleuterprogramma': 'Jeugd',
                                 'tekenfilm': 'Jeugd',
                                 'animatiereeks': 'Jeugd',
                                 'theatershow': 'Kunst en Cultuur',
                                 'concert': 'Muziek',
                                 'musical': 'Muziek',
                                 'weerbericht': 'Nieuws/Actualiteiten',
                                 'verkeersinfo': 'Nieuws/Actualiteiten',
                                 'actualiteitenmagazine': 'Nieuws/Actualiteiten',
                                 'actuele reportage': 'Nieuws/Actualiteiten',
                                 'praatprogramma over de actualiteit': 'Nieuws/Actualiteiten',
                                 'voetbal': 'Sport',
                                 'darts': 'Sport',
                                 'golf': 'Sport',
                                 'wielrennen op de weg': 'Sport',
                                 'baanwielrennen': 'Sport',
                                 'tennis': 'Sport',
                                 'veldrijden': 'Sport',
                                 'volleybal': 'Sport',
                                 'motorcross': 'Sport',
                                 'religieuze uitzending': 'Religieus',
                                 'docusoap': 'Informatief',
                                 'sitcom': 'Serie/Soap'}

        self.tvtvcat = []

        # channels for which to look on rtl.nl
        # RTLL = RTL Lounge, RTLT = RTL Telekids, RTCR = RTL Crime
        self.source_channels[2] = {4: 'RTL4',
                                    31: 'RTL5',
                                    46: 'RTL7',
                                    92: 'RTL8',
                                    408: 'RTLL',
                                    409: 'RTCR',
                                    'rtl-telekids': 'RTLT'}

        # channels for which to look on teveblad.be
        self.source_channels[3] = {5: 'een',
                                            6: 'canvas',
                                            1: 'npo-1',
                                            2: 'npo-2',
                                            3: 'npo-3',
                                            49: 'vtm',
                                            60: 'vier',
                                            59: '2be',
                                            18: 'national-geographic',
                                            4: 'rtl4',
                                            31: 'rtl5',
                                            36: 'sbs6',
                                            20: 'tcm',
                                            21: 'cartoon-network',
                                            19: 'eurosport',
                                            89: 'nickelodeonnl',
                                            90: 'bvn-tv',
                                            15: 'la-une',
                                            16: 'la-deux',
                                            17: 'tv5',
                                            7: 'bbc1-nl',
                                            8: 'bbc2-nl',
                                            300: 'bbc3-nl',
                                            301: 'bbc4-nl',
                                            104: 'bbc-entertainment',
                                            26: 'cnn',
                                            86: 'bbc-world',
                                            9: 'ard',
                                            10: 'zdf',
                                            12: 'wdr',
                                            11: 'rtl',
                                            305: 'discovery-world',
                                            306: 'discovery-science',
                                            438: 'tlc',
                                            439: 'animal',
                                            413: 'historychannel',
                                            417: 'extreme',
                                            461: 'pebbletv',
                                            424: 'disneychannel',
                                            94: 'syfy',
                                            93: '13th-street',
                                            304: 'mgmmoviechannel',
                                            404: 'foxlife',
                                            436: 'eurosport-2',
                                            38: 'arte',
                                            25: 'mtv',
                                            'discovery-vlaanderen': 'discovery',
                                            'vijftv': 'vijf',
                                            'op12': 'op12',
                                            'ketnet': 'ketnet',
                                            'vitaya': 'vitaya',
                                            'acht': 'acht',
                                            'jim': 'jim',
                                            'tmf': 'tmf',
                                            'njam': 'njam',
                                            'life-tv': 'life!tv',
                                            'france-2': 'france-2',
                                            'france-3': 'france-3',
                                            'tf1': 'tf1',
                                            'sudwest-fernsehen': 'swr',
                                            'rai-uno': 'rai',
                                            'tv-e': 'tve',
                                            'espn-america': 'espn',
                                            'espn-classic': 'espn-america',
                                            'prime-star': 'primestar',
                                            'prime-action': 'primeaction',
                                            'prime-fezztival': 'primefezztival',
                                            'prime-series': 'primeseries',
                                            'vtmkzoom': 'vtm-kzoom'}

        # Program group names to exclude from teveblad.be if the counterpart contains details
        self.teveblad_genericnames = ("ochtend- en dagprogramma's",
                                                            "ochtend - en dagprogramma's",
                                                            "nachtprogramma's",
                                                            "kinder-tv",
                                                            "pause")

        # teveblad.be genre translation table
        self.tevecattrans = {'amusement'           : (u'Amusement', u''),
                                 'documentaire'      : (u'Informatief', u'Documentaire'),
                                 'film'                      : (u'Film', u''),
                                 'kinderen'              : (u'Jeugd', u''),
                                 'kunst & cultuur': (u'Kunst en Cultuur', u''),
                                 'magazine'              : (u'Magazine', u''),
                                 'muziek'                  : (u'Muziek', u''),
                                 'nieuws'                  : (u'Nieuws/Actualiteiten', u''),
                                 'reality'                : (u'informatief', u'realityprogramma'),
                                 'serie'                    : (u'Serie/Soap', u''),
                                 'sport'                    : (u'Sport', u''),
                                 'andere'                  : (u'Overige', u'')}

        self.tevecat = {}

        # channels for which to look on npo.nl
        self.source_channels[4] = {'1': u'1',
                                           '2': u'2',
                                           '3': u'3',
                                           'journaal-24': u'4',
                                           '70': u'5',
                                           '410': u'6',
                                           'politiek-24': u'7',
                                           '316': u'8',
                                           '81': u'9',
                                           'zappelin': u'10',
                                           '66': u'11',
                                           '109': u'12',
                                           '108': u'13',
                                           '110': u'14',
                                           '111': u'15',
                                           '112': u'16',
                                           '113': u'17',
                                           '114': u'18',
                                           '100': u'19',
                                           '103': u'20',
                                           '101': u'21',
                                           '102': u'22',
                                           '115': u'23',
                                           '116': u'24'}

        self.npocattrans = {'9': (u'nieuws/actualiteiten', u''),
                                     '10': (u'amusement', u''),
                                     '10,79': (u'amusement', u'komedie'),
                                     '10,84': (u'amusement', u'quiz'),
                                     '10,85': (u'amusement', u'cabaret'),
                                     '11': (u'informatief', u''),
                                     '11,9': (u'nieuws/actualiteiten', u''),
                                     '11,12': (u'informatief', u'religieus'),
                                     '11,19': (u'informatief', u'kunst/cultuur'),
                                     '11,22': (u'informatief', u'natuur'),
                                     '11,28': (u'informatief', u'wetenschap'),
                                     '11,76': (u'informatief', u'reizen'),
                                     '11,77': (u'informatief', u'gezondheid'),
                                     '11,81': (u'informatief', u'consument'),
                                     '11,82': (u'informatief', u'wonen-tuin'),
                                     '11,84': (u'informatief', u'quiz'),
                                     '11,88': (u'informatief', u'kookprogramma'),
                                     '11,89': (u'informatief', u'geschiedenis'),
                                     '12': (u'religieus', u''),
                                     '13': (u'jeugd', u''),
                                     '13,10': (u'jeugd', u'amusement'),
                                     '13,11': (u'jeugd', u'informatief'),
                                     '13,16': (u'jeugd', u'documentaire'),
                                     '13,17': (u'jeugd', u'sport'),
                                     '13,21': (u'jeugd', u'animatieserie'),
                                     '13,22': (u'jeugd', u'natuur'),
                                     '13,24': (u'jeugd', u'muziek'),
                                     '13,25': (u'jeugd', u'film'),
                                     '13,78': (u'jeugd', u'serie'),
                                     '13,84': (u'jeugd', u'quiz'),
                                     '14': (u'serie/soap', u''),
                                     '15': (u'overige', u''),
                                     '16': (u'documentaire', u''),
                                     '16,12': (u'documentaire', u'religieus'),
                                     '16,19': (u'documentaire', u'kunst/cultuur'),
                                     '16,22': (u'documentaire', u'natuur'),
                                     '16,28': (u'documentaire', u'wetenschap'),
                                     '16,76': (u'documentaire', u'reizen'),
                                     '16,89': (u'documentaire', u'geschiedenis'),
                                     '17': (u'sport', u''),
                                     '17,86': (u'sport', u'journaal'),
                                     '18': (u'serie/soap', u'misdaadserie'),
                                     '19': (u'kunst/cultuur', u''),
                                     '20': (u'amusement', u'erotisch programma'),
                                     '21': (u'serie/soap', u'animatieserie'),
                                     '22': (u'natuur', u''),
                                     '23': (u'amusement', u'komedie'),
                                     '24': (u'muziek', u''),
                                     '24,83': (u'muziek', u'populair'),
                                     '24,87': (u'muziek', u'klassiek'),
                                     '25': (u'film', u''),
                                     '25,21': (u'film', u'animatieserie'),
                                     '25,31': (u'film', u'drama'),
                                     '25,79': (u'film', u'komisch'),
                                     '26': (u'educatief', u''),
                                     '27': (u'informatief', u'fitnessprogramma'),
                                     '28': (u'wetenschap', u''),
                                     '29': (u'jeugd', u'6-12'),
                                     '30': (u'maatschappij', u''),
                                     '31': (u'serie/soap', u'drama'),
                                     '32': (u'jeugd', u'2-5'),
                                     '34': (u'muziek', u'klassiek'),
                                     '76': (u'reizen', u''),
                                     '77': (u'gezondheid-opvoeding', u''),
                                     '78': (u'serie/soap', u''),
                                     '78,31': (u'serie/soap', u'drama'),
                                     '78,79': (u'serie/soap', u'komisch'),
                                     '78,80': (u'serie/soap', u'spanning'),
                                     '78,91': (u'serie/soap', u'soap'),
                                     '79': (u'komisch', u''),
                                     '80': (u'spanning', u''),
                                     '81': (u'consumenten-informatie', u''),
                                     '82': (u'wonen-tuin', u''),
                                     '83': (u'muziek-populair', u''),
                                     '84': (u'spel-quiz', u''),
                                     '85': (u'cabaret', u''),
                                     '86': (u'sport-informatie', u''),
                                     '87': (u'muziek-klassiek', u''),
                                     '88': (u'koken-eten', u''),
                                     '89': (u'geschiedenis', u''),
                                     '90': (u'sport-wedstrijd', u''),
                                     '91': (u'soap-serie', u'')}

        self.npo_fill = 'Programmainfo en Reclame'

        #Channel group names as used in tvgids.tv
        self.chan_groups = {1: 'Nederlands',
                                          2: 'Vlaams',
                                          3: 'Engels',
                                          4: 'Duits',
                                          5: 'Frans',
                                          6: 'Nederlands Regionaal',
                                          7: 'Nederlands Overig',
                                          8: 'Vlaams Overig',
                                          9: 'Internationaal',
                                         10: 'Overig'}

        self.group_names = {1: 'Nederlandse kanalen',
                                          2: 'Vlaamse kanalen',
                                          3: 'Engelse kanalen',
                                          4: 'Duitse kanalen',
                                          5: 'Franse kanalen',
                                          6: 'Nederlands Regionaal',
                                          7: 'Overige Nederlands kanalen',
                                          8: 'Overige Vlaamse kanalen ',
                                          9: 'Internationale kanalen',
                                         10: 'Overig kanalen',
                                         -1: 'Alleen geselecteerde kanalen'}

        # DO NOT CHANGE THIS!
        self.configversion = None
        self.__CONFIG_SECTIONS__ = { 1: u'Configuration',
                                                            2: u'tvgids.nl Channels',
                                                            3: u'Channels'}

        self.__CHANNEL_CONFIG_SECTIONS__ = {}

        self.__DEFAULT_SECTIONS__ = {1: u'genre conversion table',
                                                             2: u'no title split list',
                                                             3: u'remove groupname list',
                                                             4: u'rename title list',
                                                             5: u'teveblad.be genres',
                                                             6: u'tvgids.tv genres',
                                                             7: u'role translation'}

        self.sources = {}
        self.detail_ids = []

    # end Init()

    def version(self, as_string = False):
        """
        return tuple or string with version info
        """
        if as_string and self.alfa:
            return u'%s (Version: %s.%s.%s-p%s-alpha)' % (self.name, self.major, self.minor, self.patch, self.patchdate)

        if as_string and self.beta:
            return u'%s (Version: %s.%s.%s-p%s-beta)' % (self.name, self.major, self.minor, self.patch, self.patchdate)

        if as_string and not self.beta:
            return u'%s (Version: %s.%s.%s-p%s)' % (self.name, self.major, self.minor, self.patch, self.patchdate)

        else:
            return (self.name, self.major, self.minor, self.patch, self.patchdate, self.beta)

    # end version()

    def save_oldfile(self, file):
        """ save the old file to .old if it exists """
        try:
            os.rename(file, file + '.old')

        except Exception as e:
            pass

    # end save_old()

    def open_file(self, file_name, mode = 'rb', encoding = None):
        """ Open a file and return a file handler if success """
        if encoding == None:
            encoding = self.file_encoding

        try:
            if 'b' in mode:
                file_handler =  io.open(file_name, mode = mode)
            else:
                file_handler =  io.open(file_name, mode = mode, encoding = encoding)

        except IOError as e:
            if e.errno == 2:
                log('File: "%s" not found.\n' % file_name)
            else:
                log('File: "%s": %s.\n' % (file_name, e.strerror))
            return None

        return file_handler

    # end open_file ()

    def get_line(self, file, byteline, isremark = False, encoding = None):
        """
        Check line encoding and if valid return the line
        If isremark is True or False only remarks or non-remarks are returned.
        If None all are returned
        """
        if encoding == None:
            encoding = self.file_encoding

        try:
            line = byteline.decode(encoding)
            line = line.lstrip()
            line = line.replace('\n','')
            if isremark == None:
                return line

            if len(line) == 0:
                return False

            if isremark and line[0:1] == '#':
                return line

            if not isremark and not line[0:1] == '#':
                return line

        except UnicodeError:
            log('%s is not encoded in %s.\n' % (file.name, encoding))

        return False

    # end get_line()

    def check_encoding(self, file, encoding = None, check_version = False):
        """
        Check file encoding. Return True or False
        Encoding is stored in self.encoding
        Optionally check for a version string
        and store it in self.configversion
        """
        # regex to get the encoding string
        reconfigline = re.compile(r'#\s*(\w+):\s*(.+)')

        self.encoding = None
        self.configversion = None

        if encoding == None:
            encoding = self.file_encoding

        for byteline in file.readlines():
            line = self.get_line(file, byteline, True, self.encoding)
            if not line:
                continue

            else:
                match = reconfigline.match(line)
                if match is not None and match.group(1) == "encoding":
                    encoding = match.group(2)

                    try:
                        codecs.getencoder(encoding)
                        self.encoding = encoding

                    except LookupError:
                        log('%s has invalid encoding %s.\n' % (file.name, encoding))
                        return False

                    if (not check_version) or self.configversion != None:
                        return True

                    continue

                elif match is not None and match.group(1) == "configversion":
                    self.configversion = float(match.group(2))
                    if self.encoding != None:
                        return True

                continue

        if check_version and self.configversion == None:
            file.seek(0,0)
            for byteline in file.readlines():
                line = self.get_line(file, byteline, False, self.encoding)
                if not line:
                    continue

                else:
                    config_title = re.search('[(.*?)]', line)
                    if config_title != None:
                        self.configversion = float(2.0)
                        break

            else:
                self.configversion = float(1.0)

        if self.encoding == None:
            return False

        else:
            return True

    # end check_encoding()

    def read_commandline(self):
        """Initiate argparser and read the commandline"""
        self.description = 'The Netherlands: %s\n' % self.version(True) + \
                        '  A grabber that grabs tvguide data from tvgids.nl, tvgids.tv, rtl.nl and\n' + \
                        '  teveblad.be for up to 178+ channels and up to 14 days. Which it then stores\n' + \
                        '  in XMLTV-compatible format.'

        parser = argparse.ArgumentParser(description = self.description, formatter_class=argparse.RawTextHelpFormatter)

        parser.add_argument('-V', '--version', action = 'store_true', default = False, dest = 'version',
                        help = 'display version')

        parser.add_argument('--description', action = 'store_true', default = False, dest = 'description',
                        help = 'prints the above short description of the grabber')

        parser.add_argument('-d', '--long-descr', action = 'store_true', default = False, dest = 'description_long',
                        help = 'prints a long description in english of the grabber')

        parser.add_argument('--capabilities', action = 'store_true', default = False, dest = 'capabilities',
                        help = 'xmltv required option')

        parser.add_argument('--preferredmethod', action = 'store_true', default = False, dest = 'preferredmethod',
                        help = 'returns the preferred method to be called')

        parser.add_argument('-x', '--compat', action = 'store_true', default = None, dest = 'compat',
                        help = 'append tvgids.nl to the xmltv id\n(use this if you were using tv_grab_nl)')

        parser.add_argument('-u', '--utc', action = 'store_true', default = None, dest = 'use_utc',
                        help = 'generate all data in UTC time (use with timezone "auto"\nin mythtv)')

        parser.add_argument('-c', '--configure', action = 'store_true', default = False, dest = 'configure',
                        help = 'create configfile; rename an existing file to *.old.')

        parser.add_argument('-C', '--config-file', type = str, default = self.config_file, dest = 'config_file',
                        metavar = '<file>',
                        help = 'name of the configuration file\n<default = \'%s\'>' % self.config_file)

        parser.add_argument('-O', '--save-options', action = 'store_true', default = False, dest = 'save_options',
                        help = 'save the currently defined options to the config file\n' +
                                    'add options to the command-line to adjust the file.')

        parser.add_argument('-A', '--cache', type = str, default = self.program_cache_file, dest = 'program_cache_file',
                        metavar = '<file>',
                        help = 'cache descriptions and use the file to store\n<default = \'%s\'>' % self.program_cache_file)

        parser.add_argument('-S', '--cache-save-interval', type = int, default = None, dest = 'cache_save_interval',
                        metavar = '<number>',
                        help = 'after how many fetches to save the cache <Default %s>' % self.opt_dict['cache_save_interval'])

        parser.add_argument('--clean_cache', action = 'store_true', default = self.clean_cache, dest = 'clean_cache',
                        help = 'clean the cache of outdated data before fetching')

        parser.add_argument('--clear_cache', action = 'store_true', default = self.clear_cache, dest = 'clear_cache',
                        help = 'empties the cache file before fetching data')

        parser.add_argument('-W', '--output', type = str, default = None, dest = 'output_file',
                        metavar = '<file>',
                        help = 'file where to send the output <default to the screen>')

        parser.add_argument('-q', '--quiet', action = 'store_true', default = None, dest = 'quiet',
                        help = 'suppress all output.')

        parser.add_argument('-v', '--verbose', action = 'store_false', default = None, dest = 'quiet',
                        help = 'Sent log-info also to the screen.')

        parser.add_argument('-f', '--fast', action = 'store_true', default = None, dest = 'fast',
                        help = 'do not grab details of programming (tvgids.nl/tv)')

        parser.add_argument('-s', '--slow', action = 'store_false', default = None, dest = 'fast',
                        help = '<default> grab details of programming (tvgids.nl/tv)')

        parser.add_argument('-o', '--offset', type = int, default = None, dest = 'offset',
                        metavar = '<days>',
                        help = 'The day to start grabbing <defaults to 0 is today>')

        parser.add_argument('-g', '--days', type = int, default = None, dest = 'days',
                        metavar = '<days>',
                        help = '# number of days to grab from tvgids.nl/tvgids.tv\nstarting from offset. <max 14 = default>\n' +
                                     'The first 4 are grabed from tvgids.nl.\nThe rest plus failures from tvgids.tv\n')

        parser.add_argument('-G', '--slowdays', type = int, default = None, dest = 'slowdays',
                        metavar = '<days>',
                        help = 'number of days to grab slow and the rest in fast mode\nDefaults to all days (tvgids.nl/tv)')

        parser.add_argument('-r', '--rtldays', type = int, default = None, dest = 'rtldays',
                        metavar = '<days>',
                        help = '# number of days to grab from rtl.nl\nstarting from offset. (max 14 = default)')

        parser.add_argument('-b', '--tevedays', type = int, default = None, dest = 'tevedays',
                        metavar = '<days>',
                        help = '# number of days to grab from teveblad.be\nstarting from offset. (max 7 = default)')

        parser.add_argument('-N', '--nouse-NPO', action = 'store_false', default = None, dest = 'use_npo',
                        help = 'do not use NPO.nl for more acurate timing,\nThis is for the NPO and dutch regional channels')

        parser.add_argument('--logos', action = 'store_true', default = None, dest = 'logos',
                        help = '<default> insert urls to channel icons\n(mythfilldatabase will then use these)')

        parser.add_argument('-n', '--nologos', action = 'store_false', default = None, dest = 'logos',
                        help = 'do not insert urls to channel icons')

        parser.add_argument('-H', '--mark-HD', action = 'store_true', default = None, dest = 'mark_hd',
                        help = 'mark HD programs,\ndo not set if you only record analog SD')

        parser.add_argument('--cattrans', action = 'store_true', default = None, dest = 'cattrans',
                        help = '<default> translate the grabbed genres into\nMythTV-genres. See the tv_grab_nl_py.set file')

        parser.add_argument('-t', '--nocattrans', action = 'store_false', default = None, dest = 'cattrans',
                        help = 'do not translate the grabbed genres into MythTV-genres.\n' +
                                    'it then only uses the basic genres without possibility\n' +
                                     'to differentiate on subgenre.')

        parser.add_argument('-l ', '--desc-length', type = int, default = None, dest = 'desc_length',
                        metavar = '<bytes>',
                        help = 'maximum allowed length of program descriptions in bytes.')

        parser.add_argument('-a', '--overlap_strategy', type = str, default = None, dest = 'overlap_strategy',
                        metavar = '<strategy>',
                        help = 'what strategy to use to correct overlaps:\n' +
                                     '\'avarage\' use average of stop and start of next program.\n          <default>\n' +
                                     '\'stop\'    keep stop time of current program and adjust\n          start time.\n' +
                                     '\'start\'   keep start time of next program and adjust\n          stop time.\n' +
                                     '\'none\'    do not use any strategy and see what happens.\n')

        parser.add_argument('-m', '--max_overlap', type = int, default = None, dest = 'max_overlap',
                        metavar = '<minutes>',
                        help = 'maximum length of overlap between programming to correct\n<default 10 minutes>')

        # Handle the sys.exit(0) exception on --help more gracefull
        try:
            self.args = parser.parse_args()

        except:
            return(0)

    # end read_commandline()

    def read_config(self):
        """Read the configurationfile Return False on failure."""
        f = self.open_file(self.config_file)
        if f == None:
            log('Re-run me with the --configure flag.\n')
            return False

        if not self.check_encoding(f, None, True):
            return False

        if self.configversion == 1.0:
            type = 2
            section = self.__CONFIG_SECTIONS__[2]

        else:
            type = 0
            section = ''

        f.seek(0,0)
        for byteline in f.readlines():
            try:
                line = self.get_line(f, byteline, None, self.encoding)
                if not line:
                    continue

                if line[0:1] == '#' and type != 3:
                    continue

                # Look for section headers
                config_title = re.search('\[(.*?)\]', line)
                if config_title != None and (config_title.group(1) in self.__CONFIG_SECTIONS__.values()):
                    section = config_title.group(1)
                    for i, v in self.__CONFIG_SECTIONS__.items():
                        if v == config_title.group(1):
                            type = i
                            continue

                    continue

                elif config_title != None and (config_title.group(1) in self.__CHANNEL_CONFIG_SECTIONS__.keys()):
                    section = config_title.group(1)
                    type = 9
                    chanid = self.__CHANNEL_CONFIG_SECTIONS__[config_title.group(1)]
                    continue

                # Unknown Section header, so ignore
                if line[0:1] == '[':
                    type = 0
                    continue

                # Read Configuration options
                if type == 1:
                    try:
                        # Strip the name from the value
                        a = re.split('=',line)
                        # Boolean Values
                        if a[0].lower().strip() in ('write_info_files', 'quiet', 'fast', 'compat', 'logos', 'cattrans', 'mark_hd', 'use_utc', 'use_npo'):
                            if len(a) == 1:
                                self.opt_dict[a[0].lower().strip()] = True

                            elif a[1].lower().strip() in ('true', '1' , 'on'):
                                self.opt_dict[a[0].lower().strip()] = True

                            else:
                                self.opt_dict[a[0].lower().strip()] = False

                        elif a[0].lower().strip() == 'output_file':
                            self.opt_dict['output_file'] = None if (len(a) == 1 or a[1].lower().strip() == 'none') else a[1].strip()

                        elif len(a) == 2:
                            # Integer Values
                            if a[0].lower().strip() in ('log_level', 'match_log_level', 'offset', 'days', 'slowdays', 'rtldays', \
                              'tevedays', 'max_overlap', 'desc_length', 'cache_save_interval'):
                                try:
                                    int(a[1])

                                except ValueError:
                                    if (a[0].lower().strip() == 'slowdays') and (a[1].lower().strip() == 'none'):
                                        self.opt_dict[a[0].lower().strip()] = None

                                else:
                                    self.opt_dict[a[0].lower().strip()] = int(a[1])

                            # Select Values
                            elif a[0].lower().strip() == 'overlap_strategy':
                                if a[1].lower().strip() in ('average', 'stop', 'start'):
                                    self.opt_dict[a[0].lower().strip()] = a[1].lower().strip()

                                else:
                                    self.opt_dict[a[0].lower().strip()] = 'none'

                    except Exception:
                        log('Invalid line in %s section of config file %s: %r\n' % (section, self.config_file, line))

                # Read the channel stuff up to version 2.0
                if type == 2:
                    if self.configversion > 2.0:
                        continue

                    try:
                        channel = line.split(None, 1) # split on first whitespace
                        self.channels[unicode(channel[0]).strip()] = Channel_Config(unicode(channel[0]).strip(), unicode(channel[1]).strip())
                        self.channels[unicode(channel[0]).strip()].active = True
                        self.__CHANNEL_CONFIG_SECTIONS__[u'Channel %s' % channel[0].strip()] = unicode(channel[0]).strip()

                    except Exception:
                        log('Invalid line in %s section of config file %s: %r\n' % (section, self.config_file, line))

                # Changed Channel config since version 2.1
                if type == 3:
                    if self.configversion < 2.1:
                        continue

                    try:
                        if line[0:1] == '#':
                            active = False
                            line = line.lstrip('#').lstrip()

                        else:
                            active = True

                        channel = re.split(';', line)
                        if len(channel) != 8:
                            continue

                        for index in range(xml_output.source_count):
                            if channel[index + 2].strip() != '':
                                chanid = unicode(channel[index + 2]).strip()
                                self.__CHANNEL_CONFIG_SECTIONS__[u'Channel %s' % channel[index + 2].strip()] = chanid
                                break

                        else:
                            # No sources!
                            continue

                        self.channels[chanid] = Channel_Config(chanid, unicode(channel[0]).strip(), int(channel[1]))
                        for index in range(xml_output.source_count):
                            self.channels[chanid].source_id[index] = unicode(channel[index + 2]).strip()

                        self.channels[chanid].icon_source = int(channel[6])
                        self.channels[chanid].icon = unicode(channel[7]).strip()
                        # set the default prime_source
                        if channel [4] != '':
                            self.channels[chanid].opt_dict['prime_source'] = 2

                        elif (channel [5] != '') and ((int(channel[1]) == 2) or (int(channel[1]) == 8)):
                            self.channels[chanid].opt_dict['prime_source'] = 3

                        else:
                            for index in (0, 1, 3):
                                if self.channels[chanid].source_id[index] != '':
                                    self.channels[chanid].opt_dict['prime_source'] = index
                                    break

                        self.channels[chanid].active = active
                        if active:
                            self.chan_count += 1

                    except Exception:
                        log('Invalid line in %s section of config file %s: %r\n' % (section, self.config_file, line))

                # Read the channel specific configuration
                if type == 9:
                    try:
                        # Strip the name from the value
                        a = re.split('=',line)
                        # Boolean Values
                        if a[0].lower().strip() in ('fast', 'compat', 'logos', 'cattrans', 'mark_hd', 'add_hd_id', 'append_tvgidstv', 'use_npo'):
                            if len(a) == 1:
                                self.channels[chanid].opt_dict[a[0].lower().strip()] = True

                            elif a[1].lower().strip() in ('true', '1' , 'on'):
                                self.channels[chanid].opt_dict[a[0].lower().strip()] = True

                            else:
                                self.channels[chanid].opt_dict[a[0].lower().strip()] = False

                        elif len(a) == 2:
                            # Integer Values
                            if a[0].lower().strip() in ('slowdays', 'max_overlap', 'desc_length', 'prime_source', 'prefered_description'):
                                try:
                                    int(a[1])

                                except ValueError:
                                    if (a[0].lower().strip() == 'slowdays') and (a[1].lower().strip() == 'none'):
                                        self.channels[chanid].opt_dict[a[0].lower().strip()] = None

                                else:
                                    if a[0].lower().strip() == 'prime_source' or a[0].lower().strip() == 'prefered_description':
                                        if self.channels[chanid].source_id[int(a[1])] != '':
                                            self.channels[chanid].opt_dict[a[0].lower().strip()] = int(a[1])

                                    else:
                                        self.channels[chanid].opt_dict[a[0].lower().strip()] = int(a[1])

                            # Select Values
                            elif a[0].lower().strip() == 'overlap_strategy':
                                if a[1].lower().strip() in ('average', 'stop', 'start'):
                                    self.channels[chanid].opt_dict[a[0].lower().strip()] = a[1].lower().strip()

                                else:
                                    self.channels[chanid].opt_dict[a[0].lower().strip()] = 'none'

                    except Exception:
                        log('Invalid line in %s section of config file %s: %r\n' % (section, self.config_file, line))

            except Exception as e:
                log(u'Error reading Config\n')
                continue

        f.close()

        # an extra option for gathering extra info to better the code
        if 'write_info_files' in self.opt_dict.keys():
            self.write_info_files = self.opt_dict['write_info_files']
            if self.write_info_files :
                infofiles.open_files()

        return True
    # end read_config()

    def read_defaults_list(self):
        """
        Get the genre conversion table, the title split exception list and others
        """
        f = self.open_file(self.settings_file)
        if f == None:
            return False

        if not self.check_encoding(f):
            return False

        f.seek(0,0)
        type = 0
        for byteline in f.readlines():
            try:
                line = self.get_line(f, byteline, False, self.encoding)
                if not line:
                    continue

                # Look for section headers
                config_title = re.search('\[(.*?)\]', line)
                if config_title != None and (config_title.group(1) in self.__DEFAULT_SECTIONS__.values()):
                    for i, v in self.__DEFAULT_SECTIONS__.items():
                        if v == config_title.group(1):
                            type = i
                            continue

                    # Ignore the defaults if section exists
                    if type == 3:
                        self.groupnameremove = []

                    elif type == 4:
                        self.titlerename = {}

                    continue

                # Unknown Section header, so ignore
                if line[0:1] == '[':
                    type = 0
                    continue

                if type == 1:
                    # split of the translation (if present) or supply an empty one
                    a = re.split('=',line)
                    if len(a) == 1:
                        a.append('')

                    # split main and sub-genre (if present) and if they have a translation
                    # (overwriting the default) or are not yet pressent add them to cattrans
                    g = re.split(':', a[0].lower() )
                    if len(g) == 2:
                        if not ((g[0].strip(), g[1].strip()) in self.cattrans and a[1].strip() == ''):
                            self.cattrans[ (g[0].strip(), g[1].strip())] = a[1].strip()

                    elif len(g) == 1:
                        if not ((g[0].strip(), g[1].strip()) in self.cattrans and a[1].strip() == ''):
                            self.cattrans[ (g[0].strip(), '')] = a[1].strip()

                elif type == 2:
                    line = line.lower()
                    if not line in self.notitlesplit:
                        self.notitlesplit.append(line)

                elif type == 3:
                    line = line.lower()
                    if not line in self.groupnameremove:
                        self.groupnameremove.append(line)

                elif type == 4:
                    # split of the translation (if present) or supply an empty one
                    a = re.split('=',line)
                    if len(a) == 1:
                        continue

                    self.titlerename[a[0].lower().strip()] = a[1].strip()

                elif type == 5:
                    # split of the translation (if present) or supply an empty one
                    a = re.split('=',line)
                    if len(a) == 1:
                        self.tevecattrans[a[0].lower().strip()] = (u'Overige', u'')
                        continue

                    # split main and sub-genre (if present) and add or overwrite the default
                    g = re.split(':', a[1].lower() )
                    if len(g) == 2:
                        self.tevecattrans[a[0].lower().strip()] = (g[0].strip(), g[1].strip())
                        continue

                    self.tevecattrans[a[0].lower().strip()] = (g[0].strip(), u'')

                elif type == 6:
                    # split of the translation (if present) or supply an empty one
                    a = re.split('=',line)
                    if len(a) == 1:
                        continue
                    self.tvtvcattrans[a[1].lower().strip()] = a[0].strip()

                elif type == 7:
                    # split of the translation (if present) or supply an empty one
                    a = re.split('=',line)
                    if len(a) == 1:
                        continue
                    self.roletrans[a[0].lower().strip()] = a[1].strip()

            except Exception as e:
                log('Error reading Defaults\n')
                continue

        f.close()
        return True

    #end read_defaults_list()

    def get_channels(self):
        """
        Get a list of all available channels and store these
        in a file.
        """
        # These channels contain no data!
        empty_channels = {}
        empty_channels[0] = ('83','308','309','310','20','65','401','403','412')
        empty_channels[1] = ('eurosport-hd', 'la-une-hd', 'tf1-hd', 'vtm-hd', 'nat-geo-hd', 'tmf', 'life-tv', \
            'espn-america', 'espn-classic', 'canal-z', 'disney-playhouse', 'exqi-sport-culture', \
            'prime-sport', 'vitaliteit', 'vtmkzoom-2', 'ketnet-op12', 'cnbc-europe', 'virgin-1')
        empty_channels[2] = []
        empty_channels[3] = ('rtl4', 'rtl5', 'sbs6', 'tv5monde-europe', 'cnn', 'tcm', 'cartoon-network', \
            'rtp-international', 'foxlife', 'discovery-id', 'studio100-tv', 'fashion-one', 'tnt-benelux', \
            'historychannel', 'nickelodeonnl', 'bbc-world', 'mgmmoviechannel', 'discovery-world', \
            'discovery-science', 'sport-10', 'culture-7', 'espn', 'pebbletv', 'lacht', '13th-street', \
            'live!tv', 'stories', 'op12', 'actua-tv', 'espn-america', 'swr', '', 'mtv', 'tmf', 'cultuur-7')
        # download the json feed
        xml_output.channelsource[0].init_channels()
        xml_output.channelsource[0].get_channels()
        if not isinstance(self.channels, dict):
            self.channels = {}

        for chanid in xml_output.channelsource[0].all_channels.keys():
            if (chanid.lower() in empty_channels[0]):
                continue

            if not chanid in self.channels.keys():
                self.channels[chanid] = Channel_Config(chanid, xml_output.channelsource[0].all_channels[chanid]['name'])

            self.channels[chanid].source_id[0] = chanid
            if int(chanid) in xml_output.logo_names:
                self.channels[chanid].icon_source = xml_output.logo_names[int(chanid)][0]
                if xml_output.logo_names[int(chanid)][0] == 4:
                    self.channels[chanid].icon = xml_output.logo_names[int(chanid)][1] + '.png'

                else:
                    self.channels[chanid].icon = xml_output.logo_names[int(chanid)][1] + '.gif'

        # Get the other sources
        for index in (1, 3, 2):
            xml_output.channelsource[index].init_channels()
            xml_output.channelsource[index].get_channels()
            reverse_channels = {}
            for i, v in self.source_channels[index].items():
                reverse_channels[v] = unicode(i)

            for chanid in xml_output.channelsource[index].all_channels.keys():
                if chanid in self.source_channels[index].values() and reverse_channels[chanid] in self.channels.keys():
                    # These channels are for show, but we like the icons from source 2 and 3!
                    if not(chanid in empty_channels[index]):
                        self.channels[reverse_channels[chanid]].source_id[index] = chanid

                    # Set the group
                    if self.channels[reverse_channels[chanid]].group == 10:
                        self.channels[reverse_channels[chanid]].group = xml_output.channelsource[index].all_channels[chanid]['group']

                    # Set the Icon
                    if index == 3:
                        self.channels[reverse_channels[chanid]].icon_source = 2
                        self.channels[reverse_channels[chanid]].icon = xml_output.channelsource[index].all_channels[chanid]['icon']

                    elif index == 2 and (self.channels[reverse_channels[chanid]].icon_source == -1 or self.channels[reverse_channels[chanid]].icon_source == 1):
                        self.channels[reverse_channels[chanid]].icon_source = 3
                        self.channels[reverse_channels[chanid]].icon = xml_output.channelsource[2].all_channels[chanid]['icon']

                else:
                    if (chanid in empty_channels[index]):
                        continue

                    self.channels[chanid] = Channel_Config(chanid, xml_output.channelsource[index].all_channels[chanid]['name'])
                    self.channels[chanid].source_id[index] = chanid
                    self.channels[chanid].group = xml_output.channelsource[index].all_channels[chanid]['group']
                    if index == 3:
                        self.channels[chanid].icon_source = 2
                        self.channels[chanid].icon = xml_output.channelsource[index].all_channels[chanid]['icon']

                    elif index == 2 and (self.channels[chanid].icon_source == -1 or self.channels[chanid].icon_source == 1):
                        self.channels[chanid].icon_source = 3
                        self.channels[chanid].icon = xml_output.channelsource[2].all_channels[chanid]['icon']

        for channel in self.channels.values():
            # Set a source 4 icon if present and not allready set to 0 or 2
            if channel.icon_source in (-1, 1, 3) and channel.chanid in xml_output.logo_names.keys() \
              and xml_output.logo_names[channel.chanid][0] == 4:
                channel.icon_source = 4
                channel.icon = '%s.png' % xml_output.logo_names[channel.chanid][1]

            # mark HD channels
            if channel.chan_name[-3:].lower() == ' hd':
                channel.opt_dict['mark_hd'] = True

            if channel.source_id[3] != '' and xml_output.channelsource[3].all_channels[channel.source_id[3]]['HD']:
                channel.opt_dict['mark_hd'] = True

            # set the default prime_source
            if channel.source_id[2] != '':
                channel.opt_dict['prime_source'] = 2

            elif (channel.source_id[3] != '') and ((channel.group == 2) or (channel.group == 8)) :
                channel.opt_dict['prime_source'] = 3

            else:
                for index in (0, 1, 3):
                    if channel.source_id[index] != '':
                        channel.opt_dict['prime_source'] = index
                        break

            # For Veronica tvgids.tv contains Disney XD, so we don't append it
            if channel.source_id[0] in ('3', '34'):
                channel.opt_dict['append_tvgidstv'] = False

        return 0

    # end get_channels()

    def validate_commandline(self):
        """Read the commandline and validate the values"""
        if self.read_commandline() == 0:
             return(0)

        if self.args.version:
            print("The Netherlands: %s" % self.version(True))
            return(0)

        if self.args.description:
            v=self.version()
            if v[5]:
                print("Dutch/Flemish grabber combining multiple sources. v%s.%s.%s-beta" % (v[1], v[2], v[3]))

            else:
                print("Dutch/Flemish grabber combining multiple sources. v%s.%s.%s" % (v[1], v[2], v[3]))

            return(0)

        if self.args.description_long:
            print("The Netherlands: %s" % self.version(True))
            print(description_text)
            return(0)

        if self.args.capabilities:
            print("baseline")
            print("cache")
            print("manualconfig")
            print("preferredmethod")
            return(0)

        if self.args.preferredmethod:
            print('allatonce')
            return(0)

        if self.args.config_file != self.config_file:
            # use the provided name for configuration and logging
            self.config_file = self.args.config_file
            self.log_file = self.args.config_file+'.log'
            log('Using config file: %s\n' % self.args.config_file)

        if self.validate_option('log_file') != None:
            return(2)

        if self.args.configure:

            # check for the config dir
            config_dir = os.path.dirname(self.config_file)
            if (config_dir != '') and not os.path.exists(config_dir):
                log('Creating %s directory,\n' % config_dir)
                os.mkdir(config_dir)

            elif os.access(self.config_file, os.F_OK):
                self.read_config()

            log('Creating config file: %s\n' % self.config_file)
            x = self.get_channels()

        # get config if available Overrule if set by commandline
        elif not self.read_config():
            return(1)

        if self.args.cache_save_interval != None:
            self.opt_dict['cache_save_interval'] = self.args.cache_save_interval

        if self.args.quiet != None:
            self.opt_dict['quiet'] = self.args.quiet

        if self.args.use_utc != None:
            self.opt_dict['use_utc'] = self.args.use_utc

        if self.args.compat != None:
            self.opt_dict['compat'] = self.args.compat
            for chanid in self.channels.keys():
                self.channels[chanid].opt_dict['compat'] = self.opt_dict['compat']

        if self.args.fast != None:
            self.opt_dict['fast'] = self.args.fast
            for chanid in self.channels.keys():
                self.channels[chanid].opt_dict['fast'] = self.opt_dict['fast']

        if self.args.logos != None:
            self.opt_dict['logos'] = self.args.logos
            for chanid in self.channels.keys():
                self.channels[chanid].opt_dict['logos'] = self.opt_dict['logos']

        if self.args.mark_hd != None:
            self.opt_dict['mark_hd'] = self.args.mark_hd
            for chanid in self.channels.keys():
                self.channels[chanid].opt_dict['mark_hd'] = self.opt_dict['mark_hd']

        if self.args.cattrans != None:
            self.opt_dict['cattrans'] = self.args.cattrans
            for chanid in self.channels.keys():
                self.channels[chanid].opt_dict['cattrans'] = self.opt_dict['cattrans']

        if self.args.slowdays != None:
            self.opt_dict['slowdays'] = self.args.slowdays
            for chanid in self.channels.keys():
                self.channels[chanid].opt_dict['slowdays'] = self.opt_dict['slowdays']

        if self.args.desc_length != None:
            self.opt_dict['desc_length'] = self.args.desc_length
            for chanid in self.channels.keys():
                self.channels[chanid].opt_dict['desc_length'] = self.opt_dict['desc_length']

        if self.args.overlap_strategy != None:
            self.opt_dict['overlap_strategy'] = self.args.overlap_strategy
            for chanid in self.channels.keys():
                self.channels[chanid].opt_dict['overlap_strategy'] = self.opt_dict['overlap_strategy']

        if self.args.max_overlap != None:
            self.opt_dict['max_overlap'] = self.args.max_overlap
            for chanid in self.channels.keys():
                self.channels[chanid].opt_dict['max_overlap'] = self.opt_dict['max_overlap']

        if self.args.output_file != None:
            self.opt_dict['output_file'] = self.args.output_file

        if self.args.use_npo != None:
            self.opt_dict['use_npo'] = self.args.use_npo
            for chanid in self.channels.keys():
                self.channels[chanid].opt_dict['use_npo'] = self.opt_dict['use_npo']

        # limit days to maximum supported by the several sites
        if self.args.offset != None:
            self.offset = self.opt_dict['offset']
            self.opt_dict['offset'] = self.args.offset

        if self.args.days != None:
            self.opt_dict['days'] = self.args.days

        if self.args.tevedays != None:
            self.opt_dict['tevedays'] = self.args.tevedays

        if self.args.rtldays != None:
            self.opt_dict['rtldays'] = self.args.rtldays

        self.validate_option('offset')
        self.validate_option('days')
        self.validate_option('tevedays')
        self.validate_option('rtldays')
        if self.validate_option('output_file') != None:
            return(2)

        if not self.args.configure and self.configversion < 2.1:
            # Update to a version 2.1 config
            if self.configversion == 1.0:
                self.write_defaults_list()
            if not self.write_config(None):
                log('Error updating to new Config.\nPlease remove the old config and Re-run me with the --configure flag.\n')
                return(1)

            log('Updated the configfile %s!\nCheck if you are fine with the settings.\n' % self.config_file)
            log('If this is a first install, you have to enable the desired channels!\n', 1, 1)
            return(0)

        # Continue validating the settings for the individual channels
        for chanid in self.channels.keys():
            self.channels[chanid].validate_settings()

        self.write_opts_to_log()
        if self.args.configure:
            if not self.write_config(True):
                log('Error writing new Config. Trying to restore an old one.\n')
                try:
                    os.rename(file + '.old', file)

                except:
                    pass

                return(1)

            log('Created the configfile %s!\nCheck if you are fine with the settings.\n' % self.config_file)
            log('If this is a first install, you have to enable the desired channels!\n', 1, 1)
            return(0)

        if self.args.save_options:
            if not self.write_config(False):
                log('Error writing new Config. Trying to restore an old one.\n')
                try:
                    os.rename(file + '.old', file)

                except:
                    pass

                return(1)

            log('Updated the options in the configfile %s!\nCheck if you are fine with the settings.\n' % self.config_file)
            return(0)

        #check for cache
        if self.args.clean_cache != self.clean_cache:
            self.clean_cache = self.args.clean_cache

        if self.args.clear_cache != self.clear_cache:
            self.clear_cache = self.args.clear_cache

        if self.args.program_cache_file != self.program_cache_file:
            self.program_cache_file = self.args.program_cache_file

        if self.validate_option('program_cache_file') != None:
            return(2)

        self.read_defaults_list()

    # end validate_commandline()

    def validate_option(self, option, channel = config):
        """Validate an option"""
        if option == 'offset':
            if self.opt_dict['offset'] > 14:
                if self.offset < 14:
                    log("Een zo hoge offset van: %s is belachelijk. We resetten naar %s\n" % (self.opt_dict['offset'], self.offset),1,1)
                    self.opt_dict['offset'] = self.offset

                else:
                    log("Een zo hoge offset van: %s is belachelijk. We resetten naar 0\n" % (self.opt_dict['offset']),1,1)
                    self.opt_dict['offset'] = 0

        if option == 'days':
            if self.opt_dict['days'] > (14 - self.opt_dict['offset']):
                log("tvgids.nl/tvgids.tv kunnen maximaal 14 dagen vooruit kijken. Resetting\n",1,1)

            self.opt_dict['days'] = min(self.opt_dict['days'],(14 - self.opt_dict['offset']))

            if self.opt_dict['slowdays'] == None:
                self.opt_dict['slowdays'] = config.opt_dict['days']

        if option == 'tevedays':
            if self.opt_dict['tevedays'] > (8 - self.opt_dict['offset']):
                log("teveblad.be kan maximaal 7 dagen vooruit kijken. Resetting\n",1,1)

            self.opt_dict['tevedays'] = min(self.opt_dict['tevedays'],(8 - self.opt_dict['offset']))
            self.opt_dict['tevedays'] = min(self.opt_dict['days'], self.opt_dict['tevedays'])
            if self.opt_dict['tevedays'] < 0:
                self.opt_dict['tevedays'] = 0

        if option == 'rtldays':
            if self.opt_dict['rtldays'] > (14 - self.opt_dict['offset']):
                log("rtl.nl kan maximaal 14 dagen vooruit kijken.\n",1,1)

            self.opt_dict['rtldays'] = min(self.opt_dict['rtldays'],(14 - self.opt_dict['offset']))
            self.opt_dict['rtldays'] = min(self.opt_dict['days'], self.opt_dict['rtldays'])

        if option == 'output_file':
            if self.opt_dict['output_file'] != None:
                try:
                    output_dir = os.path.dirname(self.opt_dict['output_file'])
                    if (output_dir != '') and not os.path.exists(output_dir):
                        log('Creating %s directory,\n' % output_dir)
                        os.mkdir(output_dir)

                    self.output = self.open_file(self.opt_dict['output_file'],'w')
                    if self.output == None:
                        log('Cannot write to outputfile: %s\n' % self.opt_dict['output_file'])
                        return(2)

                except Exception:
                    log('Cannot write to outputfile: %s\n' % self.opt_dict['output_file'])
                    return(2)

            else: self.output = None

        if option == 'log_file':
            # Save an old session log and open a new one
            try:
                log_dir = os.path.dirname(self.log_file)
                if (log_dir != '') and not os.path.exists(log_dir):
                    log('Creating %s directory,\n' % log_dir)
                    os.mkdir(log_dir)

                self.save_oldfile(self.log_file)
                self.log_output = self.open_file(self.log_file, mode = 'a')
                if self.log_output != None:
                    sys.stderr = self.log_output

                else:
                    log('Cannot write to logfile: %s\n' % self.log_file)
                    return(2)

            except Exception:
                log('Cannot write to logfile: %s\n' % self.log_file)
                return(2)

        if option == 'program_cache_file':
            if self.program_cache_file.lower() == 'none' or self.program_cache_file == None:
                self.program_cache_file = None
                xml_output.program_cache = ProgramCache(self.program_cache_file)
                return

            try:
                cache_dir = os.path.dirname(self.program_cache_file)
                if (cache_dir != '') and not os.path.exists(cache_dir):
                    log('Creating %s directory,\n' % cache_dir)
                    os.mkdir(cache_dir)

                if os.access(self.program_cache_file, os.F_OK and os.W_OK):
                    pass

                elif not os.path.isfile(self.program_cache_file) and os.access(cache_dir, os.W_OK):
                    pass

                else:
                    log('Cannot write to cachefile: %s\n' % self.program_cache_file)
                    return(2)

            except Exception:
                log('Cannot write to cachefile: %s\n' % self.program_cache_file)
                return(2)

            xml_output.program_cache = ProgramCache(self.program_cache_file)
            if self.clean_cache:
                xml_output.program_cache.clean()

            if self.clear_cache:
                xml_output.program_cache.clear()

        if option == 'slowdays':
            if channel.opt_dict['slowdays'] == None:
                channel.opt_dict['slowdays'] = self.opt_dict['days']
                if channel.opt_dict['desc_length'] == 0:
                    # no description implies fast == True
                    if not channel.opt_dict['fast']:
                        log('Setting Channel: %s to Fast Mode\n' % channel.chan_name,1,1)
                        channel.opt_dict['fast'] = True

            else:
                channel.opt_dict['slowdays'] = min(self.opt_dict['days'], channel.opt_dict['slowdays'])
                # slowdays implies fast == False
                if channel.opt_dict['slowdays'] < self.opt_dict['days']:
                    channel.opt_dict['fast']  = False

        if option == 'desc_length':
            if channel.opt_dict['desc_length'] != self.opt_dict['desc_length']:
                log('Using description length: %d for Cannel: %s\n' % (channel.opt_dict['desc_length'], channel.chan_name),1,1)

        if option == 'overlap_strategy':
            if not channel.opt_dict['overlap_strategy'] in ['average', 'stop', 'start']:
                channel.opt_dict['overlap_strategy'] = 'none'

        if option == 'max_overlap':
            if channel.opt_dict['max_overlap'] == 0:
                # no max_overlap implies strategie == 'None'
                channel.opt_dict['overlap_strategy'] = 'None'
                log('Maximum overlap 0 means overlap strategy for Channel: %s set to: \'%s\'\n' % (channel.chan_name, channel.opt_dict['overlap_strategy']),1,1)

            elif channel.opt_dict['max_overlap'] != self.opt_dict['max_overlap']:
                log('Using Maximum Overlap: %d for Channel %s\n' % (channel.opt_dict['max_overlap'], channel.chan_name),1,1)
                if channel.opt_dict['overlap_strategy'] != self.opt_dict['overlap_strategy']:
                    log('overlap strategy for Channel: %s set to: \'%s\'\n' % (channel.chan_name, channel.opt_dict['overlap_strategy']),1,1)

        #~ if option == '':
        #~ if option == '':
    # end validate_option()

    def write_opts_to_log(self):
        """
        Save the the used options to the logfile
        """
        if self.log_output == None:
            return(0)

        log(u'Python versie: %s.%s.%s' % (sys.version_info[0], sys.version_info[1], sys.version_info[2]),1, 2)
        log(u'The Netherlands: %s' % self.version(True), 1, 2)
        log(u'Capabilities:"baseline" ,"cache" ,"manualconfig" ,"preferredmethod")', 1, 2)
        log(u'Preferred Methode: "allatonce"', 1, 2)
        log(u'log level = %s' % (self.opt_dict['log_level']), 1, 2)
        log(u'match log level = %s' % (self.opt_dict['match_log_level']), 1, 2)
        log(u'config_file = %s' % (self.config_file), 1, 2)
        log(u'program_cache_file = %s' % (self.program_cache_file), 1, 2)
        log(u'cache_save_interval = %s' % (self.opt_dict['cache_save_interval']), 1, 2)
        log(u'clean_cache = %s' % (self.clean_cache), 1, 2)
        log(u'clear_cache = %s' % (self.clear_cache), 1, 2)
        log(u'output_file = %s' % (self.opt_dict['output_file']), 1, 2)
        log(u'quiet = %s' % (self.opt_dict['quiet']), 1, 2)
        log(u'fast = %s' % (self.opt_dict['fast']), 1, 2)
        log(u'offset = %s' % (self.opt_dict['offset']), 1, 2)
        log(u'days = %s' % (self.opt_dict['days']), 1, 2)
        log(u'slowdays = %s' % (self.opt_dict['slowdays']), 1, 2)
        log(u'rtldays = %s' % (self.opt_dict['rtldays']), 1, 2)
        log(u'tevedays = %s' % (self.opt_dict['tevedays']), 1, 2)
        log(u'use_npo = %s' % (self.opt_dict['use_npo']), 1, 2)
        log(u'compat = %s' % (self.opt_dict['compat']), 1, 2)
        log(u'max_overlap = %s' % (self.opt_dict['max_overlap']), 1, 2)
        log(u'overlap_strategy = %s' % (self.opt_dict['overlap_strategy']), 1, 2)
        log(u'logos = %s' % (self.opt_dict['logos']), 1, 2)
        log(u'desc_length = %s' % (self.opt_dict['desc_length']), 1, 2)
        log(u'cattrans = %s' % (self.opt_dict['cattrans']), 1, 2)
        log(u'mark_hd = %s' % (self.opt_dict['mark_hd']), 1, 2)
        log(u'use_utc = %s' % (self.opt_dict['use_utc']), 1, 2)
        log(u'Channel specific settings other then the above:', 1, 2)
        for chan_def in self.channels.values():
            chan_name_written = False
            if not chan_def.opt_dict['append_tvgidstv']:
                log(u'[%s (Chanid=%s)]\n' % (chan_def.chan_name, chan_def.chanid), 1, 2)
                chan_name_written = True
                log(u'  append_tvgidstv = False\n', 1, 2)

            for index in range(xml_output.source_count):
                if chan_def.source_id[index] != '':
                    if chan_def.opt_dict['prime_source'] != index:
                        if not chan_name_written:
                            log(u'[%s (Chanid=%s)]\n' % (chan_def.chan_name, chan_def.chanid), 1, 2)
                            chan_name_written = True

                        log(u'  prime_source = %s\n' % ( chan_def.opt_dict['prime_source']), 1, 2)

                    break

            if chan_def.opt_dict['prefered_description'] != -1:
                if chan_def.opt_dict['prefered_description'] in chan_def.source_id.keys() and chan_def.source_id[chan_def.opt_dict['prefered_description']] != '':
                    if chan_def.opt_dict['prefered_description'] != index:
                        if not chan_name_written:
                            log(u'[%s (Chanid=%s)]\n' % (chan_def.chan_name, chan_def.chanid), 1, 2)
                            chan_name_written = True

                        log(u'  prefered_description = %s\n' % ( chan_def.opt_dict['prefered_description']), 1, 2)

            if chan_def.opt_dict['add_hd_id']:
                if not chan_name_written:
                    log(u'[%s (Chanid=%s)]\n' % (chan_def.chan_name, chan_def.chanid), 1, 2)
                    chan_name_written = True

                log(u'  add_hd_id = True\n', 1, 2)

            if chan_def.opt_dict['slowdays'] != self.opt_dict['slowdays'] and chan_def.opt_dict['slowdays'] != None:
                if not chan_name_written:
                    log(u'[%s (Chanid=%s)]\n' % (chan_def.chan_name, chan_def.chanid), 1, 2)
                    chan_name_written = True

                log(u'  slowdays = %s' % (chan_def.opt_dict['slowdays']), 1, 2)

            for val in ( 'fast', 'compat', 'max_overlap', 'overlap_strategy', 'logos', 'desc_length', 'cattrans', 'mark_hd', 'use_npo'):
                if chan_def.opt_dict[val] != self.opt_dict[val]:
                    if not chan_name_written:
                        log(u'[%s (Chanid=%s)]\n' % (chan_def.chan_name, chan_def.chanid), 1, 2)
                        chan_name_written = True

                    log(u'  %s = %s' % (val, chan_def.opt_dict[val]), 1, 2)

    # end write_opts_to_log()

    def write_config(self, add_channels = None):
        """
        Save the channel info and the default options
        if add_channels is False or None we copy over the Channels sections
        If add_channels is None we convert the channel info to the new form
        if add_channels is True we create a fresh channels section
        """
        self.save_oldfile(self.config_file)
        f = self.open_file(self.config_file, 'w')
        if f == None:
            return False

        f.write(u'# encoding: utf-8\n')
        f.write(u'# configversion: %s.%s\n' % (self.major, self.minor))
        f.write(u'\n')

        # Save the options
        f.write(u'# This is a list with default options set by the --save-options (-O)\n')
        f.write(u'# argument. They can be overruled on the commandline.\n')
        f.write(u'# !!THIS MUST COME FIRST BEFORE THE CHANNEL SECTIONS!!\n')
        f.write(u'# !!OR SYSTEM DEFAULTS WILL BE USED INSTEAD!!\n')
        f.write(u'# Be carefull with manually editing. Invalid options will be\n')
        f.write(u'# silently ignored. Boolean options can be set with True/False,\n')
        f.write(u'# On/Off or 1/0. Leaving it blank sets them on. Setting an invalid\n')
        f.write(u'# value sets them off. You can always check the log for the used values.\n')
        f.write(u'# To edit you beter run --save-options with all the desired defaults.\n')
        f.write(u'# Options not shown here can not be set this way.\n')
        f.write(u'\n')
        f.write(u'[%s]\n' % self.__CONFIG_SECTIONS__[1])
        if self.write_info_files:
            f.write(u'write_info_files = True\n')
            f.write(u'\n')
        f.write(u'# This handles what goes to the log and screen\n')
        f.write(u'# 0 Nothing (use quiet mode to turns off screen output, but keep a log)\n')
        f.write(u'# 1 include Errors and Warnings\n')
        f.write(u'# 2 include page fetches\n')
        f.write(u'# 4 include (merge) summaries\n')
        f.write(u'# 8 include detail fetches to the screen\n')
        f.write(u'# 16 include detail fetches to the log\n')
        f.write(u'# 32 include matchlogging (see below)\n')
        f.write(u'# 64 Title renames\n')
        f.write(u'log_level = %s\n' % self.opt_dict['log_level'])
        f.write(u'\n')
        f.write(u'# What match results go to the log/screen (needs code 32 above)\n')
        f.write(u'# 0 = Log Nothing (just the overview)\n')
        f.write(u'# 1 = log not matched programs\n')
        f.write(u'# 2 = log left over programs\n')
        f.write(u'# 4 = Log matches\n')
        f.write(u'match_log_level = %s\n' % self.opt_dict['match_log_level'])
        f.write(u'\n')
        f.write(u'quiet = %s\n' % self.opt_dict['quiet'])
        f.write(u'output_file = %s\n' % self.opt_dict['output_file'])
        f.write(u'cache_save_interval = %s\n' % self.opt_dict['cache_save_interval'])
        f.write(u'compat = %s\n' % self.opt_dict['compat'])
        f.write(u'logos = %s\n' % self.opt_dict['logos'])
        f.write(u'use_utc = %s\n' % self.opt_dict['use_utc'])
        f.write(u'fast = %s\n' % self.opt_dict['fast'])
        f.write(u'offset = %s\n' % self.opt_dict['offset'])
        f.write(u'days = %s\n' % self.opt_dict['days'])
        f.write(u'slowdays = %s\n' % self.opt_dict['slowdays'])
        f.write(u'rtldays = %s\n' % self.opt_dict['rtldays'])
        f.write(u'tevedays = %s\n' % self.opt_dict['tevedays'])
        f.write(u'use_npo = %s\n' % self.opt_dict['use_npo'])
        f.write(u'cattrans = %s\n' % self.opt_dict['cattrans'])
        f.write(u'mark_hd = %s\n' % self.opt_dict['mark_hd'])
        f.write(u'overlap_strategy = %s\n' % self.opt_dict['overlap_strategy'] )
        f.write(u'max_overlap = %s\n' % self.opt_dict['max_overlap'])
        f.write(u'desc_length = %s\n' % self.opt_dict['desc_length'])
        f.write(u'\n')

        f.write(u'# These are the channels to parse. You can disable a channel by placing\n')
        f.write(u'# a \'#\' in front. Seperated by \';\' you see on every line: The Name,\n')
        f.write(u'# the group, the ID\'s from tvgids.nl, tvgids.tv, rtl.nl and teveblad.be\n')
        f.write(u'# and finally the iconsource and name.\n')
        f.write(u'# You can change the names to suit your own preferences or\n')
        f.write(u'# A missing ID means the source doesn\'t supply the channel.\n')
        f.write(u'# remove an ID to not fetch from that source, but keep the \';\'s in place.\n')
        f.write(u'# Set iconsource to 99, to add your own full url.\n')
        f.write(u'\n')
        f.write(u'# To specify further Channel settings you can add sections in the form of\n')
        f.write(u'# [Channel <channelID>], where <channelID> is the first ID on the line, \n')
        f.write(u'# (most of the times the nummeric tvgids.nl ID)\n')
        f.write(u'# !!THEY MUST BE BELOW THE CONFIGURATION AND CHANNEL SECTIONS!!\n')
        f.write(u'# You can use the following tags:\n')
        f.write(u'# Boolean values (True, 1, on or no value means True. Everything else False):\n')
        f.write(u'#   fast, compat, logos, cattrans, mark_hd, add_hd_id, append_tvgidstv, use_npo\n')
        f.write(u'#     append_tvgidstv is True by default, which means: \'Don\'t get data\n')
        f.write(u'#     from tvgids.tv if there is from tvgids.nl\' tvgids.tv data normally is\n')
        f.write(u'#     inferiour, except for instance that for Veronica it fills in Disney XD\n')
        f.write(u'#     add_hd_id: if set to True will create two listings for the given channel.\n')
        f.write(u'#     One normal on without HD tagging and one with \'-hd\' added to the ID\n')
        f.write(u'#     and with the HD tags. This will overrule any setting of mark_hd\n')
        f.write(u'#     use_npo is by default on and delivers superior timings for three days\n')
        f.write(u'#     for the NPO channels and the dutch regional channels\n')
        f.write(u'# Integer values:\n')
        f.write(u'#   slowdays, max_overlap, desc_length, prime_source, prefered_description\n')
        f.write(u'#     prime_source (0-3) is the source whose timings are dominant\n')
        f.write(u'#     It defaults to the first available source or 2 for rtl channels\n')
        f.write(u'#     and 3 for group 2 and 8 (Flemmisch) channels\n')
        f.write(u'#     prefered_description (0-3) is the source whose description, if present,\n')
        f.write(u'#     is used. It defaults to the longest description found.\n')
        f.write(u'# String values:\n')
        f.write(u'#   overlap_strategy (With possible values): \n')
        f.write(u'#     average, stop, start; everything else sets it to none\n')
        f.write(u'\n')
        f.write(u'[%s]\n' % self.__CONFIG_SECTIONS__[3])

        # just copy over the channels section
        if add_channels == False and configversion == 2.1:
            fo = self.open_file(self.config_file + '.old')
            if fo == None or not self.check_encoding(fo):
                # We cannot read the old config, so we create a new one
                log('Error Opening the old config. Creating a new one.\n')
                add_channels = True

            else:
                fo.seek(0,0)
                type = 0
                for byteline in fo.readlines():
                    line = self.get_line(fo, byteline, None)
                    try:
                        if line == '# encoding: utf-8' or line == False:
                            continue

                        # Look for section headers
                        config_title = re.search('\[(.*?)\]', line)
                        if config_title != None and (config_title.group(1) in self.__CONFIG_SECTIONS__.values()):
                            for i, v in self.__CONFIG_SECTIONS__.items():
                                if v == config_title.group(1):
                                    type = i
                                    continue

                            continue

                        elif config_title != None and (config_title.group(1)[0:8] == 'Channel '):
                            type = 9
                            continue

                        # Unknown Section header, so ignore
                        if line[0:1] == '[':
                            type = 0
                            continue


                        if type > 1:
                            # We just copy everything except the old configuration (type = 1)
                            f.write(line + u'\n')
                    except:
                        log('Error reading old config\n')
                        continue

                fo.close()
                f.close()
                return True

        # This is an upgrade
        if add_channels != True:
            configlines = {}
            configlines['2remarks'] = []
            configlines['2'] = []
            configlines['3remarks'] = []
            configlines['3'] = []
            # Get the old channels section to convert
            fo = self.open_file(self.config_file + '.old')
            if fo == None or not self.check_encoding(fo):
                # We cannot read the old config, so we create a new one
                log('Error Opening the old config. Creating a new one.\n')
                self.get_channels()
                add_channels = True

            else:
                fo.seek(0,0)
                if self.configversion == 1.0:
                    type = 2

                else:
                    type = 0

                for byteline in fo.readlines():
                    line = self.get_line(fo, byteline, None, self.encoding)
                    try:
                        if line == '# encoding: utf-8' or line[0:17] == '# configversion: ' or line == False:
                            continue

                        if self.configversion != 1.0:
                            # Look for section headers
                            config_title = re.search('\[(.*?)\]', line)
                            if config_title != None and (config_title.group(1) in self.__CONFIG_SECTIONS__.values()):
                                section = config_title.group(1)
                                for i, v in self.__CONFIG_SECTIONS__.items():
                                    if v == config_title.group(1):
                                        type = i
                                        continue

                                continue

                            elif config_title != None and (config_title.group(1)[0:8] == 'Channel '):
                                section = config_title.group(1)
                                type = 9
                                chanid = config_title.group(1)[8:]
                                configlines[chanid] = []
                                continue

                            # Unknown Section header, so ignore
                            if line[0:1] == '[':
                                type = 0
                                continue

                        if type == 2 and self.configversion <= 2.0:
                            if line[0:1] == '#':
                                configlines['2remarks'].append(line)

                            else:
                                configlines['2'].append(line)

                        elif type == 3 and self.configversion > 2.0:
                            if line[0:1] == '#':
                                configlines['3remarks'].append(line)

                            else:
                                configlines['3'].append(line)

                        elif type == 9 and self.configversion > 2.0:
                            configlines[chanid].append(line)

                    except:
                        log('Error reading old config\n')
                        continue

                fo.close()

                self.get_channels()
                chan_added = []
                chan_not_updated = []
                chan_list = {}
                for g in self.chan_groups.keys():
                    chan_list[g] =[]

                if self.configversion <= 2.0:
                    for item in configlines['2']:
                        chan = item.split(None, 1) # split on first whitespace
                        if len(chan) != 2:
                            chan_not_updated.append(u'# %s\n' % (item))
                            continue

                        if chan[0].strip() in self.channels.keys():
                            chanid = chan[0].strip()
                            chan_list[self.channels[chanid].group].append('%s;%s;%s;%s;%s;%s;%s;%s\n' % (\
                                                                                                chan[1], \
                                                                                                self.channels[chanid].group, \
                                                                                                self.channels[chanid].source_id[0], \
                                                                                                self.channels[chanid].source_id[1], \
                                                                                                self.channels[chanid].source_id[2], \
                                                                                                self.channels[chanid].source_id[3], \
                                                                                                self.channels[chanid].icon_source, \
                                                                                                self.channels[chanid].icon))
                            chan_added.append(chanid)

                        else:
                            chan_not_updated.append(u'# %s\n' % (item))

                    for item in configlines['2remarks']:
                        chan = re.sub('#', '', item)
                        chan = chan.split(None, 1) # split on first whitespace
                        if len(chan) != 2:
                            chan_not_updated.append(u'# %s\n' % (item))
                            continue

                        if chan[0].strip() in self.channels.keys():
                            chanid = chan[0].strip()
                            chan_list[self.channels[chanid].group].append('# %s;%s;%s;%s;%s;%s;%s;%s\n' % (\
                                                                                                chan[1], \
                                                                                                self.channels[chanid].group, \
                                                                                                self.channels[chanid].source_id[0], \
                                                                                                self.channels[chanid].source_id[1], \
                                                                                                self.channels[chanid].source_id[2], \
                                                                                                self.channels[chanid].source_id[3], \
                                                                                                self.channels[chanid].icon_source, \
                                                                                                self.channels[chanid].icon))
                            chan_added.append(chanid)

                        else:
                            chan_not_updated.append(item + '\n')

                if self.configversion > 2.0:
                    for item in configlines['3']:
                        chan = re.split(';', item)
                        if len(chan) != 8:
                            chan_not_updated.append(u'# %s\n' % (item))
                            continue

                        for channel in self.channels.values():
                            if ((chan[2].strip() !='') and (chan[2].strip() == channel.source_id[0])) or \
                              ((chan[3].strip() !='') and (chan[2].strip() == channel.source_id[1])) or \
                              ((chan[4].strip() !='') and (chan[2].strip() == channel.source_id[2])) or \
                              ((chan[5].strip() !='') and (chan[2].strip() == channel.source_id[3])):
                                chan_list[chan[1]].append('%s;%s;%s;%s;%s;%s;%s;%s\n' % (chan[0], chan[1], \
                                    channel.source_id[0], channel.source_id[1], channel.source_id[2], channel.source_id[3], chan[6], chan[7]))

                                chan_added.append(channel.chanid)
                                break

                        else:
                            chan_not_updated.append(u'# %s\n' % (item))

                    for item in configlines['3remarks']:
                        chan = re.sub('#', '', item)
                        chan = re.split(';', chan)
                        if len(chan) != 8:
                            chan_not_updated.append(u'# %s\n' % (item))
                            continue

                        for channel in self.channels.values():
                            if ((chan[2].strip() !='') and (chan[2].strip() == channel.source_id[0])) or \
                              ((chan[3].strip() !='') and (chan[2].strip() == channel.source_id[1])) or \
                              ((chan[4].strip() !='') and (chan[2].strip() == channel.source_id[2])) or \
                              ((chan[5].strip() !='') and (chan[2].strip() == channel.source_id[3])):
                                chan_list[chan[1]].append('# %s;%s;%s;%s;%s;%s;%s;%s\n' % (chan[0], chan[1], \
                                    channel.source_id[0], channel.source_id[1], channel.source_id[2], channel.source_id[3], chan[6], chan[7]))

                                chan_added.append(channel.chanid)
                                break

                        else:
                            chan_not_updated.append(item+'\n')

                del configlines['2']
                del configlines['3']
                del configlines['2remarks']
                del configlines['3remarks']

                for chanid in self.channels.keys():
                    if not chanid in chan_added:
                        chan_list[self.channels[chanid].group].append('# %s;%s;%s;%s;%s;%s;%s;%s\n' % (\
                                                                                            self.channels[chanid].chan_name, \
                                                                                            self.channels[chanid].group, \
                                                                                            self.channels[chanid].source_id[0], \
                                                                                            self.channels[chanid].source_id[1], \
                                                                                            self.channels[chanid].source_id[2], \
                                                                                            self.channels[chanid].source_id[3], \
                                                                                            self.channels[chanid].icon_source, \
                                                                                            self.channels[chanid].icon))

                for g in self.chan_groups.keys():
                    f.write('\n')
                    f.write('# %s\n' % self.chan_groups[g])
                    chan_list[g].sort()
                    for channel in chan_list[g]:
                        f.write( channel)

                if len(chan_not_updated) > 0:
                    f.write('\n')
                    f.write('# Following are not converted lines!')
                    for line in chan_not_updated:
                        f.write(line)

                # At a later config upgrade we here have to parse the type 9 sections

        if add_channels:
            chan_list = {}
            for g in self.chan_groups.keys():
                chan_list[g] =[]

            for channel in self.channels.values():
                chan_string = '%s;%s;%s;%s;%s;%s;%s;%s\n' % (\
                                        channel.chan_name, \
                                        channel.group, \
                                        channel.source_id[0], \
                                        channel.source_id[1], \
                                        channel.source_id[2], \
                                        channel.source_id[3], \
                                        channel.icon_source, \
                                        channel.icon)

                if channel.active:
                    chan_list[channel.group].append(chan_string)

                else:
                    chan_list[channel.group].append('# %s' % chan_string)

            for g in self.chan_groups.keys():
                f.write('\n')
                f.write('# %s\n' % self.chan_groups[g])
                chan_list[g].sort()
                for channel in chan_list[g]:
                    f.write(channel)

        f.write(u'\n')
        f.write(u'# Channel specific settings other then the above or the default:\n')
        for chan_def in self.channels.values():
            chan_name_written = False
            if not chan_def.opt_dict['append_tvgidstv']:
                f.write(u'\n')
                f.write(u'# %s\n' % (chan_def.chan_name))
                f.write(u'[Channel %s]\n' % (chan_def.chanid))
                chan_name_written = True
                f.write(u'append_tvgidstv = False\n')

            for index in range(xml_output.source_count):
                if chan_def.source_id[index] != '':
                    if chan_def.opt_dict['prime_source'] != index:
                        if not chan_name_written:
                            f.write(u'\n')
                            f.write(u'# %s\n' % (chan_def.chan_name))
                            f.write(u'[Channel %s]\n' % (chan_def.chanid))
                            chan_name_written = True

                        f.write(u'prime_source = %s\n' % ( chan_def.opt_dict['prime_source']))

                    break

            if chan_def.opt_dict['prefered_description'] != -1:
                if chan_def.opt_dict['prefered_description'] in chan_def.source_id.keys() and chan_def.source_id[chan_def.opt_dict['prefered_description']] != '':
                    if chan_def.opt_dict['prefered_description'] != index:
                        if not chan_name_written:
                            f.write(u'\n')
                            f.write(u'# %s\n' % (chan_def.chan_name))
                            f.write(u'[Channel %s]\n' % (chan_def.chanid))
                            chan_name_written = True

                        f.write(u'prefered_description = %s\n' % ( chan_def.opt_dict['prefered_description']))

            if chan_def.opt_dict['add_hd_id']:
                if not chan_name_written:
                    f.write(u'\n')
                    f.write(u'# %s\n' % (chan_def.chan_name))
                    f.write(u'[Channel %s]\n' % (chan_def.chanid))
                    chan_name_written = True

                f.write(u'add_hd_id = True\n')

            if chan_def.opt_dict['slowdays'] != self.opt_dict['slowdays'] and chan_def.opt_dict['slowdays'] != None:
                if not chan_name_written:
                    f.write(u'\n')
                    f.write(u'# %s\n' % (chan_def.chan_name))
                    f.write(u'[Channel %s]\n' % (chan_def.chanid))
                    chan_name_written = True

                f.write(u'slowdays = %s\n' % (chan_def.opt_dict['slowdays']))

            for val in ( 'fast', 'compat', 'max_overlap', 'overlap_strategy', 'logos', 'desc_length', 'cattrans', 'mark_hd', 'use_npo'):
                if chan_def.opt_dict[val] != self.opt_dict[val]:
                    if not chan_name_written:
                        f.write(u'\n')
                        f.write(u'# %s\n' % (chan_def.chan_name))
                        f.write(u'[Channel %s]\n' % (chan_def.chanid))
                        chan_name_written = True

                    f.write(u'%s = %s\n' % (val, chan_def.opt_dict[val]))

        f.close()
        return True
    # end write_config()

    def write_defaults_list(self):
        """
        Save the genre conversion table, the title split exception list and othe translation tables
        """
        self.save_oldfile(self.settings_file)
        f = self.open_file(self.settings_file, 'w')
        if f == None:
            return False

        f.write(u'# encoding: utf-8\n')
        f.write(u'\n')
        f.write(u'# This is a list of the role-titles encountered\n')
        f.write(u'# with a translation to the english titles as used in MythTV.\n')
        f.write(u'\n')
        f.write(u'[%s]\n' % self.__DEFAULT_SECTIONS__[7])

        l = []
        for i, t in self.roletrans.iteritems():
            l.append(u'%s = %s' % (i,t))
        l.sort()
        for string in l:
            f.write(u'%s\n' % string)

        f.write(u'\n')
        f.write(u'# This is a list of titles containing a \':\' not to split\n')
        f.write(u'# in a title and a subtitle\n')
        f.write(u'# These will mainly be spin-off series like \'NCIS: Los Angeles\'\n')
        f.write(u'# Movies and programs already having a subtitle are already excluded.\n')
        f.write(u'\n')
        f.write(u'[%s]\n' % self.__DEFAULT_SECTIONS__[2])

        self.notitlesplit.sort()
        for t in self.notitlesplit:
             f.write(u'%s\n' % t)

        f.write(u'\n')
        f.write(u'# This is a list of grouptitles in titles containing a \':\'\n')
        f.write(u'# to remove from the title\n')
        f.write(u'# For instance \"KRO detectives\".\n')
        f.write(u'# This among others to cover diferent naming on separate sources.\n')
        f.write(u'\n')
        f.write(u'[%s]\n' % self.__DEFAULT_SECTIONS__[3])

        self.groupnameremove.sort()
        for t in self.groupnameremove:
             f.write(u'%s\n' % t)

        f.write(u'\n')
        f.write(u'# This is a list of titles to rename.\n')
        f.write(u'# For instance \"navy NCIS\" to \"NCIS\".\n')
        f.write(u'# This among others to cover diferent naming on separate sources.\n')
        f.write(u'\n')
        f.write(u'[%s]\n' % self.__DEFAULT_SECTIONS__[4])

        l = []
        for i, t in self.titlerename.iteritems():
            l.append(u'%s = %s' % (i,t))
        l.sort()
        for string in l:
            f.write(u'%s\n' % string)

        f.write(u'\n')
        f.write(u'# This is the translation list for teveblad.be genres to tvgids.nl\n')
        f.write(u'# genre:subgenre. If you have cattrans enabled, they will next be converted\n')
        f.write(u'# according to the list further down.\n')
        f.write(u'\n')
        f.write(u'[%s]\n' % self.__DEFAULT_SECTIONS__[5])

        # remove doubles and sort
        for k in self.tevecat.keys():
            if not (k in self.tevecattrans.keys()):
                self.tevecattrans[k] = self.tevecat[k]

        # format for export
        gl = []
        for k, (v1, v2) in self.tevecattrans.iteritems():
            gl.append('%s = %s: %s' % (k, v1, v2))
        gl.sort()

        for string in gl:
            f.write(u'%s\n' % string)

        f.write(u'\n')
        f.write(u'# This is the list of genres to add the tvgidstv genres to as subgenre\n')
        f.write(u'# tvgids.tv genres are like tvgids.nl subgenres. This is a list of what\n')
        f.write(u'# genre to add to a subgenre. Available genres are:\n')
        f.write(u'#   Amusement             Magazine                Serie/Soap\n')
        f.write(u'#   Film                  Muziek                  Sport\n')
        f.write(u'#   Informatief           Natuur                  Wetenschap\n')
        f.write(u'#   Jeugd                 Nieuws/Actualiteiten    Overige\n')
        f.write(u'#   Kunst en Cultuur      Religieus\n')
        f.write(u'# New found "subgenres" are automatically added and matched on generic rules\n')
        f.write(u'\n')
        f.write(u'[%s]\n' % self.__DEFAULT_SECTIONS__[6])

        # remove doubles and sort
        gs = set(self.tvtvcat)
        gl = []
        for k, v in gs:
            if not (k in self.tvtvcattrans):
                self.tvtvcattrans[k] = v

        # format for export
        for k, v in self.tvtvcattrans.iteritems():
            gl.append('%s = %s' % (v, k))
        gl.sort()

        for string in gl:
            f.write(u'%s\n' % string)

        f.write(u'\n')
        f.write(u'# This is the \'Genre:Subgenre\' conversion table\n')
        f.write(u'# \n')
        f.write(u'# \'Genre:Subgenre\' will automatically be converted to lowercase\n')
        f.write(u'# and leading and following spaces will be removed\n')
        f.write(u'# It will automatically get sorted with the genres without\n')
        f.write(u'# a subgenre at the top.\n')
        f.write(u'# Also new found values will be added on every new scan\n')
        f.write(u'# \n')
        f.write(u'# Behind the \'=\' you can supply the category to be used\n')
        f.write(u'# If a category value is empty the main category or an existing\n')
        f.write(u'# default will be used\n')
        f.write(u'# If a main category is empty the default will be supplied\n')
        f.write(u'# and used. If no default exists \'Unknown\' will be used.\n')
        f.write(u'# You should regualary check on new main categories\n')
        f.write(u'# so they don\'t get translated to \'Unknown\'\n')
        f.write(u'\n')
        f.write(u'[%s]\n' % self.__DEFAULT_SECTIONS__[1])

        l1 = []
        l2 = []

        # remove doubles
        gs = set(self.genre_list)
        # add them to cattrans if not yet known
        for i in gs:
            if not (i in self.cattrans):
                self.cattrans[i]=''

        # format for export and add main genres and sub-genres to seperate lists to get sorted
        # add missing maingenres for new subgenres
        for k1, k2 in self.cattrans:
            if k2 == '':
                l1.append('%s: = %s' % (k1, self.cattrans[(k1,k2)]))
            else:
                l2.append('%s: %s = %s' % (k1, k2, self.cattrans[(k1,k2)]))
                i = (k1, u'')
                if not (i in self.cattrans):
                    l1.append('%s:=' % k1)
        l1.sort()
        l2.sort()

        for string in l1:
            f.write(u'%s\n' % string)

        f.write(u'\n')
        for string in l2:
            f.write(u'%s\n' % string)

        f.close()
    # end write_defaults_list()

    def close(self):

        try:
            infofiles.close()

        except:
            log('\nAn unexpected error has occured closing infofiles: %s\n' %  (sys.exc_info()[1]), 0)

        # Quiting any remaining Threads
        for source in xml_output.channelsource.values():
            source.quit = True

        for channel in config.channels.values():
            channel.quit = True

        if xml_output.program_cache != None:
            xml_output.program_cache.quit = True
            xml_output.program_cache.join()
            xml_output.program_cache = None

        # close everything neatly
        try:
            if self.opt_dict['output_file'] != None:
                self.output.close()

            if self.log_output != None:
                self.log_output.close()

        except:
            pass

    # end close()

# end Configure
config = Configure()

# used for gathering extra info to better the code
class InfoFiles:
    """used for gathering extra info to better the code"""
    def __init__(self):

        self.detail_list = []
        self.raw_list = []
        self.raw_string = ''
        self.fetch_strings = {}

    def open_files(self):

        if config.write_info_files:
            self.fetch_list = config.open_file(config.xmltv_dir + '/fetched-programs','w')
            self.raw_output =  config.open_file(config.xmltv_dir+'/raw_output', 'w')

    def addto_raw_string(self, string):
        if config.write_info_files:
            self.raw_string = unicode(self.raw_string + string)

    def write_raw_string(self, string):
        if config.write_info_files:
            self.raw_string = unicode(self.raw_string + string)
            self.raw_output.write(self.raw_string + u'\n')
            self.raw_string = ''

    def addto_raw_list(self, raw_data = None):

        if config.write_info_files:
            if raw_data == None:
                self.raw_list.append(self.raw_string)
                self.raw_string = ''
            else:
                self.raw_list.append(raw_data)

    def write_raw_list(self, raw_data = None):

        if (not config.write_info_files) or (self.raw_output == None):
            return

        if raw_data != None:
            self.raw_list.append(raw_data)

        self.raw_list.sort()
        for i in self.raw_list:
            i = re.sub('\n +?\n', '\n', i)
            i = re.sub('\n+?', '\n', i)
            if i.strip() == '\n':
                continue

            self.raw_output.write(i + u'\n')

        self.raw_list = []
        self.raw_string = ''

    def addto_detail_list(self, detail_data):

        if config.write_info_files: self.detail_list.append(detail_data)

    def write_fetch_list(self, programs, chanid, source, ismerge = False):

        if (not config.write_info_files) or (self.fetch_list == None):
            return

        if not chanid in  self.fetch_strings:
             self.fetch_strings[chanid] = {}

        if not source in  self.fetch_strings[chanid]:
            self.fetch_strings[chanid][source] = ''

        if ismerge:
            self.fetch_strings[chanid][source] += u'(%3.0f) merging channel: %s from: %s\n' % (len(programs), config.channels[chanid].chan_name, source)

        else:
            self.fetch_strings[chanid][source] += u'(%3.0f) channel: %s from: %s\n' % (len(programs), config.channels[chanid].chan_name, source)

        programs.sort(key=lambda program: (program['start-time']))

        for tdict in programs:
            if ismerge:
                id = tdict['ID']

            elif source in config.sources.keys():
                id = tdict[config.sources[source]['ID']]

            else:
                id = ''

            self.fetch_strings[chanid][source] += u'  %s-%s: [%s][%s] %s: %s [%s/%s]\n' % (\
                            tdict['start-time'].strftime('%d %b %H:%M'), \
                            tdict['stop-time'].strftime('%H:%M'), \
                            id.rjust(15), tdict['genre'][0:10].rjust(10), \
                            tdict['name'], tdict['titel aflevering'], \
                            tdict['season'], tdict['episode'])

        if ismerge: self.fetch_strings[chanid][source] += u'#\n'

    def write_xmloutput(self, xml):

        if config.write_info_files:
            xml_output =config.open_file(config.xmltv_dir+'/xml_output', 'w')
            if xml_output == None:
                return

            xml_output.write(xml)
            xml_output.close()

    def close(self):
        if not config.write_info_files:
            return

        if self.fetch_list != None:
            for chanid in config.channels.keys():
                if chanid in self.fetch_strings:
                    for source in xml_output.channelsource.values():
                        if source.source in self.fetch_strings[chanid].keys():
                            self.fetch_list.write(self.fetch_strings[chanid][source.source])

            self.fetch_list.close()

        if self.raw_output != None:
            self.raw_output.close()

        if len(self.detail_list) > 0:
            f = config.open_file(config.xmltv_dir+'/detail_output')
            if (f != None):
                f.seek(0,0)
                for byteline in f.readlines():
                    line = config.get_line(f, byteline, False)
                    if line:
                        self.detail_list.append(line)

                f.close()

            f = config.open_file(config.xmltv_dir+'/detail_output', 'w')
            if (f != None):
                ds = set(self.detail_list)
                ds = set(self.detail_list)
                tmp_list = []
                tmp_list.extend(ds)
                tmp_list.sort()
                for i in tmp_list:
                    f.write(u'%s\n' % i)

                f.close()

# end InfoFiles
infofiles = InfoFiles()

# Work in progress, the idea is to cache program categories and
# descriptions to eliminate a lot of page fetches from tvgids.nl
# for programs that do not have interesting/changing descriptions
class ProgramCache(Thread):
    """
    A cache to hold program name and category info.
    TVgids stores the detail for each program on a separate URL with an
    (apparently unique) ID. This cache stores the fetched info with the ID.
    New fetches will use the cached info instead of doing an (expensive)
    page fetch.
    """
    def __init__(self, filename=None):
        Thread.__init__(self)
        """
        Create a new ProgramCache object, optionally from file
        """
        self.ID_list = ('ID','nl-ID','tv-ID','rtl-ID','be-ID')
        # where we store our info
        self.filename  = filename
        self.delta_hour = datetime.timedelta(hours = 1)
        self.lock = Lock()
        self.quit = False
        self.save = False
        self.counter = 0

        if self.filename == None:
            log('Cache function disabled!\n')
            self.pdict = {}

        else:
            if os.path.isfile(self.filename +'.tmp'):
                # Trying to recover a backup cache file
                if os.path.isfile(filename):
                    if os.stat(self.filename +'.tmp').st_size > os.stat(self.filename).st_size:
                        try:
                            os.remove(self.filename)
                            os.rename(self.filename + '.tmp', self.filename)

                        except:
                            pass

                    else:
                        try:
                            os.remove(self.filename + '.tmp')

                        except:
                            pass

                else:
                    try:
                        os.rename(self.filename + '.tmp', self.filename)

                    except:
                        pass

            if os.path.isfile(filename):
                self.load()

            elif not os.path.exists(os.path.dirname(filename)):
                try:
                    os.makedirs(os.path.dirname(filename), 0755)

                except:
                    log('Cache function disabled!\n')
                    self.filename = None

                self.pdict = {}

            else:
                self.pdict = {}

    def run(self):
        if self.filename == None:
            return

        while True:
            if self.save:
                self.dump()
                self.save = False

            if self.counter == config.opt_dict['cache_save_interval']:
                self.dump()
                self.counter = 0

            if self.quit:
                log('Please wait!! While I save the Cache!!\n', 0)
                self.dump()
                break

    def load(self):
        """
        Loads a pickled cache dict from file
        """
        self.lock.acquire()
        try:
            self.pdict = pickle.load(open(self.filename,'r'))

        except Exception:
            log('Error loading cache file: %s (possibly corrupt)\n' % self.filename)
            self.clear()

        self.lock.release()

    def dump(self):
        """
        Dumps a pickled cache, and makes sure it is valid
        """

        self.lock.acquire()
        pdict_tmp = self.pdict.copy()
        self.lock.release()

        if os.access(self.filename, os.F_OK):
            try:
                os.rename(self.filename, self.filename + '.tmp')

            except Exception:
                log('Cannot rename %s, check permissions\n' % self.filename)

        tmpfile = open(self.filename, 'w')
        pickle.dump(pdict_tmp, tmpfile)
        pdict_tmp = None
        try:
            tmpfile.close()

        except IOError:
            pass

        if os.access(self.filename +'.tmp', os.F_OK):
            try:
                os.remove(self.filename +'.tmp')

            except Exception:
                log('Cannot remove %s, check permissions\n' % self.filename +'.tmp')


    def query(self, program_id):
        """
        Updates/gets/whatever.
        """
        self.lock.acquire()
        if program_id in self.pdict.keys():
            self.lock.release()
            return self.pdict[program_id]

        self.lock.release()
        return None

    def query_id(self, program):
        """
        Check which ID is used
        """
        self.lock.acquire()
        for id in self.ID_list:
            if program[id] != '' and program[id] != None and program[id] in self.pdict.keys():
                self.lock.release()
                return id

        self.lock.release()
        return None

    def add(self, program):
        """
        Adds a program
        """
        # First check if it was previously saved to prevent doubles
        if self.filename == None:
            return

        id = self.query_id(program)
        self.lock.acquire()
        if id != None and id in program and program[id] in self.pdict.keys():
            del self.pdict[program[id]]

        for id in self.ID_list:
            if program[id] != '' and program[id] != None:
                self.pdict[program[id]] = program
                self.counter+= 1
                self.lock.release()
                return

        self.lock.release()
        log('Error saving program %s to the cache.\n' %  program['name'])

    def clear(self):
        """
        Clears the cache (i.e. empties it)
        """
        self.lock.acquire()
        self.pdict = {}
        self.lock.release()

    def clean(self):
        """
        Removes all cached programming before today.
        Also removes erroneously cached programming.
        """
        if self.filename == None:
            return

        dnow = datetime.date.today()
        self.lock.acquire()
        for key in self.pdict.keys():
            try:
                p = self.pdict[key]
                if 'stop-time' not in p or 'name' not in p or \
                        self.pdict[key]['stop-time'].date() < dnow or \
                        type(p['name']) != unicode or \
                        self.pdict[key]['name'].lower() == 'onbekend':

                    del self.pdict[key]

            except LookupError:
                continue

        self.lock.release()

# end ProgramCache

class FetchURL(Thread):
    """
    A simple thread to fetch a url with a timeout
    """
    def __init__ (self, url, encoding = "default encoding"):
        Thread.__init__(self)
        self.url = url
        self.result = None
        self.encoding = encoding

    def run(self):
        try:
            self.result = self.get_page_internal(self.url, self.encoding)

        except:
            log('An unexpected error "%s" has occured while fetching page: %s\n' %  (sys.exc_info()[1], self.url), 0)
            return None

    def find_html_encoding(self, httphead, htmlhead):
        # look for the text '<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8" />'
        # in the first 600 bytes of the HTTP page
        m = re.search(r'<meta[^>]+\bcharset=["\']?([A-Za-z0-9\-]+)\b', htmlhead[:512].decode('ascii', 'ignore'))
        if m:
            return m.group(1)

        # Find a HTTP header: Content-Type: text/html; charset=UTF-8
        m = re.search(r'\bcharset=([A-Za-z0-9\-]+)\b', httphead.info().getheader('Content-Type'))
        if m:
            return m.group(1)

        return 'iso-8859-1' # the default HTTP encoding.

    def get_page_internal(self, url, encoding = "default encoding"):
        """
        Retrieves the url and returns a string with the contents.
        Optionally, returns None if processing takes longer than
        the specified number of timeout seconds.
        """
        txtdata = None
        txtheaders = {'Keep-Alive' : '300',
                      'User-Agent' : config.user_agents[random.randint(0, len(config.user_agents)-1)] }
        try:
            #fp = urllib.urlopen(url)
            rurl = urllib.Request(url, txtdata, txtheaders)
            fp = urllib.urlopen(rurl)
            bytes = fp.read()
            page = None

            try:
                encoding = self.find_html_encoding(fp, bytes)
                # log ('parse %s as %s' % (url, encoding))
                page = bytes.decode(encoding, 'replace')

            except Exception:
                log('Cannot decode url %s as %s\n' % (url, encoding))
                # 'Windows-1252'
                page = bytes.decode('Windows-1252', 'ignore') # At least gets it somewhat correct

            return page

        except (urllib.URLError) as e:
            log('Cannot open url %s: %s\n' % (url, e.reason), 1, 1)
            return None

        except (urllib.HTTPError) as e:
            log('Cannot parse url %s: code=%s\n' % (url, e.code), 1, 1)
            return None

# end FetchURL

class FetchData(Thread):
    """
    Generic Class to fetch the data

    The output is a list of programming in order where each row
    contains a dictionary with program information.

    It runs as a separate thread for every source
    """
    current_date = datetime.date.today().toordinal()

    def __init__(self, proc_id, source, detail_id, detail_url = '', isjson = False, detail_check = '', detail_processor = False):
        Thread.__init__(self)
        # Flag to stop the thread
        self.quit = False
        self.ready = False
        self.isjson = isjson
        # The ID of the source
        self.proc_id = proc_id
        # The Name of the source
        self.source = source
        # The dict name of the details etc.
        self.detail_id = detail_id
        self.detail_url = detail_url
        self.detail_check = detail_check
        self.detail_processor = detail_processor
        self.detail_queue = deque()

        self.all_channels = {}
        self.channels = {}
        self.channel_loaded = {}
        self.day_loaded = {}
        self.program_data = {}
        self.program_by_id = {}
        self.chan_count = 0

    def run(self):
        """The grabing thread"""
        # First some generic initiation that couldn't be done earlier in __init__
        # Specifics can be done in init_channels and init_json which are called here
        tdict = self.checkout_program_dict()
        try:
            self.day_loaded[0] = {}
            for day in range( config.opt_dict['offset'], (config.opt_dict['offset'] + config.opt_dict['days'])):
                self.day_loaded[0][day] = False

            for chanid in config.channels.keys():
                self.channel_loaded[chanid] = False
                self.day_loaded[chanid] ={}
                for day in range( config.opt_dict['offset'], (config.opt_dict['offset'] + config.opt_dict['days'])):
                    self.day_loaded[chanid][day] = False

                self.program_data[chanid] = []

            self.init_channels()
            if not self.source in config.sources.keys():
                config.sources[self.source] ={}
                config.sources[self.source]['ID'] = self.detail_id if (self.detail_id != '') else ''
                config.sources[self.source]['url'] = self.detail_url if (self.detail_url != '') else ''
                config.detail_ids.append(self.detail_id)

            self.init_json()
            # Load and proccess al the program pages
            try:
                self.load_pages()

            except:
                log('Fatal Error: "%s" processing the basepages from %s\n' % (sys.exc_info()[1], self.source), 0)
                log('Setting them all to being loaded, to let the other sources finish the job\n', 0)
                for chanid in self.channels.keys():
                    self.channel_loaded[chanid] = True
                    config.channels[chanid].source_data[self.proc_id] = True

            # if this is the prefered description source set the value
            for chanid in self.channels.keys():
                if config.channels[chanid].opt_dict['prefered_description'] == self.proc_id:
                    for i in range(len(self.program_data[chanid])):
                        self.program_data[chanid][i]['prefered description'] = self.program_data[chanid][i]['description']

            if self.detail_processor:
                # We process detail requests, so we loop till we are finished
                self.cookyblock = False
                while True:
                    if self.quit:
                        self.ready = True
                        break

                    # be nice to the source site
                    time.sleep(random.randint(config.nice_time[0], config.nice_time[1]))

                    # Check if all channels are ready
                    for channel in config.channels.values():
                        if channel.active and not channel.ready:
                            break

                    else:
                        # All channels are ready, so if there is nothing in the queue
                        if len(self.detail_queue) == 0:
                            # if we are tvgids.tv we wait for followup requests from tvgids.nl failures
                            if (self.proc_id == 1) and (not xml_output.channelsource[0].ready):
                                continue

                            self.ready = True
                            break

                    if len(self.detail_queue) == 0:
                        continue

                    tdict = self.detail_queue.popleft()
                    cache_id = tdict['cache_id']
                    logstring = tdict['logstring']
                    parent = tdict['parent']
                    tdict = tdict['tdict']
                    chanid = tdict['channelid']
                    if not self.cookyblock:
                        try:
                            detailed_program = self.load_detailpage(tdict)

                        except:
                            detailed_program = None
                            log('Error processing the detailpage: %s\n' % (tdict[self.detail_url]), 1)

                    else:
                        detailed_program = None

                    # It failed! If this is tvgids.nl and there is an url we'll try tvgids.tv, but first check the json page and if that failes the cache again
                    if detailed_program == None and (self.proc_id == 0):
                        try:
                            detailed_program = self.load_json_detailpage(tdict)

                        except:
                            detailed_program = None
                            log('Error processing the json detailpage: http://www.tvgids.nl/json/lists/program.php?id=%s\n' % tdict[self.detail_id][3:], 1)

                    if detailed_program == None:
                        if (self.proc_id == 0) and (cache_id != None):
                            cached_program = xml_output.program_cache.query(tdict[cache_id])
                            if cached_program[xml_output.channelsource[1].detail_check]:
                                log(u'      [cached] %s:(%3.0f%%) %s' % (parent.chan_name, parent.get_counter(), logstring), 8, 1)
                                tdict= parent.use_cache(tdict, cached_program)
                                parent.detailed_programs.append(tdict)
                                parent.fetch_count[self.proc_id] -= 1
                                parent.cache_count += 1
                                continue

                            elif tdict[xml_output.channelsource[1].detail_url] != '':
                                xml_output.channelsource[1].detail_queue.append({'tdict':tdict, 'cache_id': cache_id, 'logstring': logstring, 'parent': parent})
                                parent.fetch_count[self.proc_id] -= 1
                                parent.fetch_count[1] += 1
                                continue

                        else:
                            log(u'[fetch failed or timed out] %s:(%3.0f%%) %s' % (parent.chan_name, parent.get_counter(), logstring), 8, 1)
                            parent.detailed_programs.append(tdict)
                            parent.fetch_count[self.proc_id] -= 1
                            parent.fail_count += 1
                            continue

                    else:
                        # If this is the prefered description source for this channel, set its value
                        if config.channels[detailed_program['channelid']].opt_dict['prefered_description'] == self.proc_id:
                            detailed_program['prefered description'] = detailed_program['description']

                        detailed_program[xml_output.channelsource[self.proc_id].detail_check] = True
                        detailed_program['ID'] = detailed_program[xml_output.channelsource[self.proc_id].detail_id]
                        parent.detailed_programs.append(detailed_program)
                        if self.proc_id == 0:
                            log(u'[normal fetch] %s:(%3.0f%%) %s' % (parent.chan_name, parent.get_counter(), logstring), 8, 1)

                        elif self.proc_id == 1:
                            log(u'   [.tv fetch] %s:(%3.0f%%) %s' % (parent.chan_name, parent.get_counter(), logstring), 8, 1)

                        parent.fetch_count[self.proc_id] -= 1
                        parent.fetched_count[self.proc_id] += 1

                        # do not cache programming that is unknown at the time of fetching.
                        if tdict['name'].lower() != 'onbekend':
                            xml_output.program_cache.add(xml_output.channelsource[0].checkout_program_dict(detailed_program))

            else:
                self.ready = True

        except:
            err_obj = sys.exc_info()[2]
            log('\nAn unexpected error has occured in the %s thread: %s\n' %  (self.source, sys.exc_info()[1]), 0)
            log('The current detail url is: %s\n' % (tdict[self.detail_url]), 0)
            log('                                at line: %s, %s\n' %  (err_obj.tb_lineno, err_obj.tb_lasti), 0)

            while True:
                err_obj = err_obj.tb_next
                if err_obj == None:
                    break

                log('                   tracing back to line: %s, %s\n' %  (err_obj.tb_lineno, err_obj.tb_lasti), 0)

            log('\nIf you want assistence, please attach your configuration and log files!\n     %s\n     %s\n' % (config.config_file, config.log_file),0)

            self.ready = True
            for source in xml_output.channelsource.values():
                source.quit = True

            for channel in config.channels.values():
                channel.quit = True

            xml_output.program_cache.quit = True
            return(98)

    # Dummys to be filled in by the sub-Classes
    def init_channels(self):
        """The specifig initiation code before starting with grabbing"""
        pass

    def init_json(self):
        """The specifig initiation code if the source is json before starting with grabbing"""
        if not self.isjson:
            return

        # Define here the json structure if it's not a flat list of program dicts
        # self.jsondata = {<name>: ['listname':<list>,'keyname':<key>,'valuename':<vname>}
        # self.jsondict[<list>][<key-in-json_by_id[id][tdict['keyname']] >][<vname>] = value
        self.json_by_id = {}
        self.jsondata = {}
        self.jsondict = {}

    def get_url(self):
        """return the several url's for ordinairy, detail and channel info"""
        pass

    def get_channels(self):
        """The code for the retreiving a list of suppoted channels"""
        pass

    def load_pages(self):
        """The code for the actual Grabbing and dataprocessing"""
        if len(self.channels) == 0 :
            return

    def load_detailpage(self, tdict):
        """The code for retreiving and processing a detail page"""
        return tdict

    # Helper functions
    def checkout_program_dict(self, tdict = None):
        """
        Checkout a given dict for invalid values or
        returnsa default empty dict for storing program info
        """
        # ID generation
        # u'nl-%s' % (item['db_id'])
        # u'tv-%s' % tdict[self.detail_url].split('/')[5]
        # u'be-%s' % tdict[self.detail_url].split('/')[5]
        # u'%s-%s' % (channel,  item['unixtime'])

        # source                        tvgids.nl    tvgids.tv   rtl.nl     teveblad.be
        # dagen                              4                 14        14              7
        # channelid                    j jd hd
        # channel                                            h hd         j             h hd
        # offset                          j                     h
        # unixtime                                                           j
        # datum                           jd hd              hd                        h hd
        # start-time                    j jd                h hd                        h hd
        # stop-time                     j jd hd
        # clumpidx
        # tvgids-fetched

        # name                           j jd hd           h hd         j              h hd
        # titel aflevering                                                  j              h hd
        # season                                                              j              h hd
        # episode                                                             j              h hd
        # description                   jd hd               hd         j              h hd
        # rerun                                hd                            j              h hd
        # jaar van premiere             hd              hd                        h hd
        # country                                                                           h hd
        # originaltitle                                                                     h hd

        # genre                          j jd hd               hd                       h hd
        # subgenre                     j

        # ID                               j jd hd            h hd          j             h hd
        # url                              j                      h hd                        h hd
        # official website                                    hd
        # kijkwijzer/nicam        j jd hd                hd         j

        # credits
        #       presentatie             jd hd                hd
        #       acteurs                   jd hd                hd                          hd
        #       regisseur                jd hd                hd
        #       scenario                     hd
        #       componist                  hd

        # stereo                              hd
        # dolby                                                                              h hd
        # teletekst                          hd
        # video
        #       HD                            hd                                            h hd
        #       breedbeeld                hd
        #       blackwhite                hd


        text_values = ('source', 'channel', 'unixtime', 'prefered description', \
              'clumpidx', 'name', 'titel aflevering', 'description', 'jaar van premiere', \
              'originaltitle', 'subgenre', 'ID', 'merge-source', 'nl-ID', 'tv-ID', 'be-ID', \
              'rtl-ID', 'npo-ID', 'nl-url', 'tv-url', 'be-url', 'npo-url',  \
              'infourl', 'audio', 'star-rating', 'country', 'omroep')
        date_values = ('start-time', 'stop-time')
        bool_values = ('tvgids-fetched', 'tvgidstv-fetched', 'rerun', 'teletekst', \
              'new', 'last-chance', 'premiere')
        num_values = ('channelid', 'season', 'episode', 'offset')
        dict_values = ('credits', 'video')
        list_values = ('kijkwijzer', )
        video_values = ('HD', 'breedbeeld', 'blackwhite')

        if tdict == None:
            tdict = {}

        for key in text_values:
            if not key in tdict.keys() or tdict[key] == None:
                tdict[key] = u''

            try:
                if type(tdict[key]) != unicode:
                    tdict[key] = unicode(tdict[key])

            except:
                tdict[key] = u''

        for key in date_values:
            if not key in tdict.keys() or tdict[key] == None:
                tdict[key] = u''

        if not 'genre' in tdict.keys() or tdict['genre'] == None or tdict['genre'] == '':
            tdict['genre'] = u'overige'

        for key in bool_values:
            if not key in tdict.keys() or tdict[key] != True:
                tdict[key] = False

        for key in num_values:
            if not key in tdict.keys() or tdict[key] == None or tdict[key] == '':
                tdict[key] = u'0'

        for key in dict_values:
            if not key in tdict.keys() or not isinstance(tdict[key], dict):
                tdict[key] = {}

        for key in list_values:
            if not key in tdict.keys() or not isinstance(tdict[key], list):
                tdict[key] = []

        for subkey in tdict['credits'].keys():
            if  tdict['credits'][subkey] == None:
                tdict['credits'][subkey] = []

            for i, item in enumerate(tdict['credits'][subkey]):
                try:
                    if type(item) != unicode:
                        tdict['credits'][subkey][i] = unicode(item)

                except:
                    tdict['credits'][subkey][i] = u''

        for subkey in video_values:
            if not subkey in tdict['video'].keys() or  tdict['video'][subkey] != True:
                tdict['video'][subkey] = False

        return tdict

    def get_page(self, url, encoding = "default encoding"):
        """
        Wrapper around get_page_internal to catch the
        timeout exception
        """
        try:
            fu = FetchURL(url, encoding)
            fu.start()
            fu.join(config.global_timeout)
            page = fu.result
            if (page == None) or (page.replace('\n','') == '') or (page.replace('\n','') =='{}'):
                return None

            else:
                return page

        except Exception:
            log('get_page timed out on (>%s s): %s\n' % (config.global_timeout, url), 1, 1)
            return None

    def unescape(self, text):
        # Removes HTML or XML character references and entities from a text string.
        # source: http://effbot.org/zone/re-sub.htm#unescape-html
        #
        # @param text The HTML (or XML) source text.
        # @return The plain text, as a Unicode string

        def fixup(m):
            text = m.group(0)
            if text[:2] == "&#":
                # character reference
                try:
                    if text[:3] == "&#x":
                        return unichr(int(text[3:-1], 16))

                    else:
                        return unichr(int(text[2:-1]))

                except ValueError:
                    pass

            else:
                # named entity
                try:
                    text = unichr(name2codepoint[text[1:-1]])

                except KeyError:
                    pass

            return text # leave as is

        text = re.sub("", "...", text)
        text = re.sub("", "'", text)
        text = re.sub("", "'", text)
        return re.sub("&#?\w+;", fixup, text)

    def clean_html(self, data):
        """Process characters that interfere with ElementTree processing"""
        data = self.unescape(data)
        data = re.sub('&raquo<', '<', data)
        data = re.sub('&', ' emprsant ', data)
        return data

    def empersant(self, data):
        if data == None:
            return u''

        if type(data) != unicode:
            return unicode(re.sub(' emprsant ', '&', data))

        return re.sub(' emprsant ', '&', data)

    def add_endtimes(self, chanid, date_switch = 6):
        """
        For the sites that only give start times, add the next starttime as endtime
        date_switch is the time we asume the last program will end if started before that time
        else  we assume next midnight
        """
        if len(self.program_data[chanid]) > 0:
            for i, tdict in enumerate(self.program_data[chanid]):
                if i > 0 and type(tdict['start-time']) == datetime.datetime:
                    self.program_data[chanid][i-1]['stop-time'] =  tdict['start-time']

            # And one for the last program
            prog_date = datetime.date.fromordinal(self.current_date + self.program_data[chanid][-1]['offset'])
            if int(self.program_data[chanid][-1]['start-time'].strftime('%H')) < date_switch:
                self.program_data[chanid][-1]['stop-time'] = datetime.datetime.combine(prog_date, datetime.time(date_switch, 0,0 ,0 ,CET_CEST))

            else:
                self.program_data[chanid][-1]['stop-time'] = datetime.datetime.combine(prog_date, datetime.time(23, 59,0 ,0 ,CET_CEST))

            # remove programs that end when they start
            for tdict in self.program_data[chanid][:]:
                if tdict['start-time'] == tdict['stop-time']:
                    self.program_data[chanid].remove(tdict)

    def get_offset(self, date):
        """Return the offset from today"""
        return int(date.toordinal() -  self.current_date)

    def check_title_name(self, program):
        """
        Process Title names on Grouping issues and apply the rename table
        Return the updated Progam dict
        """
        ptitle = program['name']
        psubtitle = program['titel aflevering']
        if  ptitle == None or ptitle == '':
            return program

        # Remove a groupname if in the list
        for group in config.groupnameremove:
            if (len(ptitle) > len(group) + 3) and (ptitle[0:len(group)].lower() == group):
                p = ptitle.split(':')
                if len(p) >1:
                    log('Removing \"%s\" from \"%s\"\n' %  (group, ptitle), 64)
                    if config.write_info_files:
                        infofiles.addto_detail_list(unicode('Group removing = \"%s\" from \"%s\"' %  (group, ptitle)))

                    ptitle = "".join(p[1:]).strip()

        # Fixing subtitle both named and added to the title
        if ptitle.lower() == psubtitle.lower() and program['genre'] != 'serie/soap':
            psubtitle = ''
        if  (psubtitle != '') and (len(ptitle) > len(psubtitle)):
            lentitle = len(ptitle) - len(psubtitle)
            if psubtitle.lower().strip() == ptitle[lentitle:].lower().strip():
                ptitle = ptitle[0:lentitle].strip()
                if (ptitle[-1] == ':') or (ptitle[-1] == '-'):
                    ptitle = ptitle[0:(len(ptitle) - 1)].strip()

        # Check the Title rename list
        if ptitle.lower() in config.titlerename:
            log('Renaming %s to %s\n' % (ptitle, config.titlerename[ptitle.lower()]), 64)
            if config.write_info_files:
                infofiles.addto_detail_list(unicode('Title renaming %s to %s\n' % (ptitle, config.titlerename[ptitle.lower()])))

            ptitle = config.titlerename[ptitle.lower()]

        program['name'] = ptitle
        program['titel aflevering'] = psubtitle
        return program

    def filter_description(self,ETitem, ETfind, tdict):
        """
        Filter the description as found on the detailpages for relevant info
        and return the adapted program dict
        """
        alinea = []
        atype = []
        aheader = []

        def format_text(text):
            newtext = self.empersant(text.strip())
            newtext = re.sub('\n','', newtext)
            newtext = re.sub(' +?',' ', newtext)
            return newtext

        pcount = 0
        # We scan every alinea of the description
        for p in ETitem.findall(ETfind):
            aheader.append('')
            atype.append('')
            # Check if it has a class like 'summary'
            if p.get('class') == None:
                atype[pcount] = u''

            else:
                atype[pcount] = self.empersant(p.get('class')).strip()
                if config.write_info_files:
                    infofiles.addto_detail_list(u'%s descriptionattribute => class: %s' % (self.source, p.get('class').strip()))

            content = ''
            # Add the alinea text
            if (p.text != None) and (p.text != ''):
                content = format_text(p.text) + u' '

            # Check for further tags like <i>talic and their following text
            for d in list(p.iter()):
                if d.tag == 'span' and atype[pcount] == 'summary':
                    # On tvgids.nl, this is the genre
                    pass

                elif d.tag in ('br', 'img'):
                    # Linebreaks don't contain text and images we ignore and don't count
                    # But we want the tail text
                    pass

                elif (d.tag == 'p') or (d.text != None and 'gesponsorde link' in d.text.lower()):
                    # We don't want those
                    continue

                elif (d.text != None) and (d.text != ''):
                    if d.tag == 'strong':
                        # The first is an alineaheader
                        # or if it's the first alinea the subgenre or something like it
                        if content.strip() == '':
                            aheader[pcount] = format_text(d.text)
                        else:
                            aheader[pcount] = u''
                            content = content + format_text(d.text) + u' '

                    elif d.tag in ('i', 'em', 'a', 'b'):
                        content = content + format_text(d.text) + u' '

                    else:
                        # Unknown tag we just check for text
                        content = content + format_text(d.text) + u' '
                        if config.write_info_files:
                            infofiles.addto_detail_list(unicode('new '+ self.source+' descriptiontag => ' + \
                                                    unicode(d.tag.strip()) + ': ' + unicode(d.text.strip())))

                # and we add the text inbetween the tags
                if (d.tail != None) and d.tail != '' :
                    content = content + format_text(d.tail) + u' '

            content = content.strip()

            if re.search('geen detailgegevens be(?:kend|schikbaar)', content.lower()) \
              or (content.lower() == '') or (content.lower() == 'none'):
                # No text so unless it's the first alinea, we ignore it
                if pcount == 0:
                    alinea.append('')
                    pcount +=1
                else:
                    continue

            else:
                alinea.append(content)
                pcount +=1

        # Now we decide what to return
        if len(alinea) > 0:
            for i, v in enumerate(atype):
                if v == 'summary' and alinea[i] != '':
                    # We just go for the summary
                    description = alinea[i]
                    break

            else:
                if len(alinea) ==1:
                    # Only ony alinea
                    description = alinea[0]

                elif len(alinea) == 2 and alinea[0] == '':
                    # we go for the second alinea
                    description = alinea[1]

                # Now it gets tricky for most of the time one is general and the other is specific
                # We check if one is contained in the other
                elif len(alinea) == 2 and alinea[1] in alinea[0] :
                     description = alinea[0]

                elif len(alinea) == 2 and alinea[0] in alinea[1] :
                     description = alinea[1]

                # So we return everything
                else:
                    content = ''
                    for p in alinea:
                        if p != '':
                            content = '%s%s ' % (content, p)
                    description = content.strip()

                    if config.write_info_files:
                        strdesc = ''
                        for p in alinea:
                            strdesc = strdesc + '    <p>%s</p>\n' % p

                        strdesc = '  <div start="' + tdict['start-time'].strftime('%d %b %H:%M') + \
                                                    '" name="' + tdict['name'] + '">\n' + strdesc + '  </div>'
                        if config.write_info_files:
                            infofiles.addto_raw_string(strdesc)

            # We check to not ovrwrite an already present longer description
            if description > tdict['description']:
                tdict['description'] = description

            # use the first header as subgenre, if not already present
            if tdict['subgenre'] == '' and aheader[0] != '':
                tdict['subgenre']  = aheader[0]

        return tdict

    # Selectie functions
    def get_json_data(self, id, item):
        """Return the requested json item or None if not found"""
        if not self.isjson:
            return None

        if not id in self.json_by_id.keys():
            return None

        if item in self.json_by_id[id].keys():
            return self.unescape(self.json_by_id[id][item])

        if item in self.jsondata.keys():
            tdict = self.jsondata[item]
            if  tdict['keyname'] in self.json_by_id[id]:
                key =self.json_by_id[id][tdict['keyname']]
                if key in self.jsondict[tdict['listname']] and \
                  tdict['valuename'] in self.jsondict[tdict['listname']][key]:
                    return self.unescape(self.jsondict[tdict['listname']][key][tdict['valuename']])

    def get_programcount(self, chanid = 0, offset = None):
        """Return the programcount for given channel id and Offset"""
        if not chanid in self.channels.keys():
            return 0

        if not self.channel_loaded[chanid]:
            return 0

        if offset == None:
            if chanid == 0:
                count = 0

            else:
                return len(self.program_data[chanid])

        if not self.day_loaded[chanid][offset]:
            return 0

        pcount = 0
        for tdict in self.program_data[chanid]:
            if tdict['offset'] == offset:
                pcount += 1

        return pcount

    def get_channel(self, chanid):
        """Return program_data for given channel"""
        if not chanid in self.channels.keys():
            return []

        if not self.channel_loaded[chanid]:
            return []

        return self.program_data[chanid]

    def get_program(self, id):
        """Return program data for given program id"""
        if not id in self.program_by_id.keys():
            return self.checkout_program_dict()

        return self.program_by_id[id]

    def get_program_data(self, id, item):
        """Return value of given program id and dict key"""
        tdict = get_program(id, item)

        if item in tdict.keys():
            return tdict[item]

        else:
            return None

    # Filter/merge processes
    def parse_programs(self, chanid, mode = 0, overlap_strategy = None):
        """
        Parse a list of programs as generated by parser and
        adjust begin and end times to avoid gaps and overlap.
        Depending on the mode either:
        it's own data 'self.program_data[chanid]' (mode = 0) or
        the finally joined data 'config.channels[chanid].all_programs' (mode = 1) is parsed.
        Not setting the overlap_strategy will use the configured default.
        For inbetween parsing you best set it to 'None'
        """

        if mode == 0:
            programs = self.program_data[chanid]

        elif mode == 1:
            programs = config.channels[chanid].all_programs

        else:
            return

        for item in programs[:]:
            if item == None:
                programs.remove(item)

        if len(programs) == 0:
            return

        # good programs
        good_programs = []
        fill_programs = []

        # sort all programs by startdate, enddate
        programs.sort(key=lambda program: (program['start-time'],program['stop-time']))
        if overlap_strategy == None:
            overlap_strategy = config.channels[chanid].opt_dict['overlap_strategy']

        # next, correct for missing end time and copy over all good programming to the
        # good_programs list
        for i in range(len(programs)):

            # Try to correct missing end time by taking start time from next program on schedule
            if (programs[i]['stop-time'] == None and i < len(programs)-1):
                log('Oops, "%s" has no end time. Trying to fix...\n' % programs[i]['name'], 64)
                programs[i]['stop-time'] = programs[i+1]['start-time']

            # The common case: start and end times are present and are not
            # equal to each other (yes, this can happen)
            if programs[i]['start-time'] != None \
                and programs[i]['stop-time']  != None \
                and programs[i]['start-time'] != programs[i]['stop-time']:
                    good_programs.append(programs[i])

        # Han Holl: try to exclude programs that stop before they begin
        for i in range(len(good_programs)-1,-1,-1):
            if good_programs[i]['stop-time'] <= good_programs[i]['start-time']:
                log('Deleting invalid stop/start time: %s\n' % good_programs[i]['name'], 64)

        # Try to exclude programs that only identify a group or broadcaster and have overlapping start/end times with
        # the actual programs
        for i in range(len(good_programs)-2,-1,-1):

            if good_programs[i]['start-time'] == good_programs[i+1]['start-time'] \
                and good_programs[i]['stop-time']  == good_programs[i+1]['stop-time'] \
                and good_programs[i]['name']  == good_programs[i+1]['name']:
                    log('Deleting duplicate: %s\n' % good_programs[i]['name'], 64)
                    del good_programs[i]
                    continue

            if good_programs[i]['start-time'] <= good_programs[i+1]['start-time'] \
                and good_programs[i]['stop-time']  >= good_programs[i+1]['stop-time']:
                    log('Deleting grouping/broadcaster: %s\n' % good_programs[i]['name'], 64)
                    del good_programs[i]

        # Fix overlaps/gaps
        if overlap_strategy in ['average', 'stop', 'start', 'fill']:
            for i in range(len(good_programs)-1):

                # PdB: Fix tvgids start-before-end x minute interval overlap.  An overlap (positive or
                # negative) is halved and each half is assigned to the adjacent programmes. The maximum
                # overlap length between programming is set by the global variable 'max_overlap' and is
                # default 10 minutes. Examples:
                #
                # Positive overlap (= overlap in programming):
                #   10:55 - 12:00 Lala
                #   11:55 - 12:20 Wawa
                # is transformed in:
                #   10:55 - 11.57 Lala
                #   11:57 - 12:20 Wawa
                #
                # Negative overlap (= gap in programming):
                #   10:55 - 11:50 Lala
                #   12:00 - 12:20 Wawa
                # is transformed in:
                #   10:55 - 11.55 Lala
                #   11:55 - 12:20 Wawa

                stop  = good_programs[i]['stop-time']
                start = good_programs[i+1]['start-time']
                dt    = stop-start
                avg   = start + dt // 2
                overlap = 24*60*60*dt.days + dt.seconds

                # check for the size of the overlap
                if 0 < abs(overlap) <= config.channels[chanid].opt_dict['max_overlap']*60:
                    if overlap > 0:
                        log('"%s" and "%s" overlap %s minutes. Adjusting times.\n' % \
                            (good_programs[i]['name'],good_programs[i+1]['name'],overlap // 60), 64)
                    else:
                        log('"%s" and "%s" have gap of %s minutes. Adjusting times.\n' % \
                            (good_programs[i]['name'],good_programs[i+1]['name'],abs(overlap) // 60), 64)

                    # stop-time of previous program wins
                    if overlap_strategy == 'stop':
                       good_programs[i+1]['start-time'] = good_programs[i]['stop-time']

                    # start-time of next program wins
                    elif overlap_strategy == 'start':
                       good_programs[i]['stop-time'] = good_programs[i+1]['start-time']

                    # average the difference
                    elif overlap_strategy == 'average':
                       good_programs[i]['stop-time']    = avg
                       good_programs[i+1]['start-time'] = avg

                    # We fill it with a programinfo/commercial block
                    elif overlap_strategy == 'fill' and overlap < 0:
                        tdict = self.checkout_program_dict()
                        tdict['source'] = good_programs[i]['source']
                        tdict['channelid'] = good_programs[i]['channelid']
                        tdict['channel'] = good_programs[i]['channel']
                        tdict['name'] = config.npo_fill
                        tdict['start-time'] = good_programs[i]['stop-time']
                        tdict['stop-time'] = good_programs[i+1]['start-time']
                        tdict['offset'] = good_programs[i+1]['offset']
                        tdict['genre'] = u'overige'
                        fill_programs.append(tdict)

                    # leave as is
                    else:
                       pass

                # For NPO we fill the night gap
                elif good_programs[i]['source'] == u'npo' and overlap_strategy == 'fill' and (0 < good_programs[i]['stop-time'].hour < 6):
                    if good_programs[i]['name'] == 'Tekst-TV':
                        good_programs[i]['stop-time'] = good_programs[i+1]['start-time']

                    elif good_programs[i+1]['name'] == 'Tekst-TV':
                        good_programs[i+1]['start-time'] = good_programs[i]['stop-time']

                    else:
                        tdict = self.checkout_program_dict()
                        tdict['source'] = good_programs[i]['source']
                        tdict['channelid'] = good_programs[i]['channelid']
                        tdict['channel'] = good_programs[i]['channel']
                        tdict['name'] = 'Tekst-TV'
                        tdict['start-time'] = good_programs[i]['stop-time']
                        tdict['stop-time'] = good_programs[i+1]['start-time']
                        tdict['offset'] = good_programs[i+1]['offset']
                        tdict['genre'] = u'nieuws/actualiteiten'
                        fill_programs.append(tdict)

        # Experimental strategy to make sure programming does not disappear. All programs that overlap more
        # than the maximum overlap length, but less than the shortest length of the two programs are
        # clumped.
        if config.do_clump:
            for i in range(len(good_programs)-1):

                stop  = good_programs[i]['stop-time']
                start = good_programs[i+1]['start-time']
                dt    = stop-start
                overlap = 24*60*60*dt.days + dt.seconds

                length0 = good_programs[i]['stop-time']   - good_programs[i]['start-time']
                length1 = good_programs[i+1]['stop-time'] - good_programs[i+1]['start-time']

                l0 = length0.days*24*60*60 + length0.seconds
                l1 = length1.days*24*60*60 + length0.seconds

                if abs(overlap) >= config.channels[chanid].opt_dict['max_overlap']*60 <= min(l0,l1)*60 and \
                    'clumpidx' not in good_programs[i]   and \
                    'clumpidx' not in good_programs[i+1]:
                    good_programs[i]['clumpidx']   = '0/2'
                    good_programs[i+1]['clumpidx'] = '1/2'
                    good_programs[i]['stop-time'] = good_programs[i+1]['stop-time']
                    good_programs[i+1]['start-time'] = good_programs[i]['start-time']


        # done, nothing to see here, please move on
        if len(fill_programs) > 0:
            good_programs.extend(fill_programs)

        if mode == 0:
            self.program_data[chanid] = good_programs

        elif mode == 1:
            config.channels[chanid].all_programs = good_programs

    def merge_sources(self, chanid, other_is_dominant = False, counter = 0):
        """
        Try to match the source channel info into the tvgids.nl. For all channels except the RTL channels
        tvgids.nl is the dominant source. It provides the ID', and the best genre info, but only
        for 4 days.
        First tvgids.tv provides basic and genre info and for the remainder of their 14 days.
        For the RTL channels their own timings are better, they provide 14 days and episode info.
        So tvgids.nl provides the more detailed genre info and the ID.
        Teveblad, like RTL provides aditional episode info, but only for 7 days. They don't provide
        the dutch commercial channels. For the Belgium channels we let them be dominant.
        """

        if (not chanid in self.program_data):
            self.program_data[chanid] = []

        if (len(self.program_data[chanid]) == 0):
            return

        if len(config.channels[chanid].all_programs) == 0:
            config.channels[chanid].all_programs = self.program_data[chanid]
            return

        programs = self.program_data[chanid]
        info = config.channels[chanid].all_programs

        # 0 = Log Nothing
        # 1 = log not matched programs
        # 2 = log left over programs
        # 4 = Log All

        def matchlog(matchstr, other_prog, tvgids_prog = None, mode = 1):
            if not (mode & config.opt_dict['match_log_level']):
                return

            if tvgids_prog == None:
                log(u'%s: %s: %s: %s Genre: %s.\n' % \
                        (matchstr.rjust(20), config.channels[chanid].chan_name, other_prog['start-time'].strftime('%d %b %H:%M'), other_prog['name'], \
                        other_prog['genre']), 32)
            else:
                log(u'%s: %s: %s: %s.\n%s%s: %s.\n' % \
                        (matchstr.rjust(12), config.channels[chanid].chan_name,  other_prog['start-time'].strftime('%d %b %H:%M'), other_prog['name'] , \
                        'to tvgids.nl: '.rjust(22 + len(other_prog['channel'])), tvgids_prog['start-time'].strftime('%d %b %H:%M'), \
                        tvgids_prog['name']), 32)
        # end matchlog()

        def checkrange(crange = 0):
            checktimes = []
            if crange == 0:
                checktimes.append(0)

            for i in range(1, 6):
                checktimes.append(crange + i)
                checktimes.append(-(crange + i))

            return checktimes
        # end checkrange()

        def get_tvgids_genre(other_genre):
            genre = other_genre.lower().strip()
            if genre in ('amusement','film' ,'magazine' ,'muziek' ,'sport', 'jeugd', 'kunst en cultuur', \
              'nieuws/actualiteiten', 'serie/soap', 'informatief' ):
                return (other_genre, '')

            elif genre == 'kinderen':
                return ('jeugd', '')

            elif genre == 'kunst & cultuur':
                return 'kunst en cultuur'

            elif genre == 'nieuws':
                return ('nieuws/actualiteiten', '')

            elif genre == 'serie':
                return ('serie/soap', '')

            elif genre == 'reality':
                return ('informatief', 'realityprogramma')

            elif genre == 'documentaire':
                return ('informatief', 'documentaire')

            elif genre == 'kunst & cultuur':
                return 'kunst en cultuur'

            if config.write_info_files:
                infofiles.addto_detail_list(unicode('unknown merge genre => ' + other_genre))

            return ('overige', '')
        # end get_tvgids_genre()

        def general_renames(name):
            # Some renaming to cover diferences between the sources
            mname = name.lower()
            if self.source == 'tvgidstv':
                if chanid in ('1', '2', '3'):
                    if mname == 'nos-journaal':
                        return 'NOS Journaal'

                    if mname == 'tekst tv':
                        return 'Tekst-TV'

            elif self.source == 'teveblad':
                if chanid in ('1', '2'):
                    if mname == 'nieuws':
                        return 'NOS Journaal'

                    if mname == 'tekst tv':
                        return 'Tekst-TV'

                elif chanid == '3':
                    if mname == 'nieuws':
                        return 'NOS op 3'

                    if mname == 'tekst tv':
                        return 'Tekst-TV'

                elif chanid == '5':
                    pass

                elif chanid == '6':
                    pass

                elif chanid in ('7', '8'):
                    if mname == 'nieuws':
                        return 'BBC News'
                        #~ return 'Regional News and Weather'

                    if mname == 'het weer':
                        return 'Regional News and Weather'

                elif chanid == '9':
                    if mname == 'nieuws':
                        return 'Tagesschau'

            name = re.sub(' / ',' - ', name)
            return name
        # end general_renames()

        def match_name(other_title, tvgids_name, other_subtitle = ''):
            """
            Main process for name matching
            Returns 0 if matched on name = name
            Returns 1 if matched on name:episode = name
            Returns None if no match
            """
            def rename_to_tvgids_name(name):
                if self.source == 'tvgidstv':
                    if chanid in ('1', '2', '3'):
                        if name[0:4] == 'nos-':
                            return 'nos ' + name[4:]
                        #~ if name = 'vandaag de dag':

                if self.source == 'rtl':
                    if chanid == '4':
                        if 'name' == 'weddingplanner':
                            return 'the wedding planner'

                    elif chanid == '31':
                        pass

                    elif chanid == '46':
                        pass

                    elif chanid == '92':
                        if 'name' == 'koala broertjes':
                            return 'de koalabroertjes'

                    elif chanid == '408':
                        pass

                    elif chanid == '409':
                        pass

                    elif chanid == 'rtl-telekids':
                        pass

                elif self.source == 'teveblad':
                    if chanid == '5':
                        if name == 'het journaal':
                            return 'journaallus'

                        if name == 'dagelijkse kerst':
                            return 'dagelijkse kost'

                        if name == 'winst joker+/lotto':
                            return 'winst joker+ lotto'

                    elif chanid == '6':
                        if name == 'terzake':
                            return 'canvaslus'

                        if name == 'vranckx':
                            return 'canvaslus'

                    elif chanid in ('1', '2', '3'):
                        if name == 'nieuws':
                            return 'nos journaal'

                        if name[0:4] == 'nos-':
                            return 'nos ' + name[4:]

                    elif chanid in ('7', '8'):
                        if name == 'regional news and weather':
                            return 'weather for the week ahead'

                    elif chanid == '9':
                        if name == 'tagesschau':
                            return 'tagesthemen'

                return name
            # end channelname_rename()

            def remove_accents(name):
                name = re.sub('','a', name)
                name = re.sub('','e', name)
                name = re.sub('','i', name)
                name = re.sub('','o', name)
                name = re.sub('','u', name)
                name = re.sub('','y', name)
                name = re.sub('','a', name)
                name = re.sub('','e', name)
                name = re.sub('','i', name)
                name = re.sub('','o', name)
                name = re.sub('','u', name)
                name = re.sub('','a', name)
                name = re.sub('','e', name)
                name = re.sub('','i', name)
                name = re.sub('','o', name)
                name = re.sub('','u', name)
                name = re.sub('','y', name)
                name = re.sub('','a', name)
                name = re.sub('','e', name)
                name = re.sub('','i', name)
                name = re.sub('','o', name)
                name = re.sub('','u', name)
                name = re.sub('','a', name)
                name = re.sub('','o', name)
                name = re.sub('&','and', name)
                name = re.sub(' - ',' ', name)
                name = re.sub('\'','', name)
                name = re.sub('\"','', name)
                name = re.sub(' +?',' ', name)
                name = re.sub(' ...','...', name)
                return name
            # end remove_accents()

            def compare(nother, ntvgids, nsub = ''):
                if nother == ntvgids:
                    return 0

                if len(ntvgids.split(':')) > 1 and nsub != '':
                    ntvsplit = ntvgids.split(':')[0]
                    if nother == ntvsplit:
                        return 1

                    if len(nother) < len(ntvsplit):
                        if nother == ntvsplit[len(ntvsplit) - len(nother):]:
                            return 1

                        if nother == ntvsplit[0:len(nother)]:
                            return 1

                    if len(nother) > len(ntvsplit):
                        if nother[len(nother) - len(ntvsplit):] == ntvsplit:
                            return 1

                        elif nother[0:len(ntvsplit)] == ntvsplit:
                            return 1

                if len(nother) < len(ntvgids):
                    if nother == ntvgids[len(ntvgids) - len(nother):]:
                        return 0

                    if nother == ntvgids[0:len(nother)]:
                        return 0

                if len(nother) > len(ntvgids):
                    if nother[len(nother) - len(ntvgids):] == ntvgids:
                        return 0

                    elif nother[0:len(ntvgids)] == ntvgids:
                        return 0

                return None
            # end compare()

            other_name = other_title.lower().strip()
            other_subname = other_subtitle.lower().strip()
            tvgids_name = tvgids_name.lower().strip()
            x = compare(other_name, tvgids_name, other_subname)
            if x != None:
                return x

            x = compare(remove_accents(other_name), remove_accents(tvgids_name), remove_accents(other_subname))
            if x != None:
                return x

            x = compare(rename_to_tvgids_name(other_name), tvgids_name)
            if x != None:
                return x

            x = compare(remove_accents(rename_to_tvgids_name(other_name)), remove_accents(tvgids_name))
            if x != None:
                return x

            name_split = False
            lother_name = other_name
            rother_name = other_name
            if other_name.find(':') != -1:
                name_split = True
                lother_name = other_name.split(':')[0].strip()
                rother_name = other_name.split(':')[1].strip()

            ltvgids_name = tvgids_name
            rtvgids_name = tvgids_name
            if tvgids_name.find(':') != -1:
                name_split = True
                ltvgids_name = tvgids_name.split(':')[0].strip()
                rtvgids_name = tvgids_name.split(':')[1].strip()

            if name_split:
                if compare(rother_name, rtvgids_name) != None:
                    return 0

                if compare(remove_accents(rother_name), remove_accents(rtvgids_name)) != None:
                    return 0

                if compare(rename_to_tvgids_name(rother_name), rtvgids_name) != None:
                    return 0

                if compare(remove_accents(rename_to_tvgids_name(rother_name)), remove_accents(rtvgids_name)) != None:
                    return 0

                if compare(lother_name, ltvgids_name) != None:
                    return 0

                if compare(remove_accents(lother_name), remove_accents(ltvgids_name)) != None:
                    return 0

                if compare(rename_to_tvgids_name(lother_name), ltvgids_name) != None:
                    return 0

                if compare(remove_accents(rename_to_tvgids_name(lother_name)), remove_accents(ltvgids_name)) != None:
                    return 0

            return None
        # end match_name()

        def match_genre(other_genre, tvgids_genre, tvgids_subgenre):
            """
            Process for Genre matching
            Returns True or False
            """
            tvgids_genre = tvgids_genre.lower().strip()
            tvgids_subgenre = tvgids_subgenre.lower().strip()
            other_genre = other_genre.lower().strip()
            if  (tvgids_genre != '') and (other_genre == tvgids_genre):
                return True

            elif (other_genre == 'amusement'):
                if (tvgids_genre == 'amusement') or (tvgids_genre == 'amusment') \
                  or (tvgids_genre == 'kunst en cultuur'):
                    return True

            elif (other_genre == 'kinderen') and (tvgids_genre == 'jeugd'):
                return True

            elif (other_genre == 'magazine') and (tvgids_genre == 'informatief, amusement'):
                return True

            elif (other_genre == 'nieuws') and (tvgids_genre == 'nieuws/actualiteiten'):
                return True

            elif (other_genre == 'serie') and (tvgids_genre == 'serie/soap'):
                return True

            elif (other_genre == 'serie') and (tvgids_genre == 'film'):
                return True

            elif (other_genre == 'reality'):
                if (tvgids_genre == 'informatief'):
                    if (tvgids_subgenre == 'realityprogramma') or (tvgids_subgenre == 'realityserie'):
                        return True

            elif (other_genre == 'documentaire'):
                if (tvgids_genre == 'informatief') and (tvgids_subgenre == 'documentaire'):
                    return True

                elif (tvgids_genre == 'info') and (tvgids_subgenre == 'documentary'):
                    return True

                elif (tvgids_genre == 'natuur') and (tvgids_subgenre == 'natuurdocumentaire, natuurprogramma'):
                    return True

            return False
        # end match_genre()

        def set_main_id(tdict):

            for source in xml_output.channelsource.values():
                if tdict[source.detail_id] != '':
                    tdict['ID'] = tdict[source.detail_id]
                    break

            return tdict
        # end set_main_id()

        # tdict is from info
        def add_using_tvgids_timing(tdict, tvdict, use_other_title = False):
            """Merge the source into the main data"""
            if tdict['merge-source'] == '':
                tdict['merge-source'] = xml_output.channelsource[0].source

            if self.source == 'teveblad':
                if tvdict['titel aflevering'] != '':
                    tdict['titel aflevering']  = tvdict['titel aflevering']

                if tvdict['season'] != '0':
                    tdict['season']  = tvdict['season']

                if tvdict['episode'] != '0':
                    tdict['episode'] = tvdict['episode']

                if tvdict['jaar van premiere'] != '':
                    tdict['jaar van premiere'] = tvdict['jaar van premiere']

                if tvdict['country'] != '':
                    tdict['country'] = tvdict['country']

                if tvdict['rerun']:
                    tdict['rerun']  = True

            elif self.source == 'rtl':
                if tvdict['titel aflevering']!= '':
                    tdict['titel aflevering']  = tvdict['titel aflevering']

                if tvdict['season']!= '0':
                    tdict['season']  = tvdict['season']

                if tvdict['episode']!= '0':
                    tdict['episode'] = tvdict['episode']

                if tvdict['rerun']:
                    tdict['rerun']  = True

            elif self.source == 'tvgidstv':
                if tvdict['jaar van premiere']!= '':
                    tdict['jaar van premiere'] = tvdict['jaar van premiere']

                if tvdict['infourl']!= '':
                    tdict['infourl']  = tvdict['infourl']

            if use_other_title:
                tdict['name']  = tvdict['name']

            if len(tvdict['description']) > len(tdict['description']):
                tdict['description']  = tvdict['description']

            if tvdict['prefered description'] != '':
                tdict['prefered description']  = tvdict['prefered description']

            if tvdict['star-rating'] != '':
                tdict['star-rating']  = tvdict['star-rating']

            if len(tvdict['kijkwijzer']) > 0:
                for item in tvdict['kijkwijzer']:
                    tdict['kijkwijzer'].append(item)

            if tvdict['video']['HD']:
                tdict['video']['HD']  = True

            if tvdict['video']['breedbeeld']:
                tdict['video']['breedbeeld']  = True

            if tvdict['video']['blackwhite']:
                tdict['video']['blackwhite']  = True

            if tvdict['teletekst']:
                tdict['teletekst']  = True

            if tvdict['audio'] != '':
                tdict['audio'] = tvdict['audio']

            tdict = set_main_id(tdict)
            matched_programs.append(tdict)
            if tdict in info: info.remove(tdict)

        # end add_using_tvgids_timing()

        # tdict is from programs
        def add_using_other_timing(tdict, tvdict, add_episode_info = True):
            """Merge the main data into the source"""
            matchlog('program match', tdict, tvdict, 4)
            tdict['merge-source'] = self.source
            if tdict['stop-time'] in prog_stoptimes:
                prog_stoptimes[tdict['stop-time']]['matched'] = True
                prog_stoptimes[tdict['stop-time']]['match'] = tvdict

            tdict['genre'] = tvdict['genre']
            tdict['subgenre'] = tvdict['subgenre']

            if tvdict[xml_output.channelsource[0].detail_check]:
                tdict[xml_output.channelsource[0].detail_check]  = True

            if tvdict[xml_output.channelsource[1].detail_check]:
                tdict[xml_output.channelsource[1].detail_check]  = True

            if tvdict['infourl'] != '':
                tdict['infourl']  = tvdict['infourl']

            for source in config.sources.values():
                if source['ID'] != '':
                    if tvdict[source['ID']] != '':
                        tdict[source['ID']]  = tvdict[source['ID']]

                if source['url'] != '':
                    if tvdict[source['url']] != '':
                        tdict[source['url']]  = tvdict[source['url']]

            if add_episode_info:
                if tvdict['titel aflevering'] != '':
                    tdict['titel aflevering']  = tvdict['titel aflevering']

                if tvdict['season'] != '0':
                    tdict['season']  = tvdict['season']

                if tvdict['episode'] != '0':
                    tdict['episode']  = tvdict['episode']

                if tvdict['jaar van premiere'] != '':
                    tdict['jaar van premiere']  = tvdict['jaar van premiere']

                if tvdict['country'] != '':
                    tdict['country']  = tvdict['country']

            if len(tvdict['description']) > len(tdict['description']):
                tdict['description']  = tvdict['description']

            if tvdict['prefered description'] != '':
                tdict['prefered description']  = tvdict['prefered description']

            if tvdict['star-rating'] != '':
                tdict['star-rating']  = tvdict['star-rating']

            if len(tvdict['kijkwijzer']) > 0:
                for item in tvdict['kijkwijzer']:
                    tdict['kijkwijzer'].append(item)

            if tvdict['rerun']:
                tdict['rerun']  = True
            if tvdict['video']['HD']:
                tdict['video']['HD']  = True

            if tvdict['video']['breedbeeld']:
                tdict['video']['breedbeeld']  = True

            if tvdict['video']['blackwhite']:
                tdict['video']['blackwhite']  = True

            if tvdict['teletekst']:
                tdict['teletekst']  = True

            if tvdict['audio'] != '':
                tdict['audio'] = tvdict['audio']

            if 'credits' in tvdict:
                tdict['credits']  = tvdict['credits']

            tdict = set_main_id(tdict)
            matched_programs.append(tdict)
            if tdict in programs: programs.remove(tdict)

            try:
                pstart = tdict['start-time']
                pname = tdict['name'].lower().strip()
                prog_names[pname][pstart]['state'] = 'matched'
                prog_names[pname][pstart][xml_output.channelsource[0].detail_url]  = tvdict[xml_output.channelsource[0].detail_url]
                prog_names[pname][pstart]['genre'] = tvdict['genre']
                prog_names[pname][pstart]['subgenre'] = tvdict['subgenre']

            except Exception as e:
                pass

        # end add_using_other_timing()

        # tdict is from info
        def check_match_to_info(tdict, pi, mstart, check_overlap = True):

            x = match_name(pi['name'], tdict['name'], pi['titel aflevering'])
            if x != None:
                matchlog('program match', tdict, pi, 4)

            else:
                return False

            if check_overlap:
                try:
                    mduur = (tdict['stop-time'] - tdict['start-time']).total_seconds()
                    pduur = (pi['stop-time'] - pi['start-time']).total_seconds()
                    if pduur * 1.1 > mduur:
                        # We check for program merging in info
                        merge_match.append({'type': 1, 'tdict': tdict, 'prog': pi, 'match': x})
                        if tdict in info: info.remove(tdict)

                    elif mduur * 1.1 > pduur:
                        # We check for program merging in programs
                        merge_match.append({'type': 2, 'tdict': tdict, 'prog': pi, 'match': x})
                        if tdict in info: info.remove(tdict)

                    else:
                        add_using_tvgids_timing(tdict, pi, x)

                except:
                    pass

            if mstart in prog_starttimes: del prog_starttimes[mstart]
            return True

        # end check_match_to_programs()

        # tdict is from programs
        def check_match_to_programs(tdict, pi, mstart, check_overlap = True, add_episode_info = True):

            if match_name(tdict['name'], pi['name'], tdict['titel aflevering']) != None:
                matchlog('program match', tdict, pi, 4)
                retval =1

            elif match_genre(tdict['genre'], pi['genre'], pi['subgenre']):
                matchlog('genre match', tdict, pi, 4)
                retval =2

            else:
                return False

            if check_overlap:
                mduur = (tdict['stop-time'] - tdict['start-time']).total_seconds()
                pduur = (pi['stop-time'] - pi['start-time']).total_seconds()
                if pduur * 1.1 > mduur:
                    # We check for program merging in info
                    merge_match.append({'type': 1, 'tdict': tdict, 'info': pi})
                    if tdict in programs: programs.remove(tdict)

                elif mduur * 1.1 > pduur:
                    # We check for program merging in programs
                    merge_match.append({'type': 2, 'tdict': tdict, 'info': pi})
                    if tdict in programs: programs.remove(tdict)

                else:
                    add_using_other_timing(tdict, pi, add_episode_info)

            if mstart in info_starttimes: del info_starttimes[mstart]
            return retval

        # end check_match_to_programs()

        log('\n', 2)
        log_array =[]
        log_array.append('\n')
        if other_is_dominant:
            # This goes for the belgium/british channels from teveblad.be (programs) and the rtl channels
            log('Now merging %s (channel %s of %s):\n  %s programs from tvgids.nl into %s programs from %s\n' % \
                (config.channels[chanid].chan_name, counter, config.chan_count, len(info) , len(programs), self.source), 2)

            log_array.append('Merg statistics for %s (channel %s of %s) from tvgids.nl into %s\n' % \
                (config.channels[chanid].chan_name, counter, config.chan_count, self.source))

        else:
            # this goes for adding tvgids.tv (programs) to tvgids.nl (info) and most channels from teveblad.be (programs)
            log('Now merging %s (channel %s of %s):\n  %s programs from %s into %s programs from tvgids.nl\n' % \
                (config.channels[chanid].chan_name , counter, config.chan_count, len(programs), self.source, len(info)), 2)

            log_array.append('Merg statistics for %s (channel %s of %s) from %s into tvgids.nl\n' % \
                (config.channels[chanid].chan_name , counter, config.chan_count, self.source))

        # Do some general renaming to match tvgids.nl naming
        for i in range(0, len(programs)):
            programs[i]['name'] = general_renames(programs[i]['name'])

        # Sort both lists on starttime and get their ranges
        info.sort(key=lambda program: (program['start-time'],program['stop-time']))
        infostarttime = info[0]['start-time'] - datetime.timedelta(0, 0, 0, 0, 30)
        infoendtime = info[-1]['start-time'] + datetime.timedelta(0, 0, 0, 0, 30)

        programs.sort(key=lambda program: (program['start-time'],program['stop-time']))
        progstarttime = programs[0]['start-time'] - datetime.timedelta(0, 0, 0, 0, 30)
        progendtime = programs[-1]['start-time'] + datetime.timedelta(0, 0, 0, 0, 30)

        matched_programs = []
        generic_match = []

        # move all programs outside the range of programs to matched_programs
        # count the info names, changing them to lowercase for matching
        # and organise them by name and start-time
        info_starttimes = {}
        info_names = {}
        log_array.append('%6.0f programs in tvgids.nl for range: %s - %s, \n' % \
            (len(info), infostarttime.strftime('%d-%b %H:%M:%S'), infoendtime.strftime('%d-%b %H:%M:%S')))

        gcount = 0
        ocount = 0
        # First parse over some things we for several reasons can not match
        # And we create a list of starttimes and of names for matching
        for tdict in info[:]:
            # Passing over generic timeslots that maybe detailed in the other
            if ((self.source == 'tvgidstv') and ((chanid in ('1', '2', '3')) and  (tdict['name'].lower() == 'kro kindertijd'))) \
              or (tdict['name'].lower() == 'pause'):
                pcount = 0
                for tvdict in programs[:]:
                    if (tvdict['start-time'] >= tdict['start-time']) and (tvdict['stop-time'] <= tdict['stop-time']):
                        gcount += 1
                        pcount += 1
                        tvdict = set_main_id(tvdict)
                        tvdict['merge-source'] = self.source
                        matched_programs.append(tvdict)
                        if tvdict in programs: programs.remove(tvdict)

                # For tvgidstv we asume the details were fetched before, so we remove the slot
                # For teveblad we only remove if there is alternative content
                if not ((self.source == 'teveblad') and (pcount > 0)) or (self.source == 'tvgidstv'):
                    if tdict['merge-source'] == '':
                        tdict['merge-source'] = xml_output.channelsource[0].source

                    matched_programs.append(tdict)

                if tdict in info: info.remove(tdict)
                continue

            info_starttimes[tdict['start-time']] = tdict
            iname = tdict['name'].lower().strip()
            if not iname in info_names:
                info_names[iname] = tdict

            elif (info_names[iname]['genre'] == '') or (info_names[iname]['genre'] == 'overige'):
                info_names[iname] = tdict

            # These do not overlap in time so they cannot be matched
            if (tdict['start-time'] > progendtime) or (tdict['start-time'] < progstarttime):
                ocount += 1
                tdict = set_main_id(tdict)
                if tdict['merge-source'] == '':
                    tdict['merge-source'] = xml_output.channelsource[0].source

                matched_programs.append(tdict)
                if tdict in info: info.remove(tdict)

        # First parse over some things we for several reasons can not match
        # count the occurense of the rest and organise by name/start-time and stop-time
        prog_names = {}
        prog_stoptimes ={}
        prog_starttimes ={}
        log_array.append('%6.0f programs in %s for range: %s - %s\n' % \
            (len(programs), self.source.ljust(9), progstarttime.strftime('%d-%b %H:%M:%S'), progendtime.strftime('%d-%b %H:%M:%S')))

        log_array.append('\n')
        for tdict in programs[:]:
            # Remove generic slots from teveblad.be en move the counterparts to matched
            if (self.source == 'teveblad') and tdict['name'].lower() in config.teveblad_genericnames:
                pcount = 0
                for tvdict in info[:]:
                    if (tvdict['start-time'] >= tdict['start-time']) and (tvdict['stop-time'] <= tdict['stop-time']):
                        gcount += 1
                        pcount += 1
                        tvdict = set_main_id(tvdict)
                        if tdict['merge-source'] == '':
                            tdict['merge-source'] = xml_output.channelsource[0].source

                        matched_programs.append(tvdict)
                        if tvdict in info: info.remove(tvdict)

                # We only remove if there is alternative content
                if pcount == 0:
                    tdict['merge-source'] = self.source
                    matched_programs.append(tdict)

                if tdict in programs: programs.remove(tdict)
                continue

            prog_stoptimes[tdict['stop-time']] = tdict
            prog_stoptimes[tdict['stop-time']]['matched'] = False
            prog_starttimes[tdict['start-time']] = tdict
            prog_starttimes[tdict['start-time']]['matched'] = False
            rname = tdict['name'].lower().strip()
            if not (rname in prog_names):
                prog_names[rname] = {}
                prog_names[rname]['count'] = 0

            else:
                prog_names[rname]['count'] = prog_names[rname]['count'] + 1

            # These do not overlap in time so they cannot be matched
            if (tdict['start-time'] > infoendtime) or (tdict['start-time'] < infostarttime):
                ocount += 1
                prog_names[rname][tdict['start-time']] = {}
                prog_names[rname][tdict['start-time']]['state'] = 'to late'
                # If we are not matching with tvgids.tv we'll try to match generig
                if self.source == 'tvgidstv':
                    tdict = set_main_id(tdict)
                    tdict['merge-source'] = self.source
                    matched_programs.append(tdict)

                else:
                    tdict['merge-source'] = self.source
                    generic_match.append(tdict)

                if tdict in programs: programs.remove(tdict)

            else:
                prog_names[rname][tdict['start-time']] = {}
                prog_names[rname][tdict['start-time']]['state'] = 'no match'

        log_array.append('%6.0f programs added outside common timerange\n' % ocount)
        log_array.append('%6.0f details  added from group slots\n' % gcount)
        log_array.append('%6.0f programs left in tvgids.nl to match\n' % (len(info)))
        log_array.append('%6.0f programs left in %s to match\n' % (len(programs), self.source))
        log_array.append('\n')

        # Try to match programs outside the reach of  info to get genre
        for tdict in generic_match[:]:
            rname = tdict['name'].lower().strip()
            if rname in info_names.iterkeys():
                tdict['genre'] = info_names[rname]['genre']
                tdict['subgenre'] = info_names[rname]['subgenre']
                tdict = set_main_id(tdict)
                matched_programs.append(tdict)
                if tdict in generic_match: generic_match.remove(tdict)
                continue

            else:
                for mname in info_names.iterkeys():
                    x = match_name( tdict['name'], mname, tdict['titel aflevering'])
                    if x != None:
                        tdict['genre'] = info_names[mname]['genre']
                        tdict['subgenre'] = info_names[mname]['subgenre']
                        tdict = set_main_id(tdict)
                        matched_programs.append(tdict)
                        if tdict in generic_match: generic_match.remove(tdict)
                        break

                else:
                    if 'genre' in tdict:
                        g = get_tvgids_genre(tdict['genre'])
                        tdict['genre'] = g[0]
                        tdict['subgenre'] = g[1]

                    else:
                        tdict['genre'] ='overige'

                    tdict = set_main_id(tdict)
                    matched_programs.append(tdict)
                    if tdict in generic_match: generic_match.remove(tdict)

        # Use the other for the timings and try to match to get genre/description info from tvgids
        if other_is_dominant:
            # Fixing a possible wrong last end time in programs
            if progendtime < infoendtime:
                last_start = programs[-1]['start-time']
                last_end = programs[-1]['stop-time']
                for check in (0, 1, 2, 3, 4, 5):
                    for i in checkrange(check):
                        mstart = last_start + datetime.timedelta(0, 0, 0, 0, i)
                        if mstart in info_starttimes:
                            pi = info_starttimes[mstart]
                            if match_name(tdict['name'], pi['name'], tdict['titel aflevering']) != None:
                                programs[-1]['stop-time'] = pi['stop-time']

            ncount = 0
            gcount = 0
            rcount = 0
            # Parse twice to recheck after generic name matching
            for checkrun in (0, 1):
                # first look on matching starttime (+/- 5 min) and similar names or matching genre
                # extending the range by 5 min to 30
                merge_match =[]
                for check in range(0, 30, 5):
                    if len(programs) == 0:
                        break
                    for tdict in programs[:]:
                        mduur = (tdict['stop-time'] - tdict['start-time']).total_seconds()
                        for i in checkrange(check):
                            mstart = tdict['start-time'] + datetime.timedelta(0, 0, 0, 0, i)
                            if mstart in info_starttimes:
                                pi = info_starttimes[mstart]
                                x = check_match_to_programs(tdict, pi, mstart)
                                if x == 1:
                                    ncount += 1
                                    break

                                if x == 2:
                                    gcount += 1
                                    break

                # Check for following twins that were merged in the other (teveblad shows following parts often separate)
                for item in merge_match:
                    tdict = item['tdict']
                    pi = item['info']
                    pset = []
                    # pi (from info) is the longer one (by 10%+)
                    if item['type'] == 1:
                        pset.append(tdict)
                        for pp in programs:
                            pduur = (pp['stop-time'] - pp['start-time']).total_seconds()
                            if (pi['start-time'] < pp['start-time'] < pi['stop-time']) \
                              and (pi['start-time'] < pp['start-time'] < pi['stop-time']):
                                # Full overlap
                                pset.append(pp)

                            elif (pi['start-time'] < pp['start-time'] < pi['stop-time']):
                                # Starttime overlap more than 50%
                                if (pi['stop-time'] - pp['start-time']).total_seconds() > (0.5 * pduur):
                                    pset.append(pp)

                            elif (pi['start-time'] < pp['stop-time'] < pi['stop-time']):
                                # Stoptime overlap more than 50%
                                if (pp['stop-time'] - pi['start-time']).total_seconds() > (0.5 * pduur):
                                    pset.append(pp)

                        if len(pset) > 1:
                            for pp in pset:
                                if pp == tdict:
                                    add_using_other_timing(pp, pi)

                                else:
                                    x = check_match_to_programs(pp, pi, None, False, False)
                                    if x == 1:
                                        add_using_other_timing(pp, pi)
                                        ncount += 1

                                    elif x == 2:
                                        add_using_other_timing(pp, pi)
                                        gcount += 1

                                    else:
                                        pass
                                        # No match on name or genre

                        else:
                            add_using_other_timing(tdict, pi)

                    # tdict (from programs) is the longer one (by 10%+)
                    elif item['type'] == 2:
                        pset.append(pi)
                        for pp in info_starttimes.values():
                            pduur = (pp['stop-time'] - pp['start-time']).total_seconds()
                            if (tdict['start-time'] < pp['start-time'] < tdict['stop-time']) \
                              and (tdict['start-time'] < pp['start-time'] < tdict['stop-time']):
                                # Full overlap
                                pset.append(pp)

                            elif (tdict['start-time'] < pp['start-time'] < tdict['stop-time']) and \
                              (tdict['stop-time'] - pp['start-time']).total_seconds() > (0.5 * pduur):
                                # Starttime overlap more than 50%
                                    pset.append(pp)

                            elif (tdict['start-time'] < pp['stop-time'] < tdict['stop-time']) and \
                              (pp['stop-time'] - tdict['start-time']).total_seconds() > (0.5 * pduur):
                                # Stoptime overlap more than 50%
                                    pset.append(pp)

                        if len(pset) > 1:
                            # So we have to use the timings from info
                            for pp in pset:
                                if pp == pi:
                                    add_using_tvgids_timing(pp, tdict, True)

                                else:
                                    x = check_match_to_programs(tdict, pp, None, False, False)
                                    if x == 1:
                                        add_using_tvgids_timing(pp, tdict, True)
                                        ncount += 1

                                    elif x == 2:
                                        add_using_tvgids_timing(pp, tdict, True)
                                        gcount += 1

                                    else:
                                        pass
                                        # No match on name or genre

                        else:
                            add_using_other_timing(tdict, pi)

                # next for rtl match generic on name to get genre. But only the first run
                if checkrun > 0:
                    continue

                for tdict in programs[:]:
                    rname = tdict['name'].lower().strip()
                    if rname in info_names.iterkeys():
                        tdict['genre'] = info_names[rname]['genre']
                        tdict['subgenre'] = info_names[rname]['subgenre']
                        rcount += 1
                        continue

                    else:
                        for mname in info_names.iterkeys():
                            if match_name(tdict['name'], mname, tdict['titel aflevering']) != None:
                                tdict['genre'] = info_names[mname]['genre']
                                tdict['subgenre'] = info_names[mname]['subgenre']
                                rcount += 1
                                break

                log_array.append('%6.0f programs generically matched on name to get genre\n' % rcount)
                if rcount == 0:
                    break

            log_array.append('%6.0f programs matched on time and name\n' % ncount)
            log_array.append('%6.0f programs matched on time and genre\n' % gcount)
            log_array.append('%6.0f programs added unmatched from %s\n' % (len(programs), self.source))

            # List unmatched items to the log
            for tdict in programs[:]:
                matchlog('unmatched in %s' % self.source, tdict, None, 1)
                tdict = set_main_id(tdict)
                tdict['merge-source'] = self.source
                matched_programs.append(tdict)

            p = []
            for tdict in info_starttimes.itervalues():
                if progstarttime < tdict['start-time'] < progendtime:
                    p.append(tdict)

            p.sort(key=lambda program: (program['start-time'],program['stop-time']))
            for tdict in p:
                matchlog('left over in info', tdict, None, 2)

        # Use tvgids for the timings and only add extra info
        else:
            # Only add extra info to the tvgids info if the title matches  and the start time is in range
            ncount = 0
            merge_match =[]
            for check in range(0, 30, 5):
                if len(info) == 0:
                    break

                for tdict in info[:]:
                    pduur = (tdict['stop-time'] - tdict['start-time']).total_seconds()
                    pstart = tdict['start-time']
                    pname = tdict['name'].lower().strip()
                    for i in checkrange(check):
                        mstart = pstart + datetime.timedelta(0, 0, 0, 0, i)
                        if mstart in prog_starttimes:
                            pi = prog_starttimes[mstart]
                            if check_match_to_info(tdict, pi, mstart):
                                ncount += 1
                                break

            # Check for following twins that were merged in the other (teveblad shows following parts often separate)
            for item in merge_match:
                tdict = item['tdict']
                pi = item['prog']
                pset = []
                # pi (from programs) is the longer one (by 10%+)
                if item['type'] == 1:
                    pset.append(tdict)
                    for pp in info:
                        pduur = (pp['stop-time'] - pp['start-time']).total_seconds()
                        if (pi['start-time'] <= pp['start-time'] <= pi['stop-time']) \
                          and (pi['start-time'] <= pp['start-time'] <= pi['stop-time']):
                            # Full overlap
                            pset.append(pp)

                        elif (pi['start-time'] <= pp['start-time'] <= pi['stop-time']):
                            # Starttime overlap more than 50%
                            if (pi['stop-time'] - pp['start-time']).total_seconds() > (0.5 * pduur):
                                pset.append(pp)

                        elif (pi['start-time'] <= pp['stop-time'] <= pi['stop-time']):
                            # Stoptime overlap more than 50%
                            if (pp['stop-time'] - pi['start-time']).total_seconds() > (0.5 * pduur):
                                pset.append(pp)

                    if len(pset) > 1:
                        for pp in pset:
                            if pp == tdict:
                                add_using_tvgids_timing(pp, pi)

                            else:
                                x = check_match_to_info(pp, pi, None, False)
                                if x == 1:
                                    add_using_tvgids_timing(pp, pi)
                                    ncount += 1

                                elif x == 2:
                                    add_using_tvgids_timing(pp, pi)
                                    ncount += 1

                                else:
                                    pass
                                    # No match on name or genre

                    else:
                        add_using_tvgids_timing(tdict, pi, item['match'])

                # tdict (from info) is the longer one (by 10%+)
                elif item['type'] == 2:
                    pset.append(pi)
                    for pp in prog_starttimes.values():
                        pduur = (pp['stop-time'] - pp['start-time']).total_seconds()
                        if (tdict['start-time'] <= pp['start-time'] <= tdict['stop-time']) \
                          and (tdict['start-time'] <= pp['start-time'] <= tdict['stop-time']):
                            # Full overlap
                            pset.append(pp)

                        elif (tdict['start-time'] <= pp['start-time'] <= tdict['stop-time']) and \
                          (tdict['stop-time'] - pp['start-time']).total_seconds() > (0.5 * pduur):
                            # Starttime overlap more than 50%
                                pset.append(pp)

                        elif (tdict['start-time'] <= pp['stop-time'] <= tdict['stop-time']) and \
                          (pp['stop-time'] - tdict['start-time']).total_seconds() > (0.5 * pduur):
                            # Stoptime overlap more than 50%
                                pset.append(pp)

                    if len(pset) > 1:
                        # So we have to use the timings from programs
                        for pp in pset:
                            if pp == pi:
                                add_using_other_timing(pp, tdict, True)

                            else:
                                x = check_match_to_info(tdict, pp, None, False)
                                if x == 1:
                                    add_using_other_timing(pp, tdict, True)
                                    ncount += 1

                                elif x == 2:
                                    add_using_other_timing(pp, tdict, True)
                                    ncount += 1

                                else:
                                    pass
                                    # No match on name or genre

                    else:
                        add_using_tvgids_timing(tdict, pi, True)

            log_array.append('%6.0f programs matched on time and name\n' % ncount)
            log_array.append('%6.0f programs added unmatched from info\n' % len(info))

            # List unmatched items to the log
            for tdict in info[:]:
                matchlog('unmatched in info', tdict, None, 1)
                tdict = set_main_id(tdict)
                if tdict['merge-source'] == '':
                    tdict['merge-source'] = xml_output.channelsource[0].source

                matched_programs.append(tdict)

            p = []
            for tdict in prog_starttimes.itervalues():
                if infostarttime < tdict['start-time'] < infoendtime:
                    p.append(tdict)

            p.sort(key=lambda program: (program['start-time'],program['stop-time']))
            for tdict in p:
                matchlog('left over in %s' % self.source, tdict, None , 2)

        config.log_lock.acquire()
        for item in log_array:
            log(item, 4, 3, True)

        log('\n', 4, 3, True)
        config.log_lock.release()

        config.channels[chanid].all_programs = matched_programs
        try:
            infofiles.write_fetch_list(matched_programs, chanid, self.source, True)

        except:
            pass

# end FetchData

class tvgids_JSON(FetchData):
    """
    Get all available days of programming for the requested channels
    from the tvgids.nl json pages. Based on FetchData
    """
    def init_channels(self):
        """ Detail Site layout oud
            <head>
            <body>
                <div id="container">
                    <div id="header">
                    <div id="content">
                        <div id="content-header">Title</div>
                        <div id="content-col-left">
                            <div id="prog-content">Description</div>
                        <div id="content-col-right">
                            <div id="prog-info">
                                <div id="prog-info-content">
                                    <ul id="prog-info-content-colleft">
                                        <li><strong>Titel:</strong>Nederland Waterland</li>
                                            ...
                                    <ul id="prog-info-content-colright">
                                        <li><strong>Jaar van premiere:</strong>2014</li>
                                            ...
                                        <li><strong>Bijzonderheden:</strong>Teletekst ondertiteld, Herhaling, HD 1080i</li>
                                <div id="prog-info-footer"></div>
                            </div>
                        </div>
                    </div>
                    <div class="clearer"></div>
                </div>
                <div id="footer-container">
            </body>
            Nieuw
            <head>
            <body>
                <input type="hidden" id="categoryClass" value="">
                    <input type="hidden" id="notAllowedClass" value="">
                        <input type="hidden" id="notAllowedTitles" value="">
                            <div class="container pagecontainer">
                                <div class="row">
                                    <div class="col-md-8">
                                        <div id="prog-content">
                                            <div id="prog-video">
                                            ...
                                            </div>
                                            <div class="programmering">
                                                <h1>Harry Potter and the Goblet of Fire<span><sup>(2005)</sup></span></h1>
                                                <div class="clear:both;"></div>
                                                <script type="text/javascript" src="http://tvgidsassets.nl/v43/js/nlziet.js"></script>
                                                <div class="programmering_details">
                                                    <ul>
                                                        <li class="datum_tijd"> 1 mei 2015, 22:45 - 23:55 uur</li>
                                                        <li class="zender"><img src="http://tvgidsassets.nl/img/channels/53x27/36.png">SBS 6</li>
                                                    </ul>
                                                </div>
                                                <div style="clear:both"></div>
                                            </div>
                                            <div class="clear"></div>
                                                ...
                                            <div class="clear"></div>
                                            <p class="summary">
                                                <span class="articleblock articleblock_color_fantasy">
                                            FANTASY
                                                </span>
                                                                    Harry Potter gaat zijn vierde schooljaar in op de magische school Zweinstein, waar dit jaar het belangrijke internationale Triwizard Tournament wordt gehouden. Deze competitie is alleen voor de oudere en ervaren tovenaarsstudenten, maar toch komt Harry's naam boven als een van de deelnemers. Harry weet niet hoe dit mogelijk is, maar wordt toch gedwongen om mee te doen. Terwijl Harry zich voorbereidt op de gevaarlijke wedstrijd, wordt duidelijk dat de boosaardige Voldemort en zijn aanhangers steeds sterker worden en het nog altijd op zijn leven hebben gemunt. Dit nieuws is niet het enige wat Harry de rillingen bezorgt, hij heeft ook nog geen afspraakje voor het gala.
                                            </p>
                                            <p></p>
                                            <br class="brclear" />
                                            <div class="programmering_info_socials">
                                                ...
                                            </div>
                                            <br class="clear" />
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </body>
        """

        # These regexes fetch the relevant data out of thetvgids.nl pages, which then will be parsed to the ElementTree
        self.retime = re.compile(r'(\d\d\d\d)-(\d+)-(\d+) (\d+):(\d+)(?::\d+)')
        self.tvgidsnlprog = re.compile('<div id="prog-content">(.*?)<div id="prog-banner-content">',re.DOTALL)
        self.tvgidsnltitle = re.compile('<div class="programmering">(.*?)</h1>',re.DOTALL)
        self.tvgidsnldesc = re.compile('<p(.*?)</p>',re.DOTALL)
        self.tvgidsnldesc2 = re.compile('<div class="tekst col-sm-12">(.*?)</div>',re.DOTALL)
        self.tvgidsnldetails = re.compile('<div class="programmering_info_detail">(.*?)</div>',re.DOTALL)

        self.channels = {}
        self.url_channels = ''

        for chanid, channel in config.channels.iteritems():
            self.program_data[chanid] = []
            if channel.active and channel.source_id[self.proc_id] != '':
                self.channels[chanid] = channel.source_id[self.proc_id]
                if self.url_channels == '':
                    self.url_channels = channel.source_id[self.proc_id]

                else:
                    self.url_channels  = '%s,%s' % (self.url_channels, channel.source_id[self.proc_id])

    def get_url(self, type = 'channels', offset = 0, id = None):

        tvgids = 'http://www.tvgids.nl/'
        tvgids_json = tvgids + 'json/lists/'

        if type == 'channels':
            return  u'%schannels.php' % (tvgids_json)

        elif type == 'day':
            return '%sprograms.php?channels=%s&day=%s' % (tvgids_json, self.url_channels, offset)

        elif (id == None) or id == '':
            return ''

        elif type == 'detail':
            return u'%sprogramma/%s/' % (tvgids, id)

        elif type == 'json_detail':
            return u'%sprogram.php?id=%s/' % (tvgids_json, id)

    def match_to_date(self, timestring, time, program):
        match = self.retime.match(self.unescape(timestring))

        if match:
            return datetime.datetime(int(match.group(1)),int(match.group(2)),\
                    int(match.group(3)),int(match.group(4)),int(match.group(5)),
                    tzinfo=CET_CEST)
        else:
            log("Can not determine %s for %s\n" % (time,program))
            return None

    def get_channels(self):
        """
        Get a list of all available channels and store these
        in all_channels.
        """

        # download the json feed
        total = self.get_page(self.get_url())
        if total == None:
            log("Don't write configuration file\n")
            return 69  # EX_UNAVAILABLE

        channel_list = json.loads(total)

        # and create a file with the channels
        self.all_channels ={}
        for channel in channel_list:
            # the json data has the channel names in XML entities.
            chanid = channel['id']
            self.all_channels[chanid] = {}
            self.all_channels[chanid]['name'] = self.unescape(channel['name']).strip()

    def load_pages(self):

        if config.opt_dict['offset'] > 4:
            for chanid in self.channels.keys():
                self.channel_loaded[chanid] = True
                config.channels[chanid].source_data[self.proc_id] = True

            return

        if len(self.channels) == 0 :
            return

        dl = {}
        dd = {}
        for chanid in self.channels.keys():
            dl[chanid] =[]
            dd[chanid] =[]

        first_fetched = False
        channel_cnt = 0

        for retry in (0, 1):
            for offset in range(config.opt_dict['offset'], min((config.opt_dict['offset'] + config.opt_dict['days']), 4)):
                if self.quit:
                    return

                # Check if it is allready loaded
                if self.day_loaded[0][offset]:
                    continue

                channel_cnt += 1
                log('\n', 2)
                log('Now fetching %s channels from tvgids.nl\n    (day %s of %s).\n' % (len(self.channels), offset, config.opt_dict['days']), 2)

                channel_url = self.get_url('day', offset)

                if first_fetched:

                    # be nice to tvgids.nl
                    time.sleep(random.randint(config.nice_time[0], config.nice_time[1]))
                    first_fetched = True

                # get the raw programming for the day
                strdata = self.get_page(channel_url)
                if strdata == None or strdata.replace('\n','') == '{}':
                    log("No data on tvgids.nl for day=%d\n" % (offset))
                    continue

                # Just let the json library parse it.
                for chanid, v in json.loads(strdata).iteritems():
                    # Most channels profide a list of program dicts, some a numbered dict
                    try:
                        if isinstance(v, dict):
                            v=list(v.values())

                        elif not isinstance(v, (list,tuple)):
                            raise TypeError

                    except (TypeError, LookupError):
                        log("Unsubscriptable content from channel url: %r\n" % channel_url)
                        continue
                    # remove the overlap at daychange and seperate the channels
                    for p in v:
                        if not p in dl[chanid]:
                            dd[chanid].append(p)

                self.day_loaded[0][offset] = True
                for chanid in self.channels.keys():
                    if len(dd) > 0:
                        self.day_loaded[chanid][offset] = True
                        dl[chanid].extend(dd[chanid])
                        dd[chanid] =[]

        for chanid in self.channels.keys():
            if len(dl[chanid]) == 0:
                log('No data on tvgids.nl for channel:%s\n' % (config.channels[chanid].chan_name))
                config.channels[chanid].source_data[self.proc_id] = None
                continue

            # item is a dict, like:
            # {
            #  u'db_id': u'12379780',
            #  u'titel': u'Der unauff\xe4llige Mr. Crane'
            #  u'genre': u'Film',
            #  u'soort': u'Zwarte komedie',
            #  u'kijkwijzer': u'',
            #  u'artikel_id': None,
            #  u'artikel_titel': None,
            #  u'artikel_tekst': None,
            #  u'artikel_foto': None,
            #  u'datum_start': u'2012-03-12 01:20:00',
            #  u'datum_end': u'2012-03-12 03:05:00',
            # }

            # parse the list to adjust to what we want
            for item in dl[chanid]:
                tdict = self.checkout_program_dict()
                if (item['db_id'] != '') and (item['db_id'] != None):
                    tdict[self.detail_id] = u'nl-%s' % (item['db_id'])
                    self.json_by_id[tdict[self.detail_id]] = item
                    tdict['ID'] = tdict[self.detail_id]

                tdict['source'] = self.source
                tdict['channelid'] = chanid
                tdict['channel']  = config.channels[chanid].chan_name
                tdict[self.detail_url] = self.get_url(type= 'detail', id = item['db_id'])

                # The Title
                tdict['name'] = self.unescape(item['titel'])
                tdict = self.check_title_name(tdict)
                if  tdict['name'] == None or tdict['name'] == '':
                    log('Can not determine program title for "%s"\n' % tdict[self.detail_url])
                    continue

                # The timing
                tdict['start-time'] = self.match_to_date(item['datum_start'],"begintijd", tdict['name'])
                tdict['stop-time']  = self.match_to_date(item['datum_end'], "eindtijd", tdict['name'])
                if tdict['start-time'] == None or tdict['stop-time'] == None:
                    continue

                tdict['offset'] = self.get_offset(tdict['start-time'])

                tdict['genre'] = self.unescape(item['genre']) if ('genre' in item and item['genre'] != None) else ''
                tdict['subgenre'] = self.unescape(item['soort']) if ('soort' in item and item['soort'] != None) else ''
                if  ('kijkwijzer' in item and not (item['kijkwijzer'] == None or item['kijkwijzer'] == '')):
                    for k in item['kijkwijzer']:
                        if k in config.kijkwijzer.keys() and k not in tdict['kijkwijzer']:
                            tdict['kijkwijzer'].append(k)

                self.program_by_id[tdict[self.detail_id]] = tdict
                self.program_data[chanid].append(tdict)
                config.genre_list.append((tdict['genre'].lower(), tdict['subgenre'].lower()))
                #~ if config.write_info_files:
                    #~ if 'artikel_id' in item and item['artikel_id'] != '':
                        #~ infofiles.addto_detail_list(unicode('tvgids.nl json:%s artikel id => %s' % (item['db_id'], item['artikel_id'])))

                    #~ if 'artikel_titel' in item and item['artikel_titel'] != '':
                        #~ infofiles.addto_detail_list(unicode('tvgids.nl json:%s artikel titel => %s' % (item['db_id'], item['artikel_titel'])))

                    #~ if 'artikel_tekst' in item and item['artikel_tekst'] != '':
                        #~ infofiles.addto_detail_list(unicode('tvgids.nl json:%s artikel tekst => %s' % (item['db_id'], item['artikel_tekst'])))

                    #~ if 'artikel_foto' in item and item['artikel_foto'] != '':
                        #~ infofiles.addto_detail_list(unicode('tvgids.nl json:%s artikel foto => %s' % (item['db_id'], item['artikel_foto'])))


            self.program_data[chanid].sort(key=lambda program: (program['start-time'],program['stop-time']))
            self.parse_programs(chanid, 0, 'None')
            self.channel_loaded[chanid] = True
            config.channels[chanid].source_data[self.proc_id] = True
            try:
                infofiles.write_fetch_list(self.program_data[chanid], chanid, self.source)

            except:
                pass

    def load_detailpage(self, tdict):

        try:
            strdata = self.get_page(tdict[self.detail_url])
            if strdata == None:
                log('Page %s returned no data\n' % (tdict[self.detail_url]), 1)
                return

            if re.search('<div class="cookie-backdrop">', strdata):
                self.cookyblock = True
                log('Cooky block page encountered. Falling back to json\n', 1)
                return

            strdata = '<div>\n' +  self.tvgidsnlprog.search(strdata).group(1)
            if strdata == None:
                log('Page %s returned no data\n' % (tdict[self.detail_url]), 1)
                return

            if re.search('[Gg]een detailgegevens be(?:kend|schikbaar)', strdata):
                strtitle = ''
                strdesc = ''

            else:
                # They sometimes forget to close a <p> tag
                strdata = re.sub('<p>', '</p>xxx<p>', strdata, flags = re.DOTALL)
                strtitle = self.tvgidsnltitle.search(strdata)
                if strtitle == None:
                    strtitle = ''

                else:
                    # There are titles containing '<' (eg. MTV<3) which interfere. Since whe don't need it we remove the title
                    strtitle = re.sub('<h1>.*?<span>', '<h1><span>', strtitle.group(0), flags = re.DOTALL)
                    strtitle = strtitle + '\n</div>\n'

                strdesc = ''
                for d in self.tvgidsnldesc.findall(strdata):
                    strdesc += '<p%s</p>\n' % d

                strdesc = '<div>\n' + strdesc + '\n</div>\n'

                d = self.tvgidsnldesc2.search(strdata)
                if d != None:
                    d = re.sub('</p>xxx<p>', '<p>', d.group(0), flags = re.DOTALL)
                    strdesc += d + '\n'

            strdetails = self.tvgidsnldetails.search(strdata)
            if strdetails == None:
                strdetails = ''

            else:
                strdetails = strdetails.group(0)

            strdata = (self.clean_html('<root>\n' + strtitle + strdesc + strdetails + '\n</root>\n')).strip().encode('utf-8')
            htmldata = ET.fromstring(strdata)

        except Exception as e:
            log('Fetching page %s returned an error: %s at line: %s\n' % (tdict[self.detail_url], sys.exc_info()[1], sys.exc_info()[2].tb_lineno), 1)
            if config.write_info_files:
                infofiles.write_raw_string('Error: %s at line %s\n\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
                infofiles.write_raw_string('<root>\n' + strtitle + strdesc + strdetails + '\n</root>\n')

            # if we cannot find the description page,
            # go to next in the loop
            return None

        # We scan every alinea of the description
        try:
            tdict = self.filter_description(htmldata, 'div/p', tdict)

        except:
            log('Error processing the description from: %s\n' % (tdict[self.detail_url]), 1)
            if config.write_info_files:
                infofiles.write_raw_string('Error: %s at line %s\n\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
                infofiles.write_raw_string('<root>\n' + strdesc + '\n</root>\n')

        try:
            if htmldata.find('div/h1/span/sup') != None:
                tmp = htmldata.find('div/h1/span/sup').text
                if tmp != None:
                    tmp = re.sub('\(', '', tmp)
                    tdict['jaar van premiere'] = re.sub('\)', '', tmp).strip()

        except Exception as e:
            if config.write_info_files:
                infofiles.write_raw_string('Error: %s at line %s\n\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
                infofiles.write_raw_string(strdata)

        # We scan all the details
        for d in htmldata.findall('div/ul/li'):
            try:
                ctype = self.empersant(d.find('span[@class="col-lg-3"]').text).strip().lower()
                if ctype[-1] == ':':
                    ctype = ctype[0:len(ctype)-1]

                if ctype == 'kijkwijzer':
                    content = ''
                    for k in d.find('span[@class="col-lg-9 programma_detail_info kijkwijzer_img"]'):
                        item = {'text':k.get('alt', '') ,'icon':k.get('src', '')}
                        if item['text'] != '' or item['icon'] != '':
                            for kk, kw in config.kijkwijzer.items():
                                if (kw['text'] == item['text'] or kw['icon'] == item['icon']) and kk not in tdict['kijkwijzer']:
                                    tdict['kijkwijzer'].append(kk)
                                    break

                else:
                    content = self.empersant(d.find('span[@class="col-lg-9 programma_detail_info"]').text).strip()

            except Exception as e:
                if config.write_info_files:
                    infofiles.write_raw_string('Error: %s at line %s\n%s\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno, d))
                    infofiles.write_raw_string(strdata)

                continue

            try:
                if content == '':
                    continue

                if ctype == 'genre':
                    tdict['genre'] = content.title()

                # Parse persons and their roles for credit info
                elif ctype in config.roletrans:
                    if not config.roletrans[ctype] in tdict['credits']:
                        tdict['credits'][config.roletrans[ctype]] = []
                    persons = content.split(',');
                    for name in persons:
                        if name.find(':') != -1:
                            name = name.split(':')[1]

                        if name.find('-') != -1:
                            name = name.split('-')[0]

                        if name.find('e.a') != -1:
                            name = name.split('e.a')[0]

                        if not self.unescape(name.strip()) in tdict['credits'][config.roletrans[ctype]]:
                            tdict['credits'][config.roletrans[ctype]].append(self.unescape(name.strip()))

                # Add extra properties, while at the same time checking if we do not uncheck already set properties
                elif ctype == 'kleur':
                    tdict['video']['blackwhite'] = (content.find('zwart/wit') != -1)

                elif ctype == 'bijzonderheden':
                    if config.write_info_files:
                        infofiles.addto_detail_list(unicode(ctype + ' = ' + content))

                    content = content.lower()
                    if tdict['video']['breedbeeld'] == False:
                        tdict['video']['breedbeeld'] = (content.find('breedbeeld') != -1)
                    if tdict['video']['HD'] == False:
                        tdict['video']['HD'] = (content.find('hd 1080i') != -1)
                    if tdict['video']['blackwhite'] == False:
                        tdict['video']['blackwhite'] = (content.find('zwart/wit') != -1)
                    if tdict['teletekst'] == False:
                        tdict['teletekst'] = (content.find('teletekst') != -1)
                    if content.find('stereo') != -1: tdict['audio'] = 'stereo'
                    if tdict['rerun'] == False:
                        tdict['rerun'] = (content.find('herhaling') != -1)

                elif ctype == 'nl-url':
                    tdict['infourl'] = content

                elif (ctype not in tdict) and (ctype.lower() not in ('zender', 'datum', 'uitzendtijd', 'titel')):
                    # In unmatched cases, we still add the parsed type and content to the program details.
                    # Some of these will lead to xmltv output during the xmlefy_programs step
                    if config.write_info_files:
                        infofiles.addto_detail_list(unicode('new tvgids.nl detail => ' + ctype + ': ' + content))

                    tdict[ctype] = content

            except Exception as e:
                if config.write_info_files:
                    infofiles.write_raw_string('Error: %s at line %s\n\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
                    infofiles.write_raw_string(strdata)

        tdict['ID'] = tdict[self.detail_id]
        tdict[self.detail_check] = True
        return tdict

    def load_json_detailpage(self, tdict):
        try:
            # We first get the json url
            url = 'http://www.tvgids.nl/json/lists/program.php?id=%s' % tdict[self.detail_id][3:]
            strdata = self.get_page(url)
            if strdata == None or strdata.replace('\n','') == '{}':
                return None

            detail_data = json.loads(strdata)

        except Exception as e:
            # if we cannot find the description page,
            # go to next in the loop
            return None

        for ctype, content in detail_data.items():
            if ctype in ('db_id', 'titel', 'datum', 'btijd', 'etijd', 'zender_id'):
                # We allready have these or we don use them
                continue

            if content == '':
                continue

            if ctype == 'genre':
                tdict['genre'] = content

            if  ctype == 'kijkwijzer':
                for k in content:
                    if k in config.kijkwijzer.keys() and k not in tdict['kijkwijzer']:
                        tdict['kijkwijzer'].append(k)

            elif ctype == 'synop':
                content = re.sub('<p>', '', content)
                content = re.sub('</p>', '', content)
                content = re.sub('<br/>', '', content)
                content = re.sub('<strong>.*?</strong>', '', content)
                content = re.sub('<.*?>', '', content)
                content = re.sub('\\r\\n', '\\n', content)
                content = re.sub('\\n\\n\\n', '\\n', content)
                content = re.sub('\\n\\n', '\\n', content)
                if tdict['subgenre'].lower().strip() == content[0:len(tdict['subgenre'])].lower().strip():
                    content = content[len(tdict['subgenre'])+1:]
                if content > tdict['description']:
                    tdict['description'] = self.unescape(content)

            # Parse persons and their roles for credit info
            elif ctype in config.roletrans:
                if not config.roletrans[ctype] in tdict['credits']:
                    tdict['credits'][config.roletrans[ctype]] = []
                persons = content.split(',');
                for name in persons:
                    if name.find(':') != -1:
                        name = name.split(':')[1]

                    if name.find('-') != -1:
                        name = name.split('-')[0]

                    if name.find('e.a') != -1:
                        name = name.split('e.a')[0]

                    if not self.unescape(name.strip()) in tdict['credits'][config.roletrans[ctype]]:
                        tdict['credits'][config.roletrans[ctype]].append(self.unescape(name.strip()))

            else:
                if config.write_info_files:
                    infofiles.addto_detail_list(unicode('new tvgids.nl json detail => ' + ctype + ': ' + content))

        tdict['ID'] = tdict[self.detail_id]
        tdict[self.detail_check] = True
        return tdict

# end tvgids_JSON

class tvgidstv_HTML(FetchData):
    """
    Get all available days of programming for the requested channels
    from the tvgids.tv page. Based on FetchData Class
    """
    def init_channels(self):
        """ General Site layout
            <head>
            <body><div id="wrap"><div class="container"><div class="row">
                            <div class="span16">
                            <div class="span47 offset1">
                                een of meer
                                <div class="section">
                                    ...
                            <div class="span30 offset1">
                <div id="footer">

        Channel listing:
            <div class="section-title">
                contains the grouping name (Nederlands, Vlaams, ...)
            </div>
            <div class="section-content"><div class="section-item channels"><div class="section-item-content">
                        each contain groupings of up to four channels
                        <a href="/zenders/nederland-1" title="TV Gids NPO 1" class="">
                            <div class="channel-icon sprite-channel-1"></div><br />
                           <div class="channel-name ellipsis">NPO 1</div>
                        </a>
            </div></div></div>

        Program listing:
            <div class="section-content">
                contains for each program
                <a href="/tv/hart-van-nederland" title="Hart van Nederland"></a>
                <a href="/tv/hart-van-nederland/12568262" title="Hart van Nederland" class="section-item posible-progress-bar" rel="nofollow">
                    <div class="content">
                        <div class="channel-icon sprite-channel-8"></div>
                        <span class="section-item-title">
                                                                05:25
                                                                Hart van Nederland
                        </span>
                        <div class="clearfix"></div>
                    </div>
                </a>
            </div>

        Detail layout
            <div class="section-title">
                <h1>Navy NCIS</h1>
                <a class="channel-icon sprite-channel-8 pull-right" href="/zenders/net-5" title="TV Gids NET 5"></a>
            </div>
            <div class="section-content">
                <div class="section-item gray">
                    <img class="pull-right large" src="http://images.cdn.tvgids.tv/programma/square_iphone_hd_TVGiDStv_navy-ncis.jpg" alt="Navy NCIS" title="Navy NCIS" />
                    <dl class="dl-horizontal program-details">
                        <dt>Datum</dt><dd>Ma 29 december 2014 </dd>
                        <dt>Tijd</dt><dd>19:35 tot 20:30</dd>
                        <dt>    Name    </dt><dd>    Content    </dd>
                                   ...
                    </dl>
                    <div class="program-details-social">
                        ...
                    </div>
                    <p>                description                     </p>
                </div>
            </div>
        """

        # These regexes are used to get the time offset (whiche day they see as today)
        self.fetch_datecontent = re.compile('<div class="section-title select-scope">(.*?)<div class="section-content">',re.DOTALL)
        # These regexes fetch the relevant data out of thetvgids.tv pages, which then will be parsed to the ElementTree
        self.getcontent = re.compile('<div class="span47 offset1">(.*?)<div class="span30 offset1">',re.DOTALL)
        self.daydata = re.compile('<div class="section-content">(.*?)<div class="advertisement">',re.DOTALL)
        self.detaildata = re.compile('<div class="section-title">(.*?)<div class="advertisement">',re.DOTALL)

        for chanid, channel in config.channels.iteritems():
            self.program_data[chanid] = []
            if channel.active and channel.source_id[self.proc_id] != '':
                self.channels[chanid] = channel.source_id[self.proc_id]

    def get_url(self, channel = None, offset = 0, href = None):

        tvgidstv_url = 'http://www.tvgids.tv'

        if href == None and channel == None:
            return u'%s/zenders/' % tvgidstv_url

        if href == None:
            return u'%s/zenders/%s/%s' % (tvgidstv_url, channel, offset)

        if href == '':
            return ''

        else:
            return u'%s%s' % (tvgidstv_url, self.unescape(href))

    def check_date(self, page_data, channel, offset):

        # Check on the right offset for appending the date to the time. Their date switch is aroud 6:00
        dnow = datetime.date.today().strftime('%d %b').split()
        dlast = datetime.date.fromordinal(self.current_date - 1).strftime('%d %b').split()

        if page_data == None:
            log("Skip channel=%s on tvgids.tv!, day=%d. No data\n" % (channel, offset))
            return None

        d = self.fetch_datecontent.search(page_data)
        if d == None:
            log('Unable to veryfy the right offset on .\n' )
            return None

        try:
            d = self.fetch_datecontent.search(page_data).group(1)
            d = self.clean_html(d)
            htmldata = ET.fromstring( ('<div>' + d).encode('utf-8'))

        except:
            log('Unable to veryfy the right offset on .\n' )
            return None

        dd = htmldata.find('div/a[@class="today "]/br')
        if dd == None:
            dd = htmldata.find('div/a[@class="today"]/br')

        if dd == None:
            dd = htmldata.find('div/a[@class="today active"]/br')

        if dd.tail == None:
            log('Unable to veryfy the right offset on .\n' )
            return None

        d = dd.tail.strip().split()
        if int(dnow[0]) == int(d[0]):
            return offset

        elif int(dlast[0]) == int(d[0]):
            return offset - 1

        else:
            log("Skip channel=%s, day=%d. Wrong date!\n" % (channel, offset))
            return None

    def get_channels(self):
        """
        Get a list of all available channels and store these
        in all_channels.
        """

        try:
            strdata = self.get_page(self.get_url())
            if strdata == None:
                return

            strdata = self.clean_html('<div>' + self.getcontent.search(strdata).group(1)).encode('utf-8')
            htmldata = ET.fromstring(strdata)

        except Exception as e:
            return None

        self.all_channels ={}
        for changroup in htmldata.findall('div[@class="section"]'):
            group_name = self.empersant(changroup.findtext('div[@class="section-title"]')).strip()
            for chan in changroup.findall('div[@class="section-content"]/div[@class="section-item channels"]/div[@class="section-item-content"]/a'):
                chanid = chan.get('href')
                if chanid == None:
                    continue

                chanid = re.split('/', chanid)[2]
                name = self.empersant(chan.findtext('div[@class="channel-name ellipsis"]'))
                self.all_channels[chanid] = {}
                self.all_channels[chanid]['name'] = name
                self.all_channels[chanid]['group'] = 10
                for id in config.chan_groups.keys():
                    if group_name == config.chan_groups[id]:
                        self.all_channels[chanid]['group'] = id
                        break

    def match_genre(self, dtext, tdict):
        if dtext.lower() in config.tvtvcattrans.keys():
            tdict['genre'] = config.tvtvcattrans[dtext.lower()].capitalize()
            tdict['subgenre'] = dtext

        # Now we try to match the genres not found in tvtvcattrans
        else:
            if 'jeugd' in dtext.lower():
                tdict['genre'] = u'Jeugd'

            elif 'muziek' in dtext.lower():
                tdict['genre'] = u'Muziek'

            elif 'sport' in dtext.lower():
                tdict['genre'] = u'Sport'

            elif 'nieuws' in dtext.lower():
                tdict['genre'] = u'Nieuws/Actualiteiten'

            elif 'natuur' in dtext.lower():
                tdict['genre'] = u'Natuur'

            elif 'cultuur' in dtext.lower():
                tdict['genre'] = u'Kunst en Cultuur'

            elif 'kunst' in dtext.lower():
                tdict['genre'] = u'Kunst en Cultuur'

            elif 'wetenschap' in dtext.lower():
                tdict['genre'] = u'Wetenschap'

            elif 'medisch' in dtext.lower():
                tdict['genre'] = u'Wetenschap'

            elif 'film' in dtext.lower():
                tdict['genre'] = u'Film'

            elif 'spel' in dtext.lower():
                tdict['genre'] = u'Amusement'

            elif 'show' in dtext.lower():
                tdict['genre'] = u'Amusement'

            elif 'quiz' in dtext.lower():
                tdict['genre'] = u'Amusement'

            elif 'praatprogramma' in dtext.lower():
                tdict['genre'] = u'Magazine'

            elif 'magazine' in dtext.lower():
                tdict['genre'] = u'Magazine'

            elif 'documentair' in dtext.lower():
                tdict['genre'] = u'Informatief'

            elif 'serie' in dtext.lower():
                tdict['genre'] = u'Serie/Soap'

            elif 'soap' in dtext.lower():
                tdict['genre'] = u'Serie/Soap'

            elif 'drama' in dtext.lower():
                tdict['genre'] = u'Serie/Soap'

            elif 'thriller' in dtext.lower():
                tdict['genre'] = u'Serie/Soap'

            elif 'komedie' in dtext.lower():
                tdict['genre'] = u'Serie/Soap'

            elif 'western' in dtext.lower():
                tdict['genre'] = u'Serie/Soap'

            else:
                tdict['genre'] = u'overige'
                if config.write_info_files and not tdict['channelid'] in ('29', '438',):
                    infofiles.addto_detail_list(unicode('unknown tvgids.tv genre => ' + dtext + ' on ' + tdict['channel']))

            tdict['subgenre'] = dtext
            # And add them to tvtvcattrans (and tv_grab_nl_py.set for later reference
            # But not for Discovery Channel or TLC as that is garbage
            if not (tdict['genre'] == u'overige' and tdict['channelid'] in ('29', '438',)):
                config.tvtvcat.append((dtext.lower().strip(), tdict['genre']))

        return tdict

    def load_pages(self):
        try:
            for retry in (0, 1):
                channel_cnt = 0
                for chanid in self.channels.keys():
                    channel_cnt += 1
                    failure_count = 0
                    if self.quit:
                        return

                    channel = self.channels[chanid]
                    # Start from the offset but skip the days allready fetched by tvgids.nl
                    # Except when append_tvgidstv is False
                    if config.channels[chanid].opt_dict['append_tvgidstv']:
                        fetch_range = []
                        for i in range( config.opt_dict['offset'], (config.opt_dict['offset'] + config.opt_dict['days'])):
                            if not xml_output.channelsource[0].day_loaded[chanid][i]:
                                fetch_range.append(i)

                    else:
                        fetch_range = range( config.opt_dict['offset'], (config.opt_dict['offset'] + config.opt_dict['days']))

                    if len(fetch_range) == 0:
                        config.channels[chanid].source_data[self.proc_id] = None
                        continue

                    # Tvgids.tv shows programs per channel per day, so we loop over the number of days
                    # we are required to grab
                    for offset in fetch_range:
                        # Check if it is allready loaded
                        if self.day_loaded[chanid][offset] != False or \
                          (config.channels[chanid].opt_dict['append_tvgidstv'] and xml_output.channelsource[0].day_loaded[chanid][offset]):
                            continue

                        log('\n', 2)
                        log('Now fetching %s(xmltvid=%s%s) from tvgids.tv\n    (channel %s of %s) for day %s of %s.\n' % \
                            (config.channels[chanid].chan_name, (config.channels[chanid].opt_dict['compat'] and '.tvgids.nl' or ''), \
                            chanid, channel_cnt, len(self.channels), offset, config.opt_dict['days']), 2)
                        # get the raw programming for the day
                        try:
                            channel_url = self.get_url(channel, offset)
                            strdata = self.get_page(channel_url)

                            if strdata == None:
                                log("Skip channel=%s on tvgids.tv, day=%d. No data!\n" % (config.channels[chanid].chan_name, offset))
                                failure_count += 1
                                continue

                        except:
                            log('Error: "%s" reading the tvgids.tv basepage for channel=%s, day=%d.\n' % (sys.exc_info()[1]))
                            failure_count += 1
                            continue


                        # Check on the right offset for appending the date to the time. Their date switch is aroud 6:00
                        x = self.check_date(strdata, config.channels[chanid].chan_name, offset)
                        if x == None:
                            log("Skip channel=%s on tvgids,tv, day=%d. Wrong date!\n" % (config.channels[chanid].chan_name, offset))
                            failure_count += 1
                            continue

                        date_offset = x
                        scan_date = datetime.date.fromordinal(self.current_date + date_offset)
                        last_program = datetime.datetime.combine(datetime.date.fromordinal(self.current_date + date_offset - 1), datetime.time(0, 0, 0 ,0 ,CET_CEST))

                        # and extract the ElementTree
                        try:
                            strdata =self.daydata.search(strdata).group(1)
                            strdata = self.clean_html(strdata)
                            htmldata = ET.fromstring( ('<div><div>' + strdata).encode('utf-8'))

                        except Exception as e:
                            log('Error extracting ElementTree for channel:%s day:%s on tvgids.tv\n' % (config.channels[chanid].chan_name, offset))
                            if config.write_info_files:
                                infofiles.write_raw_string('Error: %s at line %s\n\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
                                infofiles.write_raw_string(u'<div><div>' + strdata + u'\n')

                            self.day_loaded[chanid][offset] = None
                            continue

                        try:
                            for p in htmldata.findall('div/a[@class]'):
                                tdict = self.checkout_program_dict()
                                tdict['source'] = u'tvgidstv'
                                tdict['channelid'] = chanid
                                tdict['channel'] = config.channels[chanid].chan_name
                                tdict[self.detail_url] = self.get_url(href = p.get('href'))
                                tdict[self.detail_id] = u'tv-%s' % tdict[self.detail_url].split('/')[5]  if (tdict[self.detail_url] != '') else ''

                                # The Title
                                tdict['name'] = self.empersant(p.get('title'))
                                tdict = self.check_title_name(tdict)
                                if  tdict['name'] == None or tdict['name'] == '':
                                    log('Can not determine program title for "%s"\n' % tdict[self.detail_url])
                                    continue

                                # Get the starttime and make sure the midnight date change is properly crossed
                                start = p.findtext('div[@class="content"]/span[@class="section-item-title"]').split()[0]
                                if start == None or start == '':
                                    log('Can not determine starttime for "%s"\n' % tdict['name'])
                                    continue

                                prog_time = datetime.time(int(start.split(':')[0]), int(start.split(':')[1]), 0 ,0 ,CET_CEST)
                                if datetime.datetime.combine(scan_date, prog_time) < last_program:
                                    date_offset = date_offset +1
                                    scan_date = datetime.date.fromordinal(self.current_date + date_offset)

                                tdict['offset'] = date_offset
                                tdict['start-time'] = datetime.datetime.combine(scan_date, prog_time)
                                last_program = tdict['start-time']

                                m = p.findtext('div[@class="content"]/span[@class="label"]')
                                # span = "IMDB * n.n"
                                if m != None:
                                    dd = unicode(m.split(':')[1])
                                    if dd != '':
                                        tdict['star-rating'] = dd

                                d = p.findtext('div[@class="content"]/p')
                                # p      = "dd/mm - IMDB * n.n - <genre>, beschrijving"
                                if d != None:
                                    dd = d.split(',')
                                    tdict['description'] = self.empersant(d[len(dd[0])+1:]).strip()
                                    dd = self.empersant(dd[0]).split('-')
                                    tdict = self.match_genre(self.empersant(unicode(dd[-1])), tdict)

                                    if tdict['star-rating'] == '' and len(dd) > 1:
                                        ddd = dd[-2].split('*')
                                        if ddd[0].strip() == 'IMDB':
                                            tdict['star-rating'] = unicode(ddd[1].strip())

                                # and append the program to the list of programs
                                self.program_data[chanid].append(tdict)

                        except:
                            log('Error processing tvgids.tv data for channel:%s day:%s\n' % (config.channels[chanid].chan_name, offset))
                            log('Error: %s, line:%s\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
                            continue

                        self.day_loaded[chanid][offset] = True
                        # be nice to tvgids.tv
                        time.sleep(random.randint(config.nice_time[0], config.nice_time[1]))

                    if len(self.program_data) == 0:
                        log('No data for channel:%s on tvgids.tv\n' % (config.channels[chanid].chan_name))
                        config.channels[chanid].source_data[self.proc_id] = None
                        continue

                    # Add starttime of the next program as the endtime
                    self.program_data[chanid].sort(key=lambda program: (program['start-time']))
                    self.add_endtimes(chanid, 6)

                    for tdict in self.program_data[chanid]:
                        self.program_by_id[tdict[self.detail_id]] = tdict

                    if failure_count == 0 or retry == 1:
                        self.channel_loaded[chanid] = True
                        self.parse_programs(chanid, 0, 'None')
                        config.channels[chanid].source_data[self.proc_id] = True

                        try:
                            infofiles.write_fetch_list(self.program_data[chanid], chanid, self.source)

                        except:
                            pass

        except:
            log('Error: "%s" at line \n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
            for chanid in self.channels.keys():
                self.channel_loaded[chanid] = True
                config.channels[chanid].source_data[self.proc_id] = True

    def load_detailpage(self, tdict):

        try:
            strdata = self.get_page(tdict[self.detail_url])
            if strdata == None:
                return

            strdata = self.clean_html('<root><div><div class="section-title">' + self.detaildata.search(strdata).group(1) + '</root>').encode('utf-8')
            htmldata = ET.fromstring(strdata)

        except Exception as e:
            if config.write_info_files:
                infofiles.write_raw_string('Error: %s at line %s\n\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
                infofiles.write_raw_string(strdata + '\n')

            # if we cannot find the description page,
            # go to next in the loop
            return None

        # We scan every alinea of the description
        try:
            tdict = self.filter_description(htmldata, 'div/div/div/p', tdict)

        except:
            log('Error processing the description from: %s\n' % (tdict[self.detail_url]), 1)

        data = htmldata.find('div/div[@class="section-content"]')
        datatype = u''
        try:
            for d in data.find('div/dl'):
                if d.tag == 'dt':
                    datatype = self.empersant(d.text.lower())

                elif d.tag == 'dd':
                    dtext = self.empersant(d.text).strip() if (d.text != None) else ''
                    if datatype in ('datum', 'tijd', 'uitzending gemist', 'officile twitter', 'twitter hashtag', 'deel-url'):
                        continue

                    elif datatype == 'genre':
                        if dtext == '':
                            continue

                        tdict = self.match_genre(dtext, tdict)

                    elif datatype == 'jaar':
                        tdict['jaar van premiere'] = dtext

                    elif datatype in config.roletrans:
                        tdict['credits'][config.roletrans[datatype]] = []
                        persons = dtext.split(',');
                        for name in persons:
                            if name.find(':') != -1:
                                name = name.split(':')[1]

                            if name.find('-') != -1:
                                name = name.split('-')[0]

                            if name.find('e.a') != -1:
                                name = name.split('e.a')[0]

                            tdict['credits'][config.roletrans[datatype]].append(name.strip())

                    elif datatype == 'imdb':
                        dd = d.find('a')
                        if dd == None:
                            continue

                        durl = self.empersant(dd.get('href', ''))
                        if durl != '':
                            tdict['infourl'] = durl

                        stars = unicode(dd.text.strip())
                        if stars != '' and tdict['star-rating'] == '':
                            tdict['star-rating'] = stars

                    elif datatype== 'officile website':
                        if d.find('a') == None:
                            continue

                        durl = self.empersant(d.find('a').get('href', ''))
                        if durl != '':
                            tdict['infourl'] = durl

                    else:
                        if dtext != '':
                            if config.write_info_files:
                                infofiles.addto_detail_list(unicode('new tvgids.tv text detail => ' + datatype + '=' + dtext))

                            tdict[datatype] = dtext

                        elif d.find('div') != None and d.find('div').get('class') != None:
                            if config.write_info_files:
                                infofiles.addto_detail_list(unicode('new tvgids.tv div-class detail => ' + datatype + '=' + d.find('div').get('class')))

                            tdict[datatype] = unicode(d.find('div').get('class'))

                        elif d.find('a') != None and d.find('a').get('href') != None:
                            if config.write_info_files:
                                infofiles.addto_detail_list(unicode('new tvgids.tv a-href detail => ' + datatype + '=' + d.find('a').get('href')))

                            tdict[datatype] = unicode(d.find('a').get('href'))

                        elif config.write_info_files:
                            infofiles.addto_detail_list(unicode('new tvgids.tv empty detail => ' + datatype))

                elif config.write_info_files:
                    infofiles.addto_detail_list(unicode('new tvgids.d-tag => ' + d.tag))

        except:
            log('Error processing tvgids.tv detailpage:%s\n' % (tdict[self.detail_url]))
            log('Error: %s, line:%s\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
            return

        tdict['ID'] = tdict[self.detail_id]
        tdict[self.detail_check] = True

        return tdict

# end tvgidstv_HTML()

class rtl_JSON(FetchData):
    """
    Get all available days of programming for the requested channels
    from the rtl.nl json page. Based on FetchData
    """
    def init_channels(self):
        """ json Layout
            {
            "schedule": [
                {"abstract_key":"       ","season_key":"        ","episode_key":"       ","station":"   ","rerun":false,"unixtime":1421278680}, ...
            ],
            "library": [{
                "abstracts": [
                    {"abstract_key":"   ","name":"Up All Night"}, ...
                ],
                "seasons": [
                    {"season_key":"273426","season_number":"1","name":"Seizoen 1"}, ...
                ],
                "episodes": [
                    {"episode_key":"    ","episode_number":"10","name":"Week off","nicam":"ALt","synopsis":"                    ."}, ...
                ]}
            ]}
        """

        self.page_loaded = False
        self.schedule = {}

        for chanid, channel in config.channels.iteritems():
            self.program_data[chanid] = []
            if channel.active and channel.source_id[self.proc_id] != '':
                self.channels[chanid] = channel.source_id[self.proc_id]
                self.schedule[channel.source_id[self.proc_id]] =[]

    def init_json(self):

        self.json_by_id = {}
        self.jsondata = {}
        self.jsondict = {}
        self.jsondict['abstracts'] = {}
        self.jsondict['seasons'] = {}
        self.jsondict['episodes'] = {}
        self.jsondata = {'abstract_name': {'listname':'abstracts','keyname':'abstract_key','valuename':'name'}, \
                                   'season':                {'listname':'seasons','keyname':'season_key','valuename':'season_number'}, \
                                   'season_name':      {'listname':'seasons','keyname':'season_key','valuename':'name'}, \
                                   'episode':              {'listname':'episodes','keyname':'episode_key','valuename':'episode_number'}, \
                                   'episode_name':    {'listname':'episodes','keyname':'episode_key','valuename':'name'}, \
                                   'description':      {'listname':'episodes','keyname':'episode_key','valuename':'synopsis'}, \
                                   'nicam':                  {'listname':'episodes','keyname':'episode_key','valuename':'nicam'}}

    def get_url(self, abstract = None, days = 0):

        rtl_general = 'http://www.rtl.nl/system/s4m/tvguide/guide_for_one_day.xml?output=json'
        rtl_abstract = 'http://www.rtl.nl/system/s4m/tvguide/guide_for_one_abstract.xml?output=json'

        if abstract == None:
            channels = ''
            for chanid in self.channels.values():
                if len(channels) == 0:
                    channels = chanid

                else:
                    channels = '%s,%s' % (channels, chanid)

            return '%s&days_ahead=%s&days_back=%s&station=%s' % \
                ( rtl_general, (config.opt_dict['offset'] + config.opt_dict['rtldays'] -1), - config.opt_dict['offset'], channels)

        else:
            return '%s&abstract_key=%s&days_ahead=%s' % ( rtl_abstract, abstract, days)

    def get_channels(self):

        self.all_channels = {'RTL4': {'name': 'RTL 4', 'icon': 'logo_rtl4_med_dark.png', 'group': 1},
                                         'RTL5': {'name': 'RTL 5', 'icon': 'logo_rtl5.png', 'group': 1},
                                         'RTL7': {'name': 'RTL 7', 'icon': 'logo_rtl7_trans.png', 'group': 1},
                                         'RTL8': {'name': 'RTL 8', 'icon': 'logo_rtl8.png', 'group': 1},
                                         'RTLL': {'name': 'RTL Lounge', 'icon': 'logo_rtllounge.png', 'group': 7},
                                         'RTCR': {'name': 'RTL Crime', 'icon': 'logo_rtlcrime.png', 'group': 7},
                                         'RTLT': {'name': 'RTL Telekids', 'icon': 'logo_telekids.png', 'group': 7}}

    def load_pages(self):

        if len(self.channels) == 0 :
            return

        log('\n', 2)
        log('Now fetching %s channels from rtl.nl for %s days.\n' %  (len(self.channels), config.opt_dict['rtldays']), 2)

        channel_url = self.get_url()

        # get the raw programming for the day
        strdata = self.get_page(channel_url)

        if strdata == None or strdata.replace('\n','') == '{}':
            # Wait a while and try again
            time.sleep(random.randint(config.nice_time[0], config.nice_time[1]))
            strdata = self.get_page(channel_url)
            if strdata == None or strdata.replace('\n','') == '{}':
                log("Error loading rtl json data\n")
                return False

        # Just let the json library parse it.
        total = json.loads(strdata)
        # and find relevant programming info
        schedules = total['schedule']
        for r in schedules:
            self.schedule[r['station']].append(r)

        library = total['library'][0]

        for i in library['abstracts']:
            self.jsondict['abstracts'][i['abstract_key']] = i

        for i in library['seasons']:
           self.jsondict['seasons'][i['season_key']] = i

        for i in library['episodes']:
            self.jsondict['episodes'][i['episode_key']] = i

        self.page_loaded = True

        for chanid, channel in self.channels.iteritems():
            if len( self.schedule[channel]) == 0:
                config.channels[chanid].source_id[self.proc_id] = None
                continue

            for item in self.schedule[channel]:
                tdict = self.checkout_program_dict()
                tdict[self.detail_id] = u'%s-%s' % (channel,  item['unixtime'])
                self.json_by_id[tdict[self.detail_id]] = item
                tdict['source'] = 'rtl'
                tdict['channelid'] = chanid
                tdict['channel']  = config.channels[chanid].chan_name

                # The Title
                tdict['name'] = self.get_json_data(tdict[self.detail_id],'abstract_name')
                if  tdict['name'] == None or tdict['name'] == '':
                    log('Can not determine program title\n')
                    continue

                # The timing
                tdict['unixtime']  =int( item['unixtime'])
                tdict['start-time']  = datetime.datetime.fromtimestamp(tdict['unixtime'], CET_CEST)
                tdict['offset'] = self.get_offset(tdict['start-time'])
                tdict['rerun']  = (item['rerun'] == 'true')

                # The Season Number
                season = self.get_json_data(tdict[self.detail_id],'season')
                tdict['season'] = season if (season != None) else '0'

                # The Episode Number, SubTitle and Descriptionseason
                episode = self.get_json_data(tdict[self.detail_id],'episode')
                tdict['episode'] = episode if (episode != None) else '0'

                subtitle = self.get_json_data(tdict[self.detail_id],'episode_name')
                tdict['titel aflevering'] = subtitle if ((subtitle != None) and (subtitle != tdict['name'])) else ''
                tdict = self.check_title_name(tdict)

                description = self.get_json_data(tdict[self.detail_id],'description')
                tdict['description'] = description if (description != None) else ''

                nicam = self.get_json_data(tdict[self.detail_id],'nicam')
                if '16' in nicam:
                    tdict['kijkwijzer'].append('4')

                elif '12' in nicam:
                    tdict['kijkwijzer'].append('3')

                elif '9' in nicam:
                    tdict['kijkwijzer'].append('9')

                elif '6' in nicam:
                    tdict['kijkwijzer'].append('2')

                elif 'AL' in nicam:
                    tdict['kijkwijzer'].append('1')

                for k in ('g', 'a', 's', 't', 'h', 'd'):
                    if 'k' in nicam:
                        tdict['kijkwijzer'].append(k)

                self.program_data[chanid].append(tdict)

            # Add starttime of the next program as the endtime
            self.program_data[chanid].sort(key=lambda program: (program['start-time']))
            self.add_endtimes(chanid, 7)

            for tdict in self.program_data[chanid]:
                self.program_by_id[tdict[self.detail_id]] = tdict

            self.parse_programs(chanid, 0, 'None')
            self.channel_loaded[chanid] = True
            for day in range( config.opt_dict['offset'], (config.opt_dict['offset'] + config.opt_dict['rtldays'])):
                self.day_loaded[chanid][day] = True

            config.channels[chanid].source_data[self.proc_id] = True
            try:
                infofiles.write_fetch_list(self.program_data[chanid], chanid, self.source)

            except:
                pass

# end rtl_JSON

class teveblad_HTML(FetchData):
    """
    Get all available days of programming for the requested channels
    from the teveblad.be page. Based on FetchData
    """
    def init_channels(self):
        """ Site layout
            <head>
            <body>
                <div id="mainbox"></div>
                    <div>
                        <div class="epg_container">
                            <div class="epg_content" style="padding:10px 0 10px 0;">
                                <div id="epg" class="epg view_channels" baseurl="/tv-gids/{SELECTED_DATE}/zenders/npo-3" api="http://www.teveblad.be/api/teveblad/">
                                    <div id="epg_c">
                                        <div id="genrechanneloverview">
                                            <div id="smallleftcol">
                                                <div class="greyrounded">
                                                    <h2>
                                                        <a href="http://www.teveblad.be/tv-gids/2015-01-16/zendergroep/hoofd-zenders">Hoofdzenders</a>
                                                    </h2>
                                                    <a href="/tv-gids/2015-01-16/zenders/een">
                                                        <img src="http://s4.cdn.sanomamedia.be/a/epg/q100/w60/h/39043/een-nl.jpg" width="60" height="60" title="n" />
                                                    </a>
                                                        ...
                                                    <div class="clear20"></div>
                                                        ...
                                                </div>
                                            </div>
                                            <div id="middlecolchaine">
                                                <h1>
                                                    <img src="http://s3.cdn.sanomamedia.be/a/epg/q100/w50/h/1165805/npo-3.jpg" width="50" height="50" title="NPO 3" align="absmiddle" />&nbsp;&nbsp;NPO 3
                                                </h1>
                                                <div id="event_cbbc555459a8cfdd20178ab831d515d9" class="programme">
                                                    <div class="c">
                                                        <div class="l">
                                                            <span class="starttime">22u20</span>
                                                        </div>
                                                        <div class="r" class="toowide">
                                                            <p>
                                                                <span class="title">
                                                                    <a href="http://www.teveblad.be/tv-gids/programma/1250435/millennium-mannen-die-vrouwen-haten-1-2-seizoen-1-aflevering-1-6">Millennium</a>
                                                                </span><br />
                                                                <span class="title_episode" style="font-style:italic;">Mannen die vrouwen haten (1/2)</span>
                                                            </p>
                                                            <p class="desc_short">Misdaadserie</p>
                                                            <p class="basicinfo">
                                                                (<span class="year">2009</span>, <span class="country">DEU, DNK, NOR, SWE</span>) -
                                                                <span class="season">Season 1 (1/6)</span>
                                                            </p>
                                                            <div class="desc h">
                                                                <p>Onderzoeksjournalist Mikael Blomkvist krijgt een ongewone opdracht. De rijke industrieel Henrik Vanger vraagt hem zijn familiegeschiedenis neer te schrijven...</p>
                                                            </div>
                                                            <p class="picons">
                                                                <span class="genre series curvyIgnore">
                                                                    <a href="http://www.teveblad.be/tv-gids/2015-01-16/genres/serie">Serie</a>
                                                                </span>
                                                                <div class="clear"></div>
                                                            </p>
                                                        </div>
                                                        <div class="clear"></div>
                                                    </div>
                                                </div>
                                                    ...
        Detailpage (not implemented)
            <head>
            <body>
                <div id="mainbox"></div>
                <div>
                    <div>
                        <div id="content" class="narrowcolumn">
                            <div class="dialog">
                                <div class="content_rounded">
                                    <div id="epg_gridselector" class="program_detail_header"></div>
                                    <div class="epg programdetail">
                                        <div class="program_detail">
                                            <div><h2>Zaterdag 17 januari 2015 14u00</h2></div>
                                            <div class="programdetailsblock">
                                                <p class="basicinfo">
                                                    <h3>Care and Protection</h3>
                                                    <p>
                                                        <span class="season">Seizoen 1 (1/3)</span>
                                                    </p>
                                                    <p class="desc_short">Misdaadserie.</p>
                                                        (<span class="year">1992</span>,<span class="country">GBR</span>)
                                                </p>
                                                <p class="picons">
                                                    <span class="picon" title="Herhaling">HERH</span>
                                                    <div class="clear"></div>
                                                </p>
                                                <p class="picons">
                                                    <div class="clear"></div>
                                                </p>
                                                <div class="clear"></div>
                                                <p class="desc">Samen met detective Clive Barnard gaat Jack Frost op zoek naar een vermist meisje. Haar moeder is de prostitutie in gestapt om de rekeningen te kunnen betalen. Tijdens het onderzoek stoten Frost en Barnard op een misdaad die dertig jaar geleden werd begaan. Op het thuisfront heeft Frost het emotioneel erg zwaar met de hopeloze strijd van zijn vrouw tegen een ongeneeslijke ziekte...</p>
                                            </div>
                                            <div class="clear"></div>
                                            <div class="roles">
                                                <div class="group">
                                                    <p class="title_h2">Acteurs</p>
                                                    <ul>
                                                        <li>David Jason <span class="character">(D.I. Jack Frost)</span></li>
                                                        <li>Bruce Alexander <span class="character">(Superintendent Mullett)</span></li>
                                                        <li>Matt Bardock <span class="character">(DC Barnard)</span></li>
                                                        <li>Claire Hackett <span class="character">(Linda Uphill)</span></li>
                                                        <li>Ralph Nossek <span class="character">(Gerald Powell)</span></li>
                                                        <li>Lindy Whiteford <span class="character">(Shirley Fisher)</span></li>
                                                        <li>Helen Blatch <span class="character">(Annie)</span></li>
                                                    </ul>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div id="sidebar">
                    </div>
                    <div class="clear"></div>
                </div>
                <footer id="footer"></div>
            </body>
        """

        self.datecheckdata = re.compile('<input id="epg_dateselector".*?data-value="([0-9]+)-([0-9]+)-([0-9]+)".*?/>',re.DOTALL)
        self.channeldata = re.compile('<div id="smallleftcol">(.*?)<div id="middlecolchaine">',re.DOTALL)
        self.progdata = re.compile('<div id="middlecolchaine">(.*?)<div id="epg_grid_view">channels</div>',re.DOTALL)
        self.groupdata = re.compile('<div id="epg_channel_headers">(.*?)<div id="epg_scroller_right">.*?' + \
                                                    '<div id="epg_channels">(.*?)<div id="epg_scroller">',re.DOTALL)
        self.seasondata = re.compile('Season ([0-9]+) \(([0-9]+)/([0-9]+)\)',re.DOTALL)

        basepath = 'div[@id="mainbox"]/div/div[@class="epg_container"]/div[@class="epg_content"]/' + \
                                    'div[@id="epg"]/div[@id="epg_c"]/div[@id="genrechanneloverview"]/'
        self.channelpath = basepath + 'div[@id="smallleftcol"]/div[@id="class="greyrounded"]'

        for chanid, channel in config.channels.iteritems():
            self.program_data[chanid] = []
            if channel.active and channel.source_id[self.proc_id] != '':
                self.channels[chanid] = channel.source_id[self.proc_id]

    def get_url(self, date = '', channel = '', get_group = False):

        teveblad_zoeken = 'http://www.teveblad.be/tv-gids/'
        if type(date) == datetime.datetime or type(date) == datetime.date:
            date = date.strftime('%Y-%m-%d') + u'/'
            if date == datetime.date.today().strftime('%Y-%m-%d') + u'/':
                date = ''

        if get_group:
            return u'%s%szendergroep/%s' % (teveblad_zoeken,  date, channel)

        else:
            return u'%s%szenders/%s' % (teveblad_zoeken,  date, channel)

    def check_date(self, return_date, search_date):
        try:
            if return_date.group(1) == search_date.strftime('%Y'):
                if return_date.group(2) == search_date.strftime('%m'):
                    if return_date.group(3) == search_date.strftime('%d'):
                        return True

        except Exception as e:
            log('Invalid page returned by teveblad.be\n')
            log('return_date: %s search_date: %s\n' % (return_date, search_date))
            return False

        log('Wrong date %s-%s-%s returned from teveblad.be, %s requested\n' % \
             (return_date.group(1),return_date.group(2) ,return_date.group(3) , search_date.strftime('%Y-%m-%d')))

        return False

    def read_channelfile(self):
        try:
            if not os.access(u'%s/teveblad_channels.html' % (config.xmltv_dir), os.F_OK):
                if os.access(u'%s/teveblad_channels.html' % (config.hpath), os.F_OK):
                    log('copying %s/teveblad_channels.html to %s\n' % (config.hpath, config.xmltv_dir))
                    shutil.copy(u'%s/teveblad_channels.html' % (config.hpath), config.xmltv_dir)
                else:
                    log('teveblad channel info file: %s/teveblad_channels.html not found\n' % (config.hpath))
                    return None

            f = config.open_file( u'%s/teveblad_channels.html' % config.xmltv_dir)
            if f == None:
                return None

            #~ htmldata = ET.parse(f)
            strdata = u''
            for byteline in f.readlines():
                line = config.get_line(f, byteline)
                strdata += self.clean_html(line)
            f.close()

            return ET.fromstring(strdata.encode('utf-8'))

        except:
            log('error parsing %s/teveblad_channels.html\n' % (config.xmltv_dir))
            return None

    def get_channels(self):
        """
        Get a list of all available channels and store these
        in all_channels.
        """

        try:
            strdata = self.get_page(self.get_url())
            if strdata == None:
                htmldata = self.read_channelfile()
                if htmldata == None:
                    return None

            else:
                strdata = self.clean_html('<div>' + self.channeldata.search(strdata).group(1)).encode('utf-8')
                htmldata = ET.fromstring(strdata)

        except Exception as e:
            htmldata = self.read_channelfile()
            if htmldata == None:
                return None

        chan_groups = {'Nederlandstalig': 2,
                                    'Hoofdzenders': 2,
                                    'Engelstalig': 3,
                                    'Franstalig': 5,
                                    'Digitale zenders': 8,
                                    'Documentaire': 8,
                                    'Sport': 8,
                                    'Kids & Jeugd': 8,
                                    'Anderstalige zenders': 9}
        self.all_channels ={}
        self.page_strings = {}
        changroup = 10
        for item in htmldata.find('div[@class="greyrounded"]'):
            if item.tag == 'h2':
                group =  self.empersant(item.findtext('a[@href]'))
                if group in chan_groups:
                    changroup = chan_groups[group]

                else:
                    changroup = 10

                group_url = item.find('a').get('href')
                group_url = re.split('/', group_url)[-1]
                self.page_strings[group] = {}
                self.page_strings[group]['url'] = group_url
                self.page_strings[group]['chan_list'] = []
                self.page_strings[group]['fetch_list'] = []

            elif item.tag == 'a':
                chan = item.get('href')
                if chan != None:
                    chanid = re.split('/', chan)[-1]
                    icon = item.find('img').get('src')
                    icon = re.split('/', icon)
                    icon = '%s/%s' % (icon[-2], icon[-1])
                    self.all_channels[chanid] = {}
                    self.all_channels[chanid]['name'] = item.find('img').get('title')
                    self.all_channels[chanid]['icon'] = icon
                    self.all_channels[chanid]['group'] = changroup
                    self.all_channels[chanid]['group_list'] = []
                    self.page_strings[group]['chan_list'].append(chanid)
                    if group == 'Digitale zenders':
                        self.all_channels[chanid]['HD'] = True

                    else:
                        self.all_channels[chanid]['HD'] = False

        for g, v in self.page_strings.items():
            for chanid in v['chan_list']:
                self.all_channels[chanid]['group_list'].append(g)


    def load_pages(self):
        if config.opt_dict['offset'] > 8:
            for chanid in self.channels.keys():
                self.channel_loaded[chanid] = True
                config.channels[chanid].source_data[self.proc_id] = True

            return

        if len(self.channels) == 0 :
            return

        # We first try to get the solopages
        self.load_solopages()
        # And for the failed pages we try the grouppages
        self.load_grouppages()

    def load_grouppages(self):
        # First determin which pages need to be loaded
        try:
            self.get_channels()
            # Init loaded markings for the grouppages
            for n, v in self.page_strings.items():
                v['fetch_list'] = []
                self.day_loaded[n] = {}
                for day in range( config.opt_dict['offset'], (config.opt_dict['offset'] + config.opt_dict['days'])):
                    self.day_loaded[n][day] = False

            for chanid, channel in self.channels.items():
                if not channel in self.all_channels:
                    # This channel is removed, for it reurns empty
                    self.channel_loaded[chanid] = True
                    config.channels[chanid].source_data[self.proc_id] = True
                    continue

                # Check wich grouppage to load
                if not self.channel_loaded[chanid] and len(self.all_channels[channel]['group_list']) > 0:
                    self.page_strings[self.all_channels[channel]['group_list'][0]]['fetch_list'].append(channel)

            for retry in (0, 1):
                # There are 9 group pages. Check if any channel from a page is wanted
                for group_page, group_values in self.page_strings.items():
                    if len(group_values['fetch_list']) == 0:
                        continue

                    failure_count = 0
                    if self.quit:
                        return

                    # teeveeblad.be shows programs per day, so we loop over the number of days
                    # we are required to grab
                    for offset in range(config.opt_dict['offset'], (config.opt_dict['offset'] + config.opt_dict['tevedays'])):
                        if self.day_loaded[group_page][offset] != False:
                            continue

                        day_list = []
                        for channel in group_values['fetch_list']:
                            chanid = ''
                            for k, v in self.channels.items():
                                if channel == v:
                                    chanid = k
                                    if not self.day_loaded[chanid][offset]:
                                        day_list.append(chanid)

                                    break

                            if len(day_list) > 0:
                                break

                        else:
                            if len(day_list) == 0:
                                # All channels processed for this day
                                continue

                        log('\n', 2)
                        log('Now fetching GroupPage: %s from teveblad.be for day %s of %s.\n' % (group_page, offset, config.opt_dict['tevedays']), 2)

                        date_offset = offset
                        scan_date = datetime.date.fromordinal(self.current_date + offset)
                        channel_url =self.get_url(scan_date, group_values['url'], True)

                        # get the raw programming for the day
                        strdata = self.get_page(channel_url, encoding = 'utf-8')

                        if strdata == None:
                            log("Skip %s page on teveblad.be, day=%d. No data!\n" % (group_page, offset))
                            failure_count += 1
                            continue

                        if not self.check_date(self.datecheckdata.search(strdata), scan_date):
                            #~ log("Skip group=%s on teveblad.be, day=%d. Wrong date!\n" % (group_page, offset))
                            failure_count += 1
                            continue

                        # and extract the ElementTree
                        try:
                            strdata = self.clean_html(strdata)
                            strdata = re.sub('<div class="r" class="toowide">', '<div class="r">', strdata)
                            strdata =self.groupdata.search(strdata)
                            strdata = u'<root><div>' + strdata.group(1) + u'\n<div>\n' + strdata.group(2) + u'</root>'
                            htmldata = ET.fromstring(strdata.encode('utf-8'))

                        except Exception as e:
                            log('Error extracting ElementTree for zendergroup:%s day:%s\n' % (group_page, offset))
                            err_obj = sys.exc_info()[2]
                            log('Error: %s at line %s\n' %  (sys.exc_info()[1], err_obj.tb_lineno), 0)
                            if config.write_info_files:
                                infofiles.write_raw_string('Error: %s at line %s\n\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
                                infofiles.write_raw_string(unicode(strdata + u'\n'))

                            self.day_loaded[group_page][offset] = None
                            continue

                        channel_cnt = 0
                        chan_list = {}
                        # Retrieve the available channels and add the wanted channels to the channel list
                        for c in  htmldata.findall('div/div[@id="epg_channel_headers_content"]/div[@class="channel"]'):
                            url = c.find('div/a').get('href')
                            if url != None:
                                channel_cnt += 1
                                c = re.split('/', url)[-1]
                                if c in group_values['fetch_list']:
                                    chan_list[unicode(channel_cnt)] = c

                        for c in  htmldata.findall('div/div[@id="epg_channels_content"]/div[@class="channel"]'):
                            if not c.get('number') in chan_list.keys():
                                continue

                            last_program = datetime.datetime.combine(scan_date, datetime.time(1, 0, 0 ,0 ,CET_CEST))
                            channel = chan_list[c.get('number')]
                            for k, v in self.channels.items():
                                if channel == v:
                                    chanid = k

                            for p in c.findall('div'):
                                if not( p.get('class') == 'programme even' or p.get('class') == 'programme odd'):
                                    continue

                                p_duur = int(p.get('duration'))
                                tdict = self.checkout_program_dict()
                                p = p.find('div[@class="c"]')
                                tdict['source'] = 'teveblad'
                                tdict['channelid'] = chanid
                                tdict['channel'] = config.channels[chanid].chan_name

                                # The Title
                                title = p.find('p/span[@class="title"]')
                                if title == None:
                                    log('Can not determine program title"\n')
                                    continue

                                href = title.find('a').get('href')
                                if href != '' and href != None:
                                    tdict[self.detail_url] = title.find('a').get('href')
                                    tdict[self.detail_id] = u'be-%s' % tdict[self.detail_url].split('/')[5]
                                tdict['name'] = self.empersant(title.findtext('a'))
                                if tdict['name'] == None or  tdict['name'] == '':
                                    log('Can not determine program title for "%s"\n' % tdict['be-url'])
                                    continue

                                # Starttime
                                start = p.findtext('p/span[@class="starttime"]')
                                if start == None or start == '':
                                    log('Can not determine starttime for "%s"\n' % tdict['name'])
                                    continue

                                prog_time = datetime.time(int(start.split('u')[0]), int(start.split('u')[1]), 0 ,0 ,CET_CEST)

                                # Make sure the midnight date change is properly crossed
                                if datetime.datetime.combine(scan_date, prog_time) < last_program:
                                    date_offset = offset +1
                                    scan_date = datetime.date.fromordinal(self.current_date + date_offset)
                                tdict['offset'] = date_offset
                                tdict['start-time'] = datetime.datetime.combine(scan_date, prog_time)
                                last_program = tdict['start-time']
                                tdict['stop-time'] = tdict['start-time'] + datetime.timedelta(0, 0, 0, 0, p_duur)

                                # Subtitle
                                subtitle = self.empersant(p.findtext('p/span[@class="title_episode"]'))
                                tdict['titel aflevering'] = subtitle if (subtitle != None) else ''

                                # Description. There is a possible long and short version. We try to take the long one
                                descshort = self.empersant(p.findtext('p/span[@class="desc_short"]'))
                                descshort = '' if (descshort == None) else descshort

                                desc = self.empersant(p.findtext('div[@class="desc h"]/p'))
                                tdict['description'] = desc if (desc != None) else descshort

                                # The basicinfo section
                                for d in p.iterfind('div[@class="basicinfo"]/span'):

                                    if d.get('class').lower() == 'year':
                                        tdict['jaar van premiere'] = d.text

                                    elif d.get('class').lower() == 'episode':
                                        tdict['episode'] = (re.sub('Episode', '', d.text)).strip()
                                        tdict['episode'] = (re.sub('Aflevering', '', d.text)).strip()

                                    elif d.get('class').lower() == 'season':
                                        try:
                                            season = self.seasondata.search(d.text)
                                            if season != None:
                                                tdict['season'] = unicode(season.group(1))
                                                tdict['episode'] = unicode(season.group(2))
                                                #stotal = season.group(3)

                                        except:
                                            if config.write_info_files:
                                                infofiles.addto_detail_list('error processing seasonstring: %s\n\n' % season)

                                    elif d.get('class').lower() == 'desc_short' and tdict['description'] == '':
                                        tdict['description'] = self.empersant(d.text)

                                    elif d.get('class').lower() == 'originaltitle':
                                        tdict['originaltitle'] = self.empersant(d.text)

                                    # We don't use it (yet)
                                    elif d.get('class').lower() == 'country':
                                        continue

                                    elif config.write_info_files:
                                        infofiles.addto_detail_list(unicode('new teveblad basicinfo => ' + d.get('class') + '=' + d.text))

                                # The picons section
                                for d in p.iterfind('p[@class="picons"]/span'):

                                    if d.get('class').lower() == 'picon' or d.get('class').lower() == 'curvyignore picon' :

                                        # We don't use these (yet)
                                        if d.get('title').lower() in ('gedubd', 'live', 'ingekleurd'):
                                            continue

                                        if d.get('title').lower() == 'herhaling':
                                            tdict['rerun'] = True

                                        elif d.get('title').lower() == 'nieuw':
                                            tdict['new'] = True

                                        elif d.get('title').lower() == 'laatste aflevering':
                                            tdict['last-chance'] = True

                                        elif d.get('title').lower() == 'premiere':
                                            tdict['premiere'] = True

                                        elif d.get('title').lower() == 'hd':
                                            tdict['video']['HD'] = True

                                        elif d.get('title').lower() == 'dolby':
                                            tdict['audio']  = 'dolby'

                                        elif d.get('title').lower() == '16:9':
                                            tdict['breedbeeld']  = True

                                        elif d.get('title').lower() == 'ondertiteld':
                                            tdict['teletekst']  = True

                                        elif config.write_info_files:
                                            infofiles.addto_detail_list(unicode('new teveblad picondata => ' + d.get('title') + '=' + d.text))

                                    elif 'genre' in d.get('class').lower():
                                        genre = self.empersant(d.findtext('a'))
                                        if genre == '' or genre == None:
                                            continue

                                        if genre.lower() in config.tevecattrans.keys():
                                            tdict['genre'] = config.tevecattrans[genre.lower()][0].capitalize()
                                            tdict['subgenre'] = config.tevecattrans[genre.lower()][1].capitalize()

                                        else:
                                            config.tevecat[genre] = (u'Overige', u'')

                                for d in p.iterfind('span[@class]'):
                                    if 'genre' in d.get('class').lower():
                                        genre = self.empersant(p.findtext('a'))
                                        if genre == '' or genre == None:
                                            continue

                                        if genre.lower() in config.tevecattrans.keys():
                                            tdict['genre'] = config.tevecattrans[genre.lower()][0].capitalize()
                                            tdict['subgenre'] = config.tevecattrans[genre.lower()][1].capitalize()

                                        else:
                                            config.tevecat[genre] = (u'Overige', u'')

                                # and append the program to the list of programs
                                tdict = self.check_title_name(tdict)
                                self.program_data[chanid].append(tdict)

                            self.day_loaded[chanid][offset] = True

                        self.day_loaded[group_page][offset] = True
                        # be nice to teveblad.be
                        time.sleep(random.randint(config.nice_time[0], config.nice_time[1]))

                    # If all went well or it's the last try we set them loaded
                    if failure_count == 0 or retry == 1:
                        for chanid, channel in self.channels.items():
                            if channel in group_values['fetch_list']:
                                for tdict in self.program_data[chanid]:
                                    self.program_by_id[tdict[self.detail_id]] = tdict

                                self.channel_loaded[chanid] = True
                                self.parse_programs(chanid, 0, 'None')
                                config.channels[chanid].source_data[self.proc_id] = True

                                try:
                                    infofiles.write_fetch_list(self.program_data[chanid], chanid, self.source)

                                except:
                                    pass

        except:
            err_obj = sys.exc_info()[2]
            log('\nAn unexpected error has occured in the %s thread: %s\n' %  (self.source, sys.exc_info()[1]), 0)
            log('                                at line: %s, %s\n' %  (err_obj.tb_lineno, err_obj.tb_lasti), 0)

            while True:
                err_obj = err_obj.tb_next
                if err_obj == None:
                    break

                log('                   tracing back to line: %s, %s\n' %  (err_obj.tb_lineno, err_obj.tb_lasti), 0)

            for chanid in self.channels.keys():
                self.channel_loaded[chanid] = True
                config.channels[chanid].source_data[self.proc_id] = True
            return None

    def load_solopages(self):

        for retry in (0, 1):
            channel_cnt = 0
            for chanid in self.channels.keys():
                channel_cnt += 1
                failure_count = 0
                if self.quit:
                    return

                channel = self.channels[chanid]

                # teeveeblad.be shows programs per day, so we loop over the number of days
                # we are required to grab
                for offset in range(config.opt_dict['offset'], (config.opt_dict['offset'] + config.opt_dict['tevedays'])):
                    if self.day_loaded[chanid][offset] != False:
                        continue

                    log('\n', 2)
                    log('Now fetching %s(xmltvid=%s%s) from teveblad.be\n    (channel %s of %s) for day %s of %s days.\n' % \
                        (config.channels[chanid].chan_name, chanid, (config.channels[chanid].opt_dict['compat'] and \
                        '.tvgids.nl' or ''), channel_cnt, len(self.channels), offset, config.opt_dict['tevedays']), 2)

                    date_offset = offset
                    scan_date = datetime.date.fromordinal(self.current_date + offset)
                    last_program = datetime.datetime.combine(scan_date, datetime.time(1, 0, 0 ,0 ,CET_CEST))
                    channel_url =self.get_url(scan_date, channel)

                    # get the raw programming for the day
                    strdata = self.get_page(channel_url)

                    if strdata == None:
                        log("Skip channel=%s on teveblad.be, day=%d. No data!\n" % (config.channels[chanid].chan_name, offset))
                        failure_count += 1
                        continue

                    if not self.check_date(self.datecheckdata.search(strdata), scan_date):
                        #~ log("Skip channel=%s on teveblad.be, day=%d. Wrong date!\n" % (config.channels[chanid].chan_name, offset))
                        failure_count += 1
                        continue

                    # and extract the ElementTree
                    try:
                        strdata = self.clean_html(strdata)
                        strdata = re.sub('<div class="r" class="toowide">', '<div class="r">', strdata)
                        strdata = u'<div><div>' + self.progdata.search(strdata).group(1)
                        htmldata = ET.fromstring(strdata.encode('utf-8'))
                        if htmldata.findtext('div/p') == "We don't have any events for this broadcaster":
                            log('No data for channel:%s on teveblad.be\n' % (config.channels[chanid].chan_name))
                            config.channels[chanid].source_data[self.proc_id] = None
                            for i in range(config.opt_dict['offset'], (config.opt_dict['offset'] + config.opt_dict['tevedays'])):
                                self.day_loaded[chanid][i] = None
                            break

                    except Exception as e:
                        log('Error extracting ElementTree for channel:%s day:%s\n' % (config.channels[chanid].chan_name, offset))
                        if config.write_info_files:
                            infofiles.write_raw_string('Error: %s at line %s\n\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
                            infofiles.write_raw_string(strdata + u'\n')

                        self.day_loaded[chanid][offset] = None
                        continue

                    for p in htmldata.findall('div/div[@class="programme"]'):
                        tdict = self.checkout_program_dict()
                        p = p.find('div[@class="c"]')
                        tdict['source'] = 'teveblad'
                        tdict['channelid'] = chanid
                        tdict['channel'] = config.channels[chanid].chan_name

                        # The Title
                        title = p.find('div[@class="r"]/p/span[@class="title"]')
                        if title == None:
                            log('Can not determine program title"\n')
                            continue

                        href = title.find('a').get('href')
                        if href != '' and href != None:
                            tdict[self.detail_url] = title.find('a').get('href')
                            tdict[self.detail_id] = u'be-%s' % tdict[self.detail_url].split('/')[5]
                        tdict['name'] = self.empersant(title.findtext('a'))
                        if tdict['name'] == None or  tdict['name'] == '':
                            log('Can not determine program title for "%s"\n' % tdict['be-url'])
                            continue

                        # Starttime
                        start = p.findtext('div[@class="l"]/span[@class="starttime"]')
                        if start == None or start == '':
                            log('Can not determine starttime for "%s"\n' % tdict['name'])
                            continue

                        prog_time = datetime.time(int(start.split('u')[0]), int(start.split('u')[1]), 0 ,0 ,CET_CEST)

                        # Make sure the midnight date change is properly crossed
                        if datetime.datetime.combine(scan_date, prog_time) < last_program:
                            date_offset = offset +1
                            scan_date = datetime.date.fromordinal(self.current_date + date_offset)
                        tdict['offset'] = date_offset
                        tdict['start-time'] = datetime.datetime.combine(scan_date, prog_time)
                        last_program = tdict['start-time']

                        # Subtitle
                        subtitle = self.empersant(p.findtext('div[@class="r"]/p/span[@class="title_episode"]'))
                        tdict['titel aflevering'] = subtitle if (subtitle != None) else ''

                        # Description. There is a possible long and short version. We try to take the long one
                        descshort = self.empersant(p.findtext('div[@class="r"]/p[@class="desc_short"]'))
                        descshort = '' if (descshort == None) else descshort

                        desc = self.empersant(p.findtext('div[@class="r"]/div[@class="desc h"]/p'))
                        tdict['description'] = desc if (desc != None) else descshort

                        # The basicinfo section
                        for d in p.iterfind('div[@class="r"]/p[@class="basicinfo"]/span'):

                            if d.get('class').lower() == 'year':
                                tdict['jaar van premiere'] = d.text

                            elif d.get('class').lower() == 'episode':
                                tdict['episode'] = (re.sub('Episode', '', d.text)).strip()

                            elif d.get('class').lower() == 'season':
                                season = self.seasondata.search(d.text)
                                tdict['season'] = unicode(season.group(1))
                                tdict['episode'] = unicode(season.group(2))
                                #stotal = season.group(3)

                            elif d.get('class').lower() == 'originaltitle':
                                tdict['originaltitle'] = self.empersant(d.text)

                            elif d.get('class').lower() == 'country':
                                tdict['country'] = self.empersant(d.text)[0:2]
                                if config.write_info_files:
                                    infofiles.addto_detail_list(unicode('new teveblad county => ' + d.text))


                            elif config.write_info_files:
                                infofiles.addto_detail_list(unicode('new teveblad basicinfo => ' + d.get('class') + '=' + d.text))

                        # The picons section
                        for d in p.iterfind('div[@class="r"]/p[@class="picons"]/span'):

                            if d.get('class').lower() == 'picon' or d.get('class').lower() == 'curvyignore picon' :

                                # We don't use these (yet)
                                if d.get('title').lower() in ('gedubd', 'live', 'ingekleurd'):
                                    continue

                                elif d.get('title').lower() == 'herhaling':
                                    tdict['rerun'] = True

                                elif d.get('title').lower() == 'nieuw':
                                    tdict['new'] = True

                                elif d.get('title').lower() == 'laatste aflevering':
                                    tdict['last-chance'] = True

                                elif d.get('title').lower() == 'premiere':
                                    tdict['premiere'] = True

                                elif d.get('title').lower() == 'hd':
                                    tdict['video']['HD'] = True

                                elif d.get('title').lower() == 'dolby':
                                    tdict['audio']  = 'dolby'

                                elif d.get('title').lower() == 'ondertiteld':
                                    tdict['teletekst']  = True

                                elif config.write_info_files:
                                    infofiles.addto_detail_list(unicode('new teveblad picondata => ' + d.get('title') + '=' + d.text))

                            elif 'genre' in d.get('class').lower():
                                genre = self.empersant(d.findtext('a'))
                                if genre == '' or genre == None:
                                    continue

                                if genre.lower() in config.tevecattrans.keys():
                                    tdict['genre'] = config.tevecattrans[genre.lower()][0].capitalize()
                                    tdict['subgenre'] = config.tevecattrans[genre.lower()][1].capitalize()

                                else:
                                    config.tevecat[genre] = (u'Overige', u'')

                        # and append the program to the list of programs
                        tdict = self.check_title_name(tdict)
                        self.program_data[chanid].append(tdict)

                    self.day_loaded[chanid][offset] = True
                    # be nice to teveblad.be
                    time.sleep(random.randint(config.nice_time[0], config.nice_time[1]))

                # Add starttime of the next program as the endtime
                self.program_data[chanid].sort(key=lambda program: (program['start-time']))
                self.add_endtimes(chanid, 7)

                for tdict in self.program_data[chanid]:
                    self.program_by_id[tdict[self.detail_id]] = tdict

                # If all went well we set them loaded. Else we give the grouppages a try
                if failure_count == 0:
                    self.channel_loaded[chanid] = True
                    self.parse_programs(chanid, 0, 'None')
                    config.channels[chanid].source_data[self.proc_id] = True

                try:
                    infofiles.write_fetch_list(self.program_data[chanid], chanid, self.source)

                except:
                    pass

# end teveblad_HTML

class npo_HTML(FetchData):
    """
    Get all available days of programming for the requested channels
    from the npo.nl page. Based on FetchData Class
    """
    def init_channels(self):
        """ General Site layout
            <div class='guides-overlay overlay'></div>
            <div class='row-fluid'>
                <div class='span12'>
                    <div         class='vertical-guide'
                                    data-counter='?npo-nl.gids.verticaal.20150526'
                                    data-end='Wed, 27 May 2015 05:59:59 +0200'
                                    data-keyboard-input='true'
                                    data-scorecard='{"prefix":"npo","name":"gids.verticaal.26-05-2015"}'
                                    data-slide-increment='540'
                                    data-start='Tue, 26 May 2015 06:00:00 +0200'
                                    id='primary-guide'>
                        <div class='guide-scroller'>
                            <div class='vertical-guide-wrapper'>
                                <ul class='scroll-header'>
                                    <li>
                                        <a href="/live/npo-1" title="Bekijk live!">
                                            <div alt='Logo van NPO 1'
                                                    class='channel-logo'
                                                    style="background-image: url('//assets.www.npo.nl/uploads/tv_channel/263/logo/regular_logo-npo1.png')">
                                            </div>
                                                NPO 1
                                        </a>
                                    </li>
                                        ...
                                    <li class='ttv'>
                                        <div alt='Logo van NPO Nieuws'
                                                class='channel-logo'
                                                style="background-image: url('//assets.www.npo.nl/uploads/tv_channel/279/guide_label/regular_nponieuws-klein.png')">
                                        </div>
                                            NPO Nieuws
                                    </li>
                                        ...
                                    <li class='rtv'>
                                        <div alt='Logo van Regio TV Utrecht'
                                                class='channel-logo'
                                                style="background-image: url('//assets.www.npo.nl/uploads/tv_channel/273/logo/regular_rtvutrecht.png')">
                                        </div>
                                            Regio TV Utrecht
                                    </li>
                                </ul>
                                <table>
                                    <tr class='odd' data-hour='6'>          ('6' - '5')
                                        <td class='padder left'></td>
                                        <td class='red'>                             ('red', 'blue', 'green', 'ttv'..., 'rtv'...)
                                            <a           href="/nederland-in-beweging/25-05-2015/POW_00979881"
                                                            class="time-block inactive"
                                                            data-end-hour="06"
                                                            data-end-minutes="07"
                                                            data-genre="17"
                                                            data-start-hour="05"
                                                            data-start-minutes="53">
                                                <div class='time'>05:53</div>
                                                <div class='description'>
                                                    <i class='np'></i>
                                                    <div class='program-title'>Nederland in Beweging</div>
                                                </div>
                                            </a>
                                                ...
                                        </td>
                                                ...

                                        <td class='padder right'></td>
                                    <tr class='odd active' data-hour='1'>
                                        ...
                                    </tr>
                                </table>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        """

        self.get_channels()
        for chanid, channel in config.channels.iteritems():
            self.program_data[chanid] = []
            if channel.active and chanid in config.source_channels[self.proc_id].keys():
                if channel.opt_dict['use_npo']:
                    self.channels[chanid] = config.source_channels[self.proc_id][chanid]
                    channel.source_id[self.proc_id] = self.channels[chanid]

                else:
                    self.channel_loaded[chanid] = True
                    config.channels[chanid].source_data[self.proc_id] = True

            else:
                channel.source_id[self.proc_id] = ''

    def get_url(self, offset = 0, href = None, vertical = True):

        npo_zoeken = 'http://www.npo.nl'
        if href == None and vertical:
            scan_date = datetime.date.fromordinal(self.current_date + offset)
            return u'%s/gids/verticaal/%s/content' % (npo_zoeken,  scan_date.strftime('%d-%m-%Y'))

        if href == None and not vertical:
            scan_date = datetime.date.fromordinal(self.current_date + offset)
            return u'%s/gids/horizontaal/%s/content' % (npo_zoeken,  scan_date.strftime('%d-%m-%Y'))

        elif href == '':
            return ''

        else:
            return u'%s%s' % (npo_zoeken,  href)

    def get_channels(self):

        self.all_channels = {'1': {'name': 'NPO 1', 'icon': '', 'group': 1},
                                         '2': {'name': 'NPO 2', 'icon': '', 'group': 1},
                                         '3': {'name': 'NPO 3', 'alt_name': 'NPO Zapp', 'icon': '', 'group': 1},
                                         '4': {'name': 'NPO Nieuws', 'icon': '', 'group': 7},
                                         '5': {'name': 'NPO Cultura', 'icon': '', 'group': 7},
                                         '6': {'name': 'NPO 101', 'icon': '', 'group': 7},
                                         '7': {'name': 'NPO Politiek', 'icon': '', 'group': 7},
                                         '8': {'name': 'NPO Best', 'icon': '', 'group': 7},
                                         '9': {'name': 'NPO Doc', 'icon': '', 'group': 7},
                                         '10': {'name': 'NPO Zapp Xtra', 'icon': '', 'group': 7},
                                         '11': {'name': 'NPO Humor TV', 'icon': '', 'group': 7},
                                         '12': {'name': 'Omrop Fryslan', 'icon': '', 'group': 6},
                                         '13': {'name': 'RTV Noord', 'icon': '', 'group': 6},
                                         '14': {'name': 'RTV Drenthe', 'icon': '', 'group': 6},
                                         '15': {'name': 'RTV Oost', 'icon': '', 'group': 6},
                                         '16': {'name': 'Omroep Gelderland', 'icon': '', 'group': 6},
                                         '17': {'name': 'Omroep Flevoland', 'icon': '', 'group': 6},
                                         '18': {'name': 'Omroep Brabant', 'icon': '', 'group': 6},
                                         '19': {'name': 'Regio TV Utrecht', 'icon': '', 'group': 6},
                                         '20': {'name': 'RTV NH', 'icon': '', 'group': 6},
                                         '21': {'name': 'Omroep West', 'icon': '', 'group': 6},
                                         '22': {'name': 'RTV Rijnmond', 'icon': '', 'group': 6},
                                         '23': {'name': 'L1 TV', 'icon': '', 'group': 6},
                                         '24': {'name': 'Omroep Zeeland', 'icon': '', 'group': 6}}

        self.channel_names = {}
        for chanid, channel in self.all_channels.items():
            self.channel_names[channel['name']] = chanid
            if 'alt_name' in channel:
                self.channel_names[channel['alt_name']] = chanid

    def load_pages(self):

        def get_channel_name(xml):
            tag = xml.find('a')
            tag2 = xml.find('div')
            if tag != None and tag.get("alt") != None:
                cname = tag.get("alt")[9:]

            elif tag != None and tag.get("href") != None:
                cname = tag.get("href").split('/')[-1]

            elif tag2 != None and tag2.get("title") != None:
                cname = tag2.get("title")

            else:
                return

            # We add the appropriate channels to the fetch list. Comparing our list with their list
            if cname in self.channel_names.keys() and self.channel_names[cname] in self.channels.values():
                for chanid, channel in self.channels.items():
                    if self.channel_names[cname] == channel:
                        self.fetch_list[channel] = chanid
                        break

            if config.write_info_files:
                if not str(channel_cnt) in self.all_channels or cname != self.all_channels[str(channel_cnt)]['name']:
                    if channel_cnt > 24:
                        infofiles.addto_detail_list(u'Channel %s is named %s' % (channel_cnt, cname))

                    elif not ('alt_name' in self.all_channels[str(channel_cnt)] \
                      and cname != self.all_channels[str(channel_cnt)]['alt_name']):
                        infofiles.addto_detail_list(u'Channel %s should be named %s and is named %s' % \
                            (channel_cnt, self.all_channels[str(channel_cnt)]['name'], cname))

        def get_programs(xml, chanid, omroep = True):
            try:
                day_offset = 0
                for p in xml.findall('a'):
                    ptext = p.find('i[@class="np"]')
                    if ptext == None:
                        # No title Found
                        continue

                    ptime = p.get('data-time')
                    if ptext == None:
                        # No start-stop time Found
                        continue

                    tdict = self.checkout_program_dict()
                    tdict['source'] = u'npo'
                    tdict['channelid'] = chanid
                    tdict['channel'] = config.channels[chanid].chan_name
                    tdict[self.detail_url] = self.get_url(href = p.get('href',''))
                    if tdict[self.detail_url] != '':
                        pid = tdict[self.detail_url].split('/')[-1]
                        tdict[self.detail_id] = u'npo-%s' % pid.split('_')[-1]

                    # The Title
                    tdict['name'] = self.empersant(ptext.tail.strip())
                    tdict = self.check_title_name(tdict)

                    ptime = ptime.split('-')
                    pstart = ptime[0].split(':')
                    prog_time = datetime.time(int(pstart[0]), int(pstart[1]), 0 ,0 ,CET_CEST)
                    if day_offset == 0 and int(pstart[0]) < 6:
                        day_offset = 1

                    tdict['offset'] = offset + day_offset

                    if day_offset == 1:
                        tdict['start-time'] = datetime.datetime.combine(nextdate, prog_time)

                    else:
                        tdict['start-time'] = datetime.datetime.combine(startdate, prog_time)

                    pstop = ptime[1].split(':')
                    prog_time = datetime.time(int(pstop[0]), int(pstop[1]), 0 ,0 ,CET_CEST)
                    if day_offset == 1 or int(pstop[0]) < 6:
                        tdict['stop-time'] = datetime.datetime.combine(nextdate, prog_time)

                    else:
                        tdict['stop-time'] = datetime.datetime.combine(startdate, prog_time)

                    if omroep:
                        tdict['omroep'] = p.findtext('span', '')

                    pgenre = p.get('data-genre','')
                    if pgenre in config.npocattrans.keys():
                        tdict['genre'] = config.npocattrans[pgenre][0].capitalize()
                        tdict['subgenre'] = config.npocattrans[pgenre][1].capitalize()

                    else:
                        p = pgenre.split(',')
                        if len(p) > 1 and p[0] in config.npocattrans.keys():
                            tdict['genre'] = config.npocattrans[p[0]][0].capitalize()
                            tdict['subgenre'] = config.npocattrans[p[0]][1].capitalize()

                        else:
                            tdict['genre'] = u'overige'

                        if config.write_info_files and pgenre != '':
                            infofiles.addto_detail_list(unicode('unknown npo.nl genre => ' + pgenre + ': ' + tdict['name']))

                    # and append the program to the list of programs
                    self.program_data[chanid].append(tdict)

            except:
                log('Error: %s, line:%s\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))

        if config.opt_dict['offset'] > 7:
            for chanid in self.channels.keys():
                self.channel_loaded[chanid] = True
                config.channels[chanid].source_data[self.proc_id] = True

            return

        if len(self.channels) == 0 :
            return

        for offset in range(config.opt_dict['offset'], min((config.opt_dict['offset'] + config.opt_dict['days']), 7)):
            if self.quit:
                return

            log('\n', 2)
            log('Now fetching %s channels from npo.nl\n    (day %s of %s).\n' % (len(self.channels), offset, config.opt_dict['days']), 2)

            channel_url = self.get_url(offset, None, False)

            # get the raw programming for the day
            strdata = self.get_page(channel_url)
            if strdata == None or 'We hebben deze pagina niet gevonden...' in strdata:
                log("No data on npo.nl for day=%d\n" % (offset))
                continue

            try:
                strdata = self.clean_html(strdata)
                htmldata = ET.fromstring( (u'<root>\n' + strdata + u'\n</root>\n').encode('utf-8'))

            except Exception as e:
                log('Error extracting ElementTree for day:%s on npo.nl\n' % (offset))
                if config.write_info_files:
                    infofiles.write_raw_string('Error: %s at line %s\n\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
                    infofiles.write_raw_string(u'<root>\n' + strdata + u'\n</root>\n')

                #~ self.day_loaded[chanid][offset] = None
                continue

            # First we check for a changed line-up
            try:
                startdate = htmldata.find('div[@class="row-fluid"]/div[@class="span12"]/div').get('data-start')
                nextdate = htmldata.find('div[@class="row-fluid"]/div[@class="span12"]/div').get('data-end')
                if startdate == None or nextdate == None:
                    log('Error validating page for day:%s on npo.nl\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno, offset))
                    continue

                d = (startdate.split(',')[-1].strip()).split(' ')
                startdate = datetime.datetime.strptime('%s %s %s' % (d[0], d[1], d[2]),'%d %b %Y').date()

                d = (nextdate.split(',')[-1].strip()).split(' ')
                nextdate = datetime.datetime.strptime('%s %s %s' % (d[0], d[1], d[2]),'%d %b %Y').date()

                self.fetch_list = {}
                channel_cnt = 0
                # The NPO base channels
                for c in htmldata.findall('div[@class="row-fluid"]/div[@class="span12"]/div/div/div[@class="channel-icon"]'):
                    channel_cnt += 1
                    get_channel_name(c)

                # The NPO theme channels
                for c in htmldata.findall('div[@id="themed-guide"]/div/div/div/div[@class="channel-icon"]'):
                    channel_cnt += 1
                    get_channel_name(c)

                # The Regional channels
                for c in htmldata.findall('div[@id="regional-guide"]/div/div/div/div[@class="channel-icon"]'):
                    channel_cnt += 1
                    get_channel_name(c)

            except:
                log('Error: %s, line:%s\n  Validating page for day:%s on npo.nl\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno, offset))
                #~ self.day_loaded[chanid][offset] = None
                continue

            try:
                channel_cnt = 0
                # The NPO base channels
                for c in htmldata.findall('div[@class="row-fluid"]/div[@class="span12"]/div/div/div/div[@class="channels"]/div'):
                    channel_cnt += 1
                    if str(channel_cnt) in self.fetch_list.keys():
                        chanid = self.fetch_list[str(channel_cnt)]
                        get_programs(c, chanid)
                        self.day_loaded[chanid][offset] = True

                # The NPO theme channels
                for c in htmldata.findall('div[@id="themed-guide"]/div/div/div/div/div[@class="channels"]/div'):
                    channel_cnt += 1
                    if str(channel_cnt) in self.fetch_list.keys():
                        chanid = self.fetch_list[str(channel_cnt)]
                        get_programs(c, chanid)
                        self.day_loaded[chanid][offset] = True

                # The Regional channels
                for c in htmldata.findall('div[@id="regional-guide"]/div/div/div/div/div[@class="channels"]/div'):
                    channel_cnt += 1
                    if str(channel_cnt) in self.fetch_list.keys():
                        chanid = self.fetch_list[str(channel_cnt)]
                        get_programs(c, chanid, False)
                        self.day_loaded[chanid][offset] = True

            except:
                log('Error: %s, line:%s\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))

            # be nice to npo.nl
            time.sleep(random.randint(config.nice_time[0], config.nice_time[1]))

        for chanid in self.channels.keys():
            for tdict in self.program_data[chanid]:
                self.program_by_id[tdict[self.detail_id]] = tdict

            self.channel_loaded[chanid] = True
            self.parse_programs(chanid, 0, 'none')
            config.channels[chanid].source_data[self.proc_id] = True
            if len(self.program_data) == 0:
                log('No data for channel:%s on tvgids.tv\n' % (config.channels[chanid].chan_name))
                config.channels[chanid].source_data[self.proc_id] = None
                continue

            try:
                infofiles.write_fetch_list(self.program_data[chanid], chanid, self.source)

            except:
                pass

    def load_pages_vertical(self):

        if config.opt_dict['offset'] > 3:
            for chanid in self.channels.keys():
                self.channel_loaded[chanid] = True
                config.channels[chanid].source_data[self.proc_id] = True

            return

        if len(self.channels) == 0 :
            return

        for offset in range(config.opt_dict['offset'], min((config.opt_dict['offset'] + config.opt_dict['days']), 3)):
            if self.quit:
                return

            log('\n', 2)
            log('Now fetching %s channels from npo.nl\n    (day %s of %s).\n' % (len(self.channels), offset, config.opt_dict['days']), 2)

            channel_url = self.get_url(offset)

            # get the raw programming for the day
            strdata = self.get_page(channel_url)
            if strdata == None or 'We hebben deze pagina niet gevonden...' in strdata:
                log("No data on npo.nl for day=%d\n" % (offset))
                continue

            try:
                strdata = self.clean_html(strdata)
                htmldata = ET.fromstring( (u'<root>\n' + strdata + u'\n</root>\n').encode('utf-8'))

            except Exception as e:
                log('Error extracting ElementTree for day:%s on npo.nl\n' % (offset))
                if config.write_info_files:
                    infofiles.write_raw_string('Error: %s at line %s\n\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))
                    infofiles.write_raw_string(u'<root>\n' + strdata + u'\n</root>\n')

                #~ self.day_loaded[chanid][offset] = None
                continue

            # First we check for a changed line-up
            try:
                startdate = htmldata.find('div/div/div').get('data-start')
                nextdate = htmldata.find('div/div/div').get('data-end')
                if startdate == None or nextdate == None:
                    log('Error validating page for day:%s on npo.nl\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno, offset))
                    continue

                d = (startdate.split(',')[-1].strip()).split(' ')
                startdate = datetime.datetime.strptime('%s %s %s' % (d[0], d[1], d[2]),'%d %b %Y').date()

                d = (nextdate.split(',')[-1].strip()).split(' ')
                nextdate = datetime.datetime.strptime('%s %s %s' % (d[0], d[1], d[2]),'%d %b %Y').date()

                fetch_list = {}
                channel_cnt = 0
                for c in htmldata.findall('div/div/div/div/div/ul/li'):
                    channel_cnt += 1
                    if c.get('class') == None:
                        cname = c.find('a/div').tail.strip()

                    elif c.get('class') == 'ttv':
                        cname = c.find('div').tail.strip()

                    elif c.get('class') == 'rtv':
                        cname = c.find('div').tail.strip()

                    # We add the appropriate channels to the fetch list. Comparing our list with their list
                    if cname in self.channel_names.keys() and self.channel_names[cname] in self.channels.values():
                        for chanid, channel in self.channels.items():
                            if self.channel_names[cname] == channel:
                                fetch_list[channel] = chanid
                                break

                    if config.write_info_files:
                        if not str(channel_cnt) in self.all_channels or cname != self.all_channels[str(channel_cnt)]['name']:
                            if channel_cnt > 24:
                                infofiles.addto_detail_list(u'Channel %s is named %s' % (channel_cnt, cname))

                            else:
                                infofiles.addto_detail_list(u'Channel %s should be named %s and is named %s' % (channel_cnt, self.all_channels[str(channel_cnt)]['name'], cname))

            except:
                log('Error: %s, line:%s\n  Validating page for day:%s on npo.nl\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno, offset))
                #~ self.day_loaded[chanid][offset] = None
                continue

            try:
                day_offset = 0
                for h in htmldata.findall('div/div/div/div/div/table/tr'):
                    phour = int(h.get('data-hour'))
                    channel_cnt = 0
                    for c in h.findall('td'):
                        cclass = c.get('class')
                        if cclass == None or cclass == 'padder left' or cclass == 'padder right':
                            continue

                        elif cclass in ('red', 'blue', 'green', 'ttv', 'rtv',):
                            channel_cnt += 1
                            if not str(channel_cnt) in fetch_list.keys():
                                continue

                            chanid = fetch_list[str(channel_cnt)]
                            for p in c.findall('a'):
                                ptext = p.findtext('div[@class="description"]/div[@class="program-title"]','')
                                pshour = p.get('data-start-hour','')
                                psmin =p.get('data-start-minutes','')
                                pstart = p.findtext('div[@class="time"]','')
                                pehour = p.get('data-end-hour','')
                                pemin = p.get('data-end-minutes','')

                                for v in (ptext, pshour, psmin):
                                    if v == '':
                                        log('Unable to determin Title and/or Starttime')
                                        continue

                                # We skip any program starting before the regular day start at 6
                                #~ if day_offset == 0 and phour == 6 and int(pshour) < 6:
                                    #~ continue

                                tdict = self.checkout_program_dict()
                                tdict['source'] = u'npo'
                                tdict['channelid'] = chanid
                                tdict['channel'] = config.channels[chanid].chan_name
                                tdict[self.detail_url] = self.get_url(href = p.get('href',''))
                                if tdict[self.detail_url] != '':
                                    pid = tdict[self.detail_url].split('/')[-1]
                                    tdict[self.detail_id] = u'npo-%s' % pid.split('_')[-1]

                                # The Title
                                tdict['name'] = self.empersant(ptext)
                                tdict = self.check_title_name(tdict)

                                prog_time = datetime.time(int(pshour), int(psmin), 0 ,0 ,CET_CEST)
                                if day_offset == 0 and phour < 6:
                                    day_offset = 1

                                tdict['offset'] = offset + day_offset

                                if day_offset == 1:
                                    tdict['start-time'] = datetime.datetime.combine(nextdate, prog_time)

                                else:
                                    tdict['start-time'] = datetime.datetime.combine(startdate, prog_time)

                                # There seem to be regular gaps between the programs
                                # I asume they are commercials and in between talk.
                                prog_time = datetime.time(int(pehour), int(pemin), 0 ,0 ,CET_CEST)
                                if day_offset == 1 or int(pehour) < 6:
                                    tdict['stop-time'] = datetime.datetime.combine(nextdate, prog_time)

                                else:
                                    tdict['stop-time'] = datetime.datetime.combine(startdate, prog_time)

                                pgenre = p.get('data-genre','')
                                if pgenre in config.npocattrans.keys():
                                    tdict['genre'] = config.npocattrans[pgenre][0].capitalize()
                                    tdict['subgenre'] = config.npocattrans[pgenre][1].capitalize()

                                else:
                                    p = pgenre.split(',')
                                    if len(p) > 1 and p[0] in config.npocattrans.keys():
                                        tdict['genre'] = config.npocattrans[p[0]][0].capitalize()
                                        tdict['subgenre'] = config.npocattrans[p[0]][1].capitalize()

                                    else:
                                        tdict['genre'] = u'overige'

                                    if config.write_info_files and pgenre != '':
                                        infofiles.addto_detail_list(unicode('unknown npo.nl genre => ' + pgenre + ': ' + tdict['name']))

                                # and append the program to the list of programs
                                self.program_data[chanid].append(tdict)

                        else:
                            # Unknown Channel class
                            pass

            except:
                log('Error: %s, line:%s\n' % (sys.exc_info()[1], sys.exc_info()[2].tb_lineno))

            for chanid in self.channels.keys():
                self.day_loaded[chanid][offset] = True

            # be nice to npo.nl
            time.sleep(random.randint(config.nice_time[0], config.nice_time[1]))

        for chanid in self.channels.keys():
            for tdict in self.program_data[chanid]:
                self.program_by_id[tdict[self.detail_id]] = tdict

            self.channel_loaded[chanid] = True
            self.parse_programs(chanid, 0, 'fill')
            config.channels[chanid].source_data[self.proc_id] = True
            if len(self.program_data) == 0:
                log('No data for channel:%s on tvgids.tv\n' % (config.channels[chanid].chan_name))
                config.channels[chanid].source_data[self.proc_id] = None
                continue

            try:
                infofiles.write_fetch_list(self.program_data[chanid], chanid, self.source)

            except:
                pass

# end npo_HTML()

class Channel_Config(Thread):
    """
    Class that holds the Channel definitions and manages the data retrieval and processing
    """
    def __init__(self, chanid = 0, name = '', group = 10):
        Thread.__init__(self)
        # Flag to stop the thread
        self.quit = False

        # Flags to indicate the data is in
        self.source_data = {}

        # Flag to indicate all data is processed
        self.ready = False

        self.active = False
        self.counter = 0
        self.chanid = chanid
        self.chan_name = name
        self.group = group
        self.source_id = {}
        self.icon_source = -1
        self.icon = ''

        for index in range(xml_output.source_count):
            self.source_id[index] = ''
            self.source_data[index] = False

        self.none_count = 0
        self.cache_count = 0
        self.fail_count = 0
        self.fetch_count = {}
        self.fetch_count[0] = 0
        self.fetch_count[1] = 0
        self.fetched_count = {}
        self.fetched_count[0] = 0
        self.fetched_count[1] = 0
        # This will contain the final fetcheddata
        self.all_programs = []

        self.opt_dict = {}
        self.opt_dict['fast'] = config.opt_dict['fast']
        self.opt_dict['slowdays'] = config.opt_dict['slowdays']
        self.opt_dict['use_npo'] = config.opt_dict['use_npo']
        self.opt_dict['compat'] = config.opt_dict['compat']
        self.opt_dict['max_overlap'] = config.opt_dict['max_overlap']
        self.opt_dict['overlap_strategy'] = config.opt_dict['overlap_strategy']
        self.opt_dict['logos'] = config.opt_dict['logos']
        self.opt_dict['desc_length'] = config.opt_dict['desc_length']
        self.opt_dict['cattrans'] = config.opt_dict['cattrans']
        self.opt_dict['mark_hd'] = config.opt_dict['mark_hd']
        self.opt_dict['add_hd_id'] = False
        self.opt_dict['prime_source'] = -1
        self.opt_dict['prefered_description'] = -1
        self.opt_dict['append_tvgidstv'] = True

    def validate_settings(self):

        if not self.active:
            return

        config.validate_option('overlap_strategy', self)
        config.validate_option('max_overlap', self)
        config.validate_option('desc_length', self)
        config.validate_option('slowdays', self)

    def run(self):

        if not self.active:
            self.ready = True
            return

        try:
            xml_data = False
            # Retrieve and merge the data from the available sources.
            for index in xml_output.source_order:
                if (self.source_id[index] != '') and ((index != 4) or (index == 4 and self.opt_dict['use_npo'])):
                    while self.source_data[index] == False:
                        if self.quit:
                            self.ready = True
                            return

                if xml_data == False and self.source_data[index] == True:
                    xml_data = True
                    self.all_programs = xml_output.channelsource[index].program_data[self.chanid]

                elif self.source_data[index] == True:
                    xml_data = True
                    xml_output.channelsource[index].merge_sources(self.chanid, ((self.opt_dict['prime_source'] == index) or (index == 4)), self.counter)
                    xml_output.channelsource[index].parse_programs(self.chanid, 1, 'None')
                    for i in range(0, len(self.all_programs)):
                        self.all_programs[i] = xml_output.channelsource[index].checkout_program_dict(self.all_programs[i])

            # And get the detailpages
            self.get_details()

            # Wait for all details being processed
            while True:
                if self.quit:
                    self.ready = True
                    return

                if self.fetch_count[0] == 0 and self.fetch_count[1] == 0:
                    self.all_programs = self.detailed_programs
                    break

            # And log the results
            config.log_lock.acquire()
            xml_output.progress_counter+= 1
            counter = xml_output.progress_counter
            log('\n', 4, 3, True)
            log('Detail statistics for %s (channel %s of %s)\n' % (self.chan_name, counter, config.chan_count),4, 3, True)
            log('%6.0f cache hits\n' % (self.cache_count),4, 3, True)
            if self.opt_dict['fast']:
                log('%6.0f without details in cache\n' % self.none_count,4, 3, True)

            else:
                log('%6.0f detail fetches from tvgids.nl\n' % self.fetched_count[0], 4, 3, True)
                log('%6.0f detail fetches from tvgids.tv\n' % self.fetched_count[1], 4, 3, True)
                log('%6.0f failures\n' % self.fail_count,4, 3, True)
                log('%6.0f without detail info\n' % self.none_count, 4, 3, True)
                log('\n', 4, 3, True)
                log('%6.0f left in the tvgids.nl queue to process\n' % (len(xml_output.channelsource[0].detail_queue)), 4, 3, True)
                log('%6.0f left in the tvgids.tv queue to process\n' % (len(xml_output.channelsource[1].detail_queue)), 4, 3, True)

            log('\n', 4, 3, True)
            config.log_lock.release()

            # a final check on the sanity of the data
            xml_output.channelsource[0].parse_programs(self.chanid, 1)

            # Split titles with colon in it
            # Note: this only takes place if all days retrieved are also grabbed with details (slowdays=days)
            # otherwise this function might change some titles after a few grabs and thus may result in
            # loss of programmed recordings for these programs.
            for i, v in enumerate(self.all_programs):
                self.all_programs[i] = self.title_split(v)

            if self.opt_dict['add_hd_id']:
                self.opt_dict['mark_hd'] = False
                xml_output.create_channel_strings(self.chanid, False)
                xml_output.create_program_string(self.chanid, False)
                xml_output.create_channel_strings(self.chanid, True)
                xml_output.create_program_string(self.chanid, True)

            else:
                xml_output.create_channel_strings(self.chanid)
                xml_output.create_program_string(self.chanid)

            if config.write_info_files:
                infofiles.write_raw_list()

            self.ready = True

        except:
            err_obj = sys.exc_info()[2]
            log('\nAn unexpected error has occured in the %s thread: %s\n' %  (self.chan_name, sys.exc_info()[1]), 0)
            log('                                at line: %s, %s\n' %  (err_obj.tb_lineno, err_obj.tb_lasti), 0)

            while True:
                err_obj = err_obj.tb_next
                if err_obj == None:
                    break

                log('                   tracing back to line: %s, %s\n' %  (err_obj.tb_lineno, err_obj.tb_lasti), 0)

            log('\nIf you want assistence, please attach your configuration and log files!\n     %s\n     %s\n' % (config.config_file, config.log_file),0)

            self.ready = True
            for source in xml_output.channelsource.values():
                source.quit = True

            for channel in config.channels.values():
                channel.quit = True

            xml_output.program_cache.quit = True
            return(97)

    def use_cache(self, tdict, cached):
        # copy the cached information, except the start/end times, rating and clumping,
        # these may have changed.
        # But first checkout the dict
        cached = xml_output.channelsource[0].checkout_program_dict(cached)
        try:
            clump  = tdict['clumpidx']

        except LookupError:
            clump = False

        cached['start-time'] = tdict['start-time']
        cached['stop-time']  = tdict['stop-time']
        if clump:
            cached['clumpidx'] = clump

        # Make sure we do not overwrite fresh info with cashed info
        if tdict['description'] > cached['description']:
            cached['description'] = tdict['description']

        if not 'prefered description' in cached.keys():
            cached['prefered description'] = tdict['prefered description']

        if tdict['prefered description'] > cached['prefered description']:
            cached['prefered description'] = tdict['prefered description']

        for fld in ('titel aflevering', 'jaar van premiere', 'country', 'star-rating', 'omroep'):
            if tdict[fld] != '':
                cached[fld] = tdict[fld]

        for fld in ('season', 'episode'):
            if tdict[fld] != '0':
                cached[fld] = tdict[fld]

        if tdict['rerun'] == True:
            cached['rerun'] = True

        if len(tdict['kijkwijzer']) > 0:
            for item in tdict['kijkwijzer']:
                if not item in cached['kijkwijzer']:
                    cached['kijkwijzer'].append(item)

        return cached

    def get_counter(self):
        self.fetch_counter += 1
        return 100*float(self.fetch_counter)/float(self.nprograms)
    def get_details(self, ):
        """
        Given a list of programs, from the several sources, retrieve program details
        """
        # Check if there is data
        self.detailed_programs = []
        if len(self.all_programs) == 0:
            return

        programs = self.all_programs

        if self.opt_dict['fast']:
            log('\nNow Checking cache for %s programs on %s(xmltvid=%s%s)\n    (channel %s of %s) for %s days.\n' % \
                (len(programs), self.chan_name, self.chanid, (self.opt_dict['compat'] and '.tvgids.nl' or ''), \
                self.counter, config.chan_count, config.opt_dict['days']), 2)

        else:
            log('\nNow fetching details for %s programs on %s(xmltvid=%s%s)\n    (channel %s of %s) for %s days.\n' % \
                (len(programs), self.chan_name, self.chanid, (self.opt_dict['compat'] and '.tvgids.nl' or ''), \
                self.counter, config.chan_count, config.opt_dict['days']), 2)

        # randomize detail requests
        self.fetch_counter = 0
        self.nprograms = len(programs)
        fetch_order = list(range(0,self.nprograms))
        random.shuffle(fetch_order)

        #~ counter = 0
        for i in fetch_order:
            if self.quit:
                self.ready = True
                return

            if programs[i] == None:
                continue

            p = programs[i]
            logstring = u'%s-%s: %s \n' % \
                                (p['start-time'].strftime('%d %b %H:%M'), \
                                p['stop-time'].strftime('%H:%M'), \
                                p['name'])

            # We only fetch when we are in slow mode and slowdays is not set to tight
            no_fetch = (self.opt_dict['fast'] or p['offset'] >= (config.opt_dict['offset'] + self.opt_dict['slowdays']))

            # check the cache for this program's ID
            # If not found, check the various ID's and (if found) make it the prime one
            cache_id = xml_output.program_cache.query_id(p)
            if cache_id != None:
                cached_program = xml_output.program_cache.query(p[cache_id])

                # check if it contains detail info from tvgids.nl or (if no nl-url known, or in no_fetch mode) tvgids.tv
                if cached_program[xml_output.channelsource[0].detail_check] \
                  or ((p[xml_output.channelsource[0].detail_url] == '') and cached_program[xml_output.channelsource[1].detail_check]) \
                  or (no_fetch and cached_program[xml_output.channelsource[1].detail_check]):
                    log(u'      [cached] %s:(%3.0f%%) %s' % (self.chan_name, self.get_counter(), logstring), 8, 1)
                    self.cache_count += 1
                    self.detailed_programs.append(self.use_cache(p, cached_program))
                    continue

            # Either we are fast-mode, outsite slowdays or there is no url. So we continue
            try:
                no_detail_fetch = (no_fetch or ((p[xml_output.channelsource[0].detail_url] == '') and (p[xml_output.channelsource[1].detail_url] == '')))

            except:
                no_detail_fetch = True

            if no_detail_fetch:
                log(u'    [no fetch] %s:(%3.0f%%) %s' % (self.chan_name, self.get_counter(), logstring), 8, 1)
                self.none_count += 1
                self.detailed_programs.append(p)

                continue

            detailed_program = None
            if p[xml_output.channelsource[0].detail_url] != '':
                self.fetch_count[0]  += 1
                xml_output.channelsource[0].detail_queue.append({'tdict':p, 'cache_id': cache_id, 'logstring': logstring, 'parent': self})
                continue

            if detailed_program == None and p[xml_output.channelsource[1].detail_url] != '':
                self.fetch_count[1]  += 1
                xml_output.channelsource[1].detail_queue.append({'tdict':p, 'cache_id': cache_id, 'logstring': logstring, 'parent': self})
                continue

    def title_split(self,program):
        """
        Some channels have the annoying habit of adding the subtitle to the title of a program.
        This function attempts to fix this, by splitting the name at a ': '.
        """
        # Some programs (BBC3 when this happened) have no genre. If none, then set to a default
        if program['genre'] is None:
            program['genre'] = 'overige';

        ptitle = program['name']
        psubtitle = program['titel aflevering']
        if  ptitle == None or ptitle == '':
            return program

        # exclude certain programs
        if  ('titel aflevering' in program and psubtitle != '')  \
          or ('genre' in program and program['genre'].lower() in ['movies','film']) \
          or (ptitle.lower() in config.notitlesplit):
            return program

        # and do the title split test
        p = ptitle.split(':')
        if len(p) >1:
            log('Splitting title \"%s\"\n' %  ptitle, 64)
            program['name'] = p[0].strip()
            program['titel aflevering'] = "".join(p[1:]).strip()
            if config.write_info_files:
                infofiles.addto_detail_list(unicode('Name split = %s + %s' % (program['name'] , program['titel aflevering'])))

        return program

# end Channel_Config()

class XMLoutput:
    '''
    This class collects the data and creates the output
    '''
    def __init__(self):

        xmlencoding = 'UTF-8'
        # This will contain the cache
        self.program_cache = None
        # Thes will contain the seperate XML strings
        self.startstring = []
        self.xml_channels = {}
        self.xml_programs = {}
        self.progress_counter = 0

        self.startstring.append(u'<?xml version="1.0" encoding="%s"?>\n' % xmlencoding)
        self.startstring.append(u'<!DOCTYPE tv SYSTEM "xmltv.dtd">\n')
        self.startstring.append(u'<tv generator-info-name="%s" generator-info-url="https://github.com/tvgrabbers/tvgrabnlpy">\n' % config.version(True))
        self.closestring = u'</tv>\n'

        # We have several sources of logos, the first provides the nice ones, but is not
        # complete. We use the tvgids logos to fill the missing bits.
        self.logo_provider = ['http://graphics.tudelft.nl/~paul/logos/gif/64x64/',
                                        'http://static.tvgids.nl/gfx/zenders/',
                                        'http://s4.cdn.sanomamedia.be/a/epg/q100/w60/h/',
                                        'http://staticfiles.rtl.nl/styles/img/logos/',
                                        'http://212.142.41.211/ChannelLogos/02/']

                                    #~ 1 : [0, 'ned1'],
                                    #~ 2 : [0, 'ned2'],
                                    #~ 3 : [0, 'ned3'],
                                    #~ 4 : [0, 'rtl4'],
                                    #~ 5 : [0, 'een'],
                                    #~ 6 : [0, 'canvas_color'],
                                    #~ 7 : [0, 'bbc1'],
                                    #~ 8 : [0, 'bbc2'],
                                    #~ 9 : [0,'ard'],
                                    #~ 10 : [0,'zdf'],
                                    #~ 12 : [0, 'wdr'],
                                    #~ 24 : [0, 'canal+red'],
                                    #~ 26 : [0, 'cnn'],
                                    #~ 31 : [0, 'rtl5'],
                                    #~ 34 : [0, 'veronica'],
                                    #~ 36 : [0, 'sbs6'],
                                    #~ 37 : [0, 'net5'],
                                    #~ 39 : [0, 'canal+blue'],
                                    #~ 40 : [0, 'at5'],
                                    #~ 46 : [0, 'rtl7'],
                                    #~ 86 : [0, 'bbc-world'],
                                    #~ 92 : [0, 'rtl8'],
                                    #~ 100 : [0, 'rtvu'],
                                    #~ 101 : [0, 'tvwest'],
                                    #~ 102 : [0, 'tvrijnmond'],
                                    #~ 103 : [0, 'rtvnh'],
                                    #~ 107 : [0, 'canal+yellow'],
                                    #~ 108 : [0, 'tvnoord'],
                                    #~ 109 : [0, 'omropfryslan'],
                                    #~ 114 : [0, 'omroepbrabant'],
                                    #~ 300 : [0, 'bbc3'],
                                    #~ 301 : [0, 'bbc4'],
                                    #~ 13 : [1, 'ndr'],
                                    #~ 28 : [1, 'sat1'],
                                    #~ 38 : [1, 'arte'],
                                    #~ 99 : [1, 'sport1_1'],
                                    #~ 104 : [1, 'bbcprime'],
                                    #~ 105 : [1, 'spiceplatinum'],

        self.logo_names = {
                                    1 : [4, 'npo1'],
                                    2 : [4, 'npo2'],
                                    3 : [4, 'npo3'],
                                    4 : [4, 'rtl4_1'],
                                    5 : [4, 'een'],
                                    6 : [4, 'canvas'],
                                    7 : [4, 'bbc1'],
                                    8 : [4, 'bbc_two'],
                                    9 : [4, 'ard'],
                                    10 : [4, 'zdf'],
                                    11 : [1, 'rtl'],
                                    12 : [4, 'wdr'],
                                    13 : [4, 'ndr'],
                                    14 : [1, 'srsudwest'],
                                    15 : [1, 'rtbf1'],
                                    16 : [1, 'rtbf2'],
                                    17 : [0, 'tv5'],
                                    18 : [0, 'ngc'],
                                    19 : [1, 'eurosport'],
                                    20 : [1, 'tcm'],
                                    21 : [0, 'cartoonnetwork'],
                                    24 : [4, 'film1_premiere'],
                                    25 : [0, 'mtv-color'],
                                    26 : [4, 'cnn'],
                                    27 : [0, 'rai'],
                                    28 : [4, 'sat_1'],
                                    29 : [0, 'discover-spacey'],
                                    31 : [4, 'rtl_5_1'],
                                    32 : [0, 'trt'],
                                    34 : [4, 'veronica_disney_xd'],
                                    35 : [0, 'tmf'],
                                    36 : [4, 'sbs6_1'],
                                    37 : [4, 'net5'],
                                    38 : [4, 'arte'],
                                    39 : [4, 'film1_comedykids_sd'],
                                    40 : [4, 'at5'],
                                    46 : [4, 'rtl7'],
                                    49 : [1, 'vtm'],
                                    50 : [1, '3sat'],
                                    58 : [1, 'pro7'],
                                    59 : [1, 'kanaal2'],
                                    60 : [1, 'vt4'],
                                    65 : [0, 'animal-planet'],
                                    66 : [4, 'npo_humor'],
                                    70 : [4, 'npo_cultura'],
                                    73 : [1, 'mezzo'],
                                    81 : [4, 'npo_doc'],
                                    86 : [4, 'bbc_world_news'],
                                    87 : [1, 'tve'],
                                    89 : [1, 'nick'],
                                    90 : [0, 'bvn'],
                                    91 : [0, 'comedy_central'],
                                    92 : [4, 'rtl_8_1'],
                                    99 : [4, 'sport1'],
                                    100 : [4, 'rtvutrecht'],
                                    101 : [4, 'tv_west'],
                                    102 : [4, 'tv_rijnmond'],
                                    103 : [4, 'rtv_nh'],
                                    104 : [4, 'bbc_entertainment'],
                                    105 : [4, 'private_spice'],
                                    107 : [4, 'film1_sundance'],
                                    108 : [4, 'rtv_noord'],
                                    109 : [4, 'omroep_friesland'],
                                    110 : [4, 'rtv_drenthe'],
                                    111 : [4, 'rtv_oost'],
                                    112 : [4, 'omroep_gelderland'],
                                    113 : [4, 'omroep_flevoland'],
                                    114 : [4, 'omroep_brabant'],
                                    115 : [4, 'omroep_limburg'],
                                    116 : [4, 'omroep_zeeland'],
                                    148 : [4, 'fox_sports_ere_1_sd'],
                                    300 : [4, 'bbc_three'],
                                    301 : [4, 'bbc_four'],
                                    311 : [4, 'disney_xd'],
                                    312 : [4, 'nick_jr'],
                                    313 : [4, 'boomerang_1'],
                                    315 : [4, 'cbs_reality'],
                                    316 : [4, 'npo_best'],
                                    317 : [4, 'comedy_central_family1'],
                                    406 : [4, 'nostalgienet'],
                                    407 : [4, 'outtv_v2'],
                                    408 : [4, 'rtl_lounge1'],
                                    409 : [4, 'rtlcrime'],
                                    410 : [4, 'npo_101'],
                                    411 : [4, 'film1_action'],
                                    413 : [4, 'history'],
                                    414 : [4, 'investigation_discovery_2'],
                                    415 : [4, 'travel_channel_new'],
                                    416 : [4, 'nat_geo_wild'],
                                    419 : [4, 'sport1_golf'],
                                    420 : [4, 'sport1_tennis'],
                                    422 : [4, 'euronews'],
                                    423 : [4, 'al_jazeera_english1'],
                                    427 : [4, 'mtv_brand_new'],
                                    428 : [4, 'bravanl'],
                                    429 : [4, 'tv_oranje'],
                                    430 : [4, 'film1_spotlight_sd'],
                                    431 : [4, 'hbo_sd'],
                                    432 : [4, 'hbo_2sd'],
                                    433 : [4, 'hbo_3sd'],
                                    434 : [4, 'dusk_24'],
                                    435 : [4, '24_kitchen'],
                                    437 : [4, 'comedy_central_extra1'],
                                    440 : [4, 'fox'],
                                    460 : [4, 'sbs9'],
                                    462 : [4, 'shortstv'],
                                    'zone-realty' : [4, 'zone_reality'],
                                    'animal-planet-hd' : [4, 'animal_planet_hd'],
                                    'cbeebies' : [4, 'cbbc'],
                                    'discovery-hd' : [4, 'discovery_hd'],
                                    'ketnet-canvas-2' : [4, 'ketnet_canvas'],
                                    'sport-1-extra-1' : [4, 'sport1_extra1'],
                                    'sport1-extra-2' : [4, 'sport1_extra2'],
                                    'sport-1-2' : [4, 'sport1_voetbal'],
                                    'zone_reality' : [4, 'zone_reality'],
                                    'rtl_telekids' : [4, 'rtl_telekids'],
                                    'jimjam' : [4, 'jimjam'],
                                    'zappelin' : [4, 'npo_zapp_xtra'],
                                    'politiek-24' : [4, 'npo_politiek'],
                                    'journaal-24' : [4, 'npo_nieuws'],
                                    'history-hd' : [4, 'history_hd'],
                                    'goed-tv' : [4, 'goedtv'],
                                    'eredivisie-live-2' : [4, 'fox_sports2'],
                                    'eredivisie-live-3' : [4, 'fox_sports_ere_3_sd'],
                                    'eredivisie-live-4' : [4, 'fox_sports4'],
                                    'fox-sports-5-eredivisie' : [4, 'fox_sports_ere_5_sd'],
                                    'e-entertainment' : [4, 'e_entertainment'],
                                    'sky-1' : [4, 'sky_news'],
                                    'sky-2' : [4, 'sky_news'],
                                    'sky-sports-1' : [4, 'sky_news'],
                                    'sky-sports-2' : [4, 'sky_news'],
                                    'sky-sports-3' : [4, 'sky_news'],
                                    'sky-sports-4' : [4, 'sky_news'],
                                    'sky-sports-news' : [4, 'sky_news'],
                                    'bbc-hd' : [4, 'bbc_hd']}

        self.source_count = 5
        self.sources = {0: 'tvgids.nl', 1: 'tvgids.tv', 2: 'rtl.nl', 3: 'teveblad.be', 4: 'npo.nl'}
        self.source_order = (0, 1, 2, 3, 4)
        self.channelsource = {}
        self.channelsource[0] = tvgids_JSON(0, 'tvgidsnl', 'nl-ID', 'nl-url', True, 'tvgids-fetched', True)
        self.channelsource[1] = tvgidstv_HTML(1, 'tvgidstv', 'tv-ID', 'tv-url', False, 'tvgidstv-fetched', True)
        self.channelsource[2] = rtl_JSON(2, 'rtl.nl', 'rtl-ID', '', True)
        self.channelsource[3] = teveblad_HTML(3, 'teveblad', 'be-ID', 'be-url')
        self.channelsource[4] = npo_HTML(4, 'npo.nl', 'npo-ID', 'npo-url')

    def xmlescape(self, s):
        """Escape <, > and & characters for use in XML"""
        return saxutils.escape(s)

    def format_timezone(self, td, use_utc):
        """
        Given a datetime object, returns a string in XMLTV format
        """
        if use_utc:
            td = td.astimezone(UTC)

        return td.strftime('%Y%m%d%H%M%S %z')

    def add_starttag(self, tag, ident = 0, attribs = '', text = '', close = False):
        '''
        Add a starttag with optional attributestring, textstring and optionally close it.
        Give it the proper ident.
        '''
        if attribs != '':
            attribs = ' %s' % attribs

        if close and text == '':
            return u'%s<%s%s/>\n' % (''.rjust(ident), self.xmlescape(tag), self.xmlescape(attribs))

        if close and text != '':
            return u'%s<%s%s>%s</%s>\n' % (''.rjust(ident), self.xmlescape(tag), self.xmlescape(attribs), self.xmlescape(text), self.xmlescape(tag))

        else:
            return u'%s<%s%s>%s\n' % (''.rjust(ident), self.xmlescape(tag), self.xmlescape(attribs), self.xmlescape(text))

    def add_endtag(self, tag, ident = 0):
        '''
        Return a proper idented closing tag
        '''
        return u'%s</%s>\n' % (''.rjust(ident), self.xmlescape(tag))

    def create_channel_strings(self, chanid, add_HD = None):
        '''
        Create the strings for the channels we fetched info about
        '''
        if add_HD == True:
            chanidhd = '%s-hd' % chanid

        else:
            chanidhd = chanid

        self.xml_channels[chanidhd] = []
        self.xml_channels[chanidhd].append(self.add_starttag('channel', 2, 'id="%s%s"' % \
            (chanidhd, config.channels[chanid].opt_dict['compat'] and '.tvgids.nl' or '')))
        self.xml_channels[chanidhd].append(self.add_starttag('display-name', 4, 'lang="nl"', \
            config.channels[chanid].chan_name, True))
        if (config.channels[chanid].opt_dict['logos']):
            if -1 < config.channels[chanid].icon_source < 5:
                full_logo_url = self.logo_provider[config.channels[chanid].icon_source] + config.channels[chanid].icon
                self.xml_channels[chanidhd].append(self.add_starttag('icon', 4, 'src="%s"' % full_logo_url, '', True))

            elif config.channels[chanid].icon_source == 99:
                self.xml_channels[chanidhd].append(self.add_starttag('icon', 4, 'src="%s"' % config.channels[chanid].icon, '', True))

        self.xml_channels[chanidhd].append(self.add_endtag('channel', 2))

    def create_program_string(self, chanid, add_HD = None):
        '''
        Create all the program strings
        '''
        if add_HD == True:
            chanidhd = '%s-hd' % chanid

        else:
            chanidhd = chanid

        self.xml_programs[chanidhd] = []
        config.channels[chanid].all_programs.sort(key=lambda program: (program['start-time'],program['stop-time']))
        for program in config.channels[chanid].all_programs:
            xml = []

            # Start/Stop
            attribs = 'start="%s" stop="%s" channel="%s%s"' % \
                (self.format_timezone(program['start-time'], config.opt_dict['use_utc']), \
                self.format_timezone(program['stop-time'], config.opt_dict['use_utc']), \
                chanidhd, config.channels[chanid].opt_dict['compat'] and '.tvgids.nl' or '')

            if 'clumpidx' in program and program['clumpidx'] != '':
                attribs += 'clumpidx="%s"' % program['clumpidx']

            xml.append(self.add_starttag('programme', 2, attribs))

            # Title
            xml.append(self.add_starttag('title', 4, 'lang="nl"', program['name'], True))
            if program['originaltitle'] != '' and program['country'] != '' and program['country'].lower() != 'nl' and program['country'].lower() != 'be':
                xml.append(self.add_starttag('title', 4, 'lang="%s"' % (program['country'].lower()), program['originaltitle'], True))

            # Subtitle
            if 'titel aflevering' in program and program['titel aflevering'] != '':
                xml.append(self.add_starttag('sub-title', 4, 'lang="nl"', program['titel aflevering'] ,True))

            # Add an available subgenre in front off the description or give it as description

            # A prefered description was set and found
            if len(program['prefered description']) > 100:
                program['description'] = program['prefered description']

            desc_line = u''
            if program['subgenre'] != '':
                 desc_line = u'%s: ' % (program['subgenre'])

            if program['omroep'] != '':
                 desc_line = u'%s%s ' % (desc_line, program['omroep'])

            if program['description'] != '':
                 desc_line = u'%s%s ' % (desc_line, program['description'])

            # Limit the length of the description
            if desc_line != '':
                if len(desc_line) > config.channels[chanid].opt_dict['desc_length']:
                    spacepos = desc_line[0:config.channels[chanid].opt_dict['desc_length']-3].rfind(' ')
                    desc_line = desc_line[0:spacepos] + '...'

                xml.append(self.add_starttag('desc', 4, 'lang="nl"', desc_line.strip(),True))

            # Process credits section if present.
            # This will generate director/actor/presenter info.
            if program['credits'] != {}:
                xml.append(self.add_starttag('credits', 4))
                for role in ('director', 'actor', 'writer', 'adapter', 'producer', 'composer', 'editor', 'presenter', 'commentator', 'guest'):
                    if role in program['credits']:
                        for name in program['credits'][role]:
                            if name != '':
                                xml.append(self.add_starttag((role), 6, '', self.xmlescape(name),True))

                xml.append(self.add_endtag('credits', 4))

            # Original Air-Date
            if program['jaar van premiere'] != '':
                xml.append(self.add_starttag('date', 4, '', program['jaar van premiere'],True))

            # Genre
            if not config.channels[chanid].opt_dict['cattrans']:
                xml.append(self.add_starttag('category', 4, 'lang="nl', program['genre'], True))

            else:
                cat0 = ('', '')
                cat1 = (program['genre'].lower(), '')
                cat2 = (program['genre'].lower(), program['subgenre'].lower())
                try:
                    if config.cattrans[cat2] != '':
                        cat = cat2

                    else:
                        if config.cattrans[cat1] != '':
                            cat = cat1

                        else:
                            cat = cat0

                except:
                    try:
                        if config.cattrans[cat1] != '':
                            cat = cat1

                        else:
                            cat = cat0

                    except:
                        cat = cat0

                if cat in config.cattrans:
                    xml.append(self.add_starttag('category', 4 , '', config.cattrans[cat].capitalize(), True))

                else:
                    xml.append(self.add_starttag('category', 4 , '', 'Unknown', True))

            # An available url
            if program['infourl'] != '':
                xml.append(self.add_starttag('url', 4, '', program['infourl'],True))

            if program['country'] != '':
                xml.append(self.add_starttag('country', 4, '', program['country'],True))

            # Only add season/episode if relevant. i.e. Season can be 0 if it is a pilot season, but episode never.
            # Also exclude Sports for MythTV will make it into a Series
            if not (cat in config.cattrans and config.cattrans[cat].lower() == 'sports'):
                if program['season'] != '' and program['episode'] != '' and program['episode'] != '0':
                    if program['season'] == '0':
                        text = ' . %d . '  % (int(program['episode']) - 1)

                    else:
                        text = '%d . %d . '  % (int(program['season']) - 1, int(program['episode']) - 1)

                    xml.append(self.add_starttag('episode-num', 4, 'system="xmltv_ns"', text,True))

            # Process video/audio/teletext sections if present
            if (program['video']['breedbeeld'] or program['video']['blackwhite'] \
              or (config.channels[chanid].opt_dict['mark_hd'] \
              or add_HD == True) and (program['video']['HD'])):
                xml.append(self.add_starttag('video', 4))

                if program['video']['breedbeeld']:
                    xml.append(self.add_starttag('aspect', 6, '', '16:9',True))

                if program['video']['blackwhite']:
                    xml.append(self.add_starttag('colour', 6, '', 'no',True))

                if (config.channels[chanid].opt_dict['mark_hd'] \
                  or add_HD == True) and (program['video']['HD']):
                    xml.append(self.add_starttag('quality', 6, '', 'HDTV',True))

                xml.append(self.add_endtag('video', 4))

            if program['audio'] != '':
                xml.append(self.add_starttag('audio', 4))
                xml.append(self.add_starttag('stereo', 6, '',program['audio'] ,True))
                xml.append(self.add_endtag('audio', 4))

            # It's been shown before
            if program['rerun']:
                xml.append(self.add_starttag('previously-shown', 4, '', '',True))

            # It's a first
            if program['premiere']:
                xml.append(self.add_starttag('premiere', 4, '', '',True))

            # It's the last showing
            if program['last-chance']:
                xml.append(self.add_starttag('last-chance', 4, '', '',True))

            # It's new
            if program['new']:
                xml.append(self.add_starttag('new', 4, '', '',True))

            # There are teletext subtitles
            if program['teletekst']:
                xml.append(self.add_starttag('subtitles', 4, 'type="teletext"', '',True))

            # Add any Kijkwijzer items
            # First only one age limit from high to low
            for k in ('4', '3', '9', '2', '1'):
                if k in program['kijkwijzer']:
                    xml.append(self.add_starttag('rating', 4, 'system="kijkwijzer"'))
                    xml.append(self.add_starttag('value', 6, '', config.kijkwijzer[k]['code'], True))
                    xml.append(self.add_starttag('icon', 6, 'src="%s"' % config.kijkwijzer[k]['icon'], '', True))
                    xml.append(self.add_endtag('rating', 4))
                    break

            # And only one of any of the others
            for k in ('g', 'a', 's', 't', 'h', 'd'):
                if k in program['kijkwijzer']:
                    xml.append(self.add_starttag('rating', 4, 'system="kijkwijzer"'))
                    xml.append(self.add_starttag('value', 6, '', config.kijkwijzer[k]['code'], True))
                    xml.append(self.add_starttag('icon', 6, 'src="%s"' % config.kijkwijzer[k]['icon'], '', True))
                    xml.append(self.add_endtag('rating', 4))

            # Set star-rating if applicable
            if program['star-rating'] != '':
                xml.append(self.add_starttag('star-rating', 4))
                xml.append(self.add_starttag('value', 6, '',('%s/10' % (program['star-rating'])).strip(),True))
                xml.append(self.add_endtag('star-rating', 4))

            xml.append(self.add_endtag('programme', 2))
            self.xml_programs[chanidhd].append(xml)

    def get_xmlstring(self):
        '''
        Compound the compleet XML output and return it
        '''
        xml = []
        xml.append(u"".join(self.startstring))

        for chanid in config.channels.keys():
            if config.channels[chanid].active and chanid in self.xml_channels:
                xml.append(u"".join(self.xml_channels[chanid]))
                if config.channels[chanid].opt_dict['add_hd_id'] and '%s-hd' % (chanid) in self.xml_channels:
                    xml.append(u"".join(self.xml_channels['%s-hd' % chanid]))

        for chanid in config.channels.keys():
            if config.channels[chanid].active and chanid in self.xml_programs:
                for program in self.xml_programs[chanid]:
                    xml.append(u"".join(program))

                if config.channels[chanid].opt_dict['add_hd_id']:
                    for program in self.xml_programs['%s-hd' % chanid]:
                        xml.append(u"".join(program))

        xml.append(self.closestring)

        return u"".join(xml)

    def print_string(self):
        '''
        Print the compleet XML string to stdout or selected file
        '''
        xml = xml_output.get_xmlstring()

        if xml != None:
            if config.output == None:
                print(xml.encode(config.file_encoding))

            else:
                config.output.write(xml)

            if config.write_info_files:
                infofiles.write_xmloutput(xml)

# end XMLoutput
xml_output = XMLoutput()

def get_brt1_channel(days):
    """
    Get the channel info from the BRT1
    """
    brt1_zoeken ='http://www.een.be/tv-gids/day'
    programs = []
    onedata = re.compile('<li.*?id="([0-9]+?)">.*?<div class="(.*?)">(.*?)</li>',re.DOTALL)
    startdata = re.compile('<span title="begintijd">(.*?)</span>',re.DOTALL)
    contentdata = re.compile('<div class="content">.*?<h5>(.*?)</h5>(.*?)</div>',re.DOTALL)
    urldata = re.compile('(.*?)<a href="(.*?)" title="',re.DOTALL)
    extradata = re.compile('(.*?)p style=(.*?)</p>',re.DOTALL)
    descrline = re.compile('<p>(.*?)</p>',re.DOTALL)

    # een.be shows programs per day, so we loop over the number of days
    # we are required to grab
    for offset in range( config.opt_dict['offset'], (config.opt_dict['offset'] + config.opt_dict['days'])):

        channel_url = brt1_zoeken +  unicode(offset + 1)

        if offset > 0:
            time.sleep(random.randint(config.nice_time[0], config.nice_time[1]))

        # get the raw programming for the day
        strdata = xml_output.channelsource[0].get_page(channel_url)
        prog_list = onedata.finditer(strdata)
        for v in prog_list:
            id = v.group(1)
            type = v.group(2)
            start = startdata.search(v.group(3)).group(1)
            content = contentdata.search(v.group(3))
            titel = content.group(1)
            data =content.group(2)
            #print id + ': ' + type + ': ' + start + ': ' + titel
            #print data
            try:
                url = urldata.search(data)
                data = url.group(1)
                url = url.group(2)
            except Exception as e:
                url = ''
            try:
                details = extradata.search(data)
                data = details.group(1)
                details = details.group(2)
            except:
                details = ''
            teletext = ('Ondertiteling via T888' in details)
            #~ actua = ('Beschikbaar in ACTUA' in details)
            #~ ooitgemist = ('Beschikbaar in OOIT GEMIST' in details)
            #~ netgemist = ('Beschikbaar in NET GEMIST' in details)
            data = data.replace('\n','')
            data = data.replace(' <br/> ',' ')
            data = data.replace(' <br/>',' ')
            data = data.replace('<br/> ',' ')
            data = data.replace('<br/>',' ')
            #descriptions = ()
            descriptions = descrline.finditer(data)
            #~ print ''
            #~ print titel
            #~ for descr in descriptions:
                #~ if descr.group(1) != '':
                    #~ print descr.group(1)

#end get_brt1_channel()

def main():
    # We want to handle unexpected errors nicely. With a message to the log
    try:
        # Get the options, channels and other configuration
        x = config.validate_commandline()
        if x != None:
            return(x)

        log("The Netherlands: %s\n" % config.version(True), 1, 1)

        # Start the seperate fetching threads
        for source in xml_output.channelsource.values():
            x = source.start()
            if x != None:
                return(x)

        # Start the Channel threads
        counter = 0
        for channel in config.channels.values():
            if not channel.active:
                continue

            counter += 1
            channel.counter = counter
            x = channel.start()
            if x != None:
                return(x)

        # This thread monitors the cache and saves it at an interval
        xml_output.program_cache.start()

        xml_output.channelsource[0].join()
        xml_output.channelsource[1].join()

        # Make sure the cache is saved
        xml_output.program_cache.quit = True

        # produce the results and wrap-up
        config.write_defaults_list()
        xml_output.print_string()
        xml_output.program_cache.join()
        xml_output.program_cache = None

    except:
        err_obj = sys.exc_info()[2]
        log('\nAn unexpected error has occured at line: %s, %s: %s\n' %  (err_obj.tb_lineno, err_obj.tb_lasti, sys.exc_info()[1]), 0)

        while True:
            err_obj = err_obj.tb_next
            if err_obj == None:
                break

            log('                   tracing back to line: %s, %s\n' %  (err_obj.tb_lineno, err_obj.tb_lasti), 0)

        log('\nIf you want assistence, please attach your configuration and log files!\n     %s\n     %s\n' % (config.config_file, config.log_file),0)
        return(99)

    # and return success
    return(0)
# end main()

# allow this to be a module
if __name__ == '__main__':
    x = main()
    config.close()
    sys.exit(x)
